WEBVTT

00:00:00.000 --> 00:00:05.401 align:middle line:90%


00:00:05.401 --> 00:00:08.838 align:middle line:90%
[THEME MUSIC]

00:00:08.838 --> 00:00:20.131 align:middle line:90%


00:00:20.131 --> 00:00:22.140 align:middle line:10%
>>GEORGE NOORY: Well,
welcome to another edition

00:00:22.140 --> 00:00:22.940 align:middle line:10%
of "Beyond Belief."

00:00:22.940 --> 00:00:26.990 align:middle line:10%
I'm George Noory, and when
we get done with this show,

00:00:26.990 --> 00:00:29.250 align:middle line:10%
you are going to be
running around the house--

00:00:29.250 --> 00:00:31.710 align:middle line:10%
or wherever you
live-- going, I can't

00:00:31.710 --> 00:00:34.520 align:middle line:10%
believe this is going to
happen to us in the future.

00:00:34.520 --> 00:00:37.620 align:middle line:84%
Our special guest is a
technology consultant

00:00:37.620 --> 00:00:42.350 align:middle line:90%
and a scientist, Charles Ostman.

00:00:42.350 --> 00:00:43.820 align:middle line:84%
>>The technology
of the future may

00:00:43.820 --> 00:00:46.820 align:middle line:84%
be closer than you think
Charles Ostman, a Senior

00:00:46.820 --> 00:00:49.290 align:middle line:84%
Fellow at the Institute
for Global Futures,

00:00:49.290 --> 00:00:51.230 align:middle line:84%
has spent more than
30 years working

00:00:51.230 --> 00:00:54.230 align:middle line:84%
in cutting-edge fields such
as electronics, computing,

00:00:54.230 --> 00:00:55.830 align:middle line:90%
and artificial intelligence.

00:00:55.830 --> 00:00:58.400 align:middle line:84%
He explains how we may
soon use technology

00:00:58.400 --> 00:01:02.580 align:middle line:84%
to manipulate the weather,
alter our genes, and much more.

00:01:02.580 --> 00:01:06.032 align:middle line:90%
Today, on "Beyond Belief."

00:01:06.032 --> 00:01:07.740 align:middle line:84%
>>NOORY: Charles,
welcome to the program.

00:01:07.740 --> 00:01:08.750 align:middle line:90%
Good to have you with us.

00:01:08.750 --> 00:01:10.416 align:middle line:10%
>>CHARLES OSTMAN:
Very happy to be here.

00:01:10.416 --> 00:01:12.450 align:middle line:10%
>>NOORY: We met once,
briefly, many years ago.

00:01:12.450 --> 00:01:14.844 align:middle line:84%
But you've been on the radio
program quite a long time--

00:01:14.844 --> 00:01:15.760 align:middle line:90%
>>OSTMAN: Yes, I have.

00:01:15.760 --> 00:01:18.360 align:middle line:84%
>>NOORY: --providing
us great information.

00:01:18.360 --> 00:01:20.820 align:middle line:84%
And kind of scary
information, isn't it?

00:01:20.820 --> 00:01:23.180 align:middle line:10%
>>OSTMAN: Well,
hopefully informative.

00:01:23.180 --> 00:01:25.279 align:middle line:10%
Not to paint everything
in a dark picture,

00:01:25.279 --> 00:01:27.570 align:middle line:10%
but I think it's appropriate--
especially at this point

00:01:27.570 --> 00:01:30.090 align:middle line:10%
in time-- that people have
at least a sense of where

00:01:30.090 --> 00:01:32.100 align:middle line:10%
these changes are going
to happen and why.

00:01:32.100 --> 00:01:33.930 align:middle line:84%
We may still have a
potential, at least,

00:01:33.930 --> 00:01:35.410 align:middle line:90%
for influencing that change.

00:01:35.410 --> 00:01:37.290 align:middle line:84%
But I believe, at a
certain threshold,

00:01:37.290 --> 00:01:39.440 align:middle line:84%
it will be beyond the reach
of the general public.

00:01:39.440 --> 00:01:39.863 align:middle line:90%
And that's my concern.

00:01:39.863 --> 00:01:40.980 align:middle line:84%
>>NOORY: It might
be "Beyond Belief."

00:01:40.980 --> 00:01:43.105 align:middle line:84%
>>OSTMAN: Might even be
"Beyond Belief," indeed so.

00:01:43.105 --> 00:01:45.950 align:middle line:84%
>>NOORY: How did technology pull
Charles Ostman into this field?

00:01:45.950 --> 00:01:46.750 align:middle line:90%
What happened?

00:01:46.750 --> 00:01:49.350 align:middle line:10%
>>OSTMAN: Well, that's a
somewhat long meandering story.

00:01:49.350 --> 00:01:49.630 align:middle line:10%
[LAUGHS]

00:01:49.630 --> 00:01:50.850 align:middle line:10%
But I started out in physics.

00:01:50.850 --> 00:01:52.490 align:middle line:10%
>>NOORY: Give us the
Cliff Notes version.

00:01:52.490 --> 00:01:53.790 align:middle line:10%
>>OSTMAN: Yeah, Cliff
Notes version, exactly.

00:01:53.790 --> 00:01:55.664 align:middle line:84%
So I started at Lawrence
Berkeley Laboratory,

00:01:55.664 --> 00:01:56.670 align:middle line:90%
UC Berkeley.

00:01:56.670 --> 00:01:59.010 align:middle line:84%
Spent about a decade in
the National Labs system,

00:01:59.010 --> 00:02:01.120 align:middle line:90%
working with hydrogen physics.

00:02:01.120 --> 00:02:02.940 align:middle line:84%
I had the interesting
experience of then

00:02:02.940 --> 00:02:05.786 align:middle line:84%
being sent to Los Alamos,
to work on what was then

00:02:05.786 --> 00:02:07.160 align:middle line:84%
called the Antares
Project, which

00:02:07.160 --> 00:02:09.509 align:middle line:84%
was the
largest-ever-constructed--

00:02:09.509 --> 00:02:11.950 align:middle line:84%
at that time-- laser for
military applications.

00:02:11.950 --> 00:02:15.160 align:middle line:84%
Our goal was to neutralize
incoming MIRV warheads

00:02:15.160 --> 00:02:15.960 align:middle line:90%
from the Soviets.

00:02:15.960 --> 00:02:16.610 align:middle line:90%
>>NOORY: With lasers?

00:02:16.610 --> 00:02:17.590 align:middle line:90%
>>OSTMAN: With lasers, exactly.

00:02:17.590 --> 00:02:18.190 align:middle line:90%
>>NOORY: Yeah.

00:02:18.190 --> 00:02:19.910 align:middle line:84%
>>OSTMAN: And that's where
some of the atmospheric stuff

00:02:19.910 --> 00:02:20.253 align:middle line:90%
came in.

00:02:20.253 --> 00:02:21.860 align:middle line:84%
I can go into that
later, if you wish.

00:02:21.860 --> 00:02:23.950 align:middle line:84%
But then, I later
went into robotics.

00:02:23.950 --> 00:02:26.610 align:middle line:84%
I actually worked for a company
called Integrated Automation,

00:02:26.610 --> 00:02:28.356 align:middle line:84%
which specialize in
machine vision, sort

00:02:28.356 --> 00:02:30.394 align:middle line:84%
of like smart
cameras for robots.

00:02:30.394 --> 00:02:32.060 align:middle line:84%
Then we got bought
by Litton Industries.

00:02:32.060 --> 00:02:33.880 align:middle line:84%
So then I went to
work for Litton.

00:02:33.880 --> 00:02:36.510 align:middle line:84%
Then I got to work for Lucas
Film, strangely enough,

00:02:36.510 --> 00:02:37.310 align:middle line:90%
working on things--

00:02:37.310 --> 00:02:38.130 align:middle line:84%
>>NOORY: Well, that's
an interesting switch.

00:02:38.130 --> 00:02:40.280 align:middle line:84%
>>OSTMAN: It's an interesting
switch, indeed so.

00:02:40.280 --> 00:02:41.380 align:middle line:90%
I didn't do any film work.

00:02:41.380 --> 00:02:44.630 align:middle line:84%
But what I did do, is I worked
on the first ever really

00:02:44.630 --> 00:02:47.920 align:middle line:84%
fully-integrated
audio/visual editing

00:02:47.920 --> 00:02:49.129 align:middle line:90%
system, called the EditDroid.

00:02:49.129 --> 00:02:50.295 align:middle line:90%
>>NOORY: I've heard of that.

00:02:50.295 --> 00:02:52.110 align:middle line:84%
>>OSTMAN: Well, it was
kind of a big deal.

00:02:52.110 --> 00:02:55.300 align:middle line:84%
Because Steve Jobs actually came
to our facility at one point.

00:02:55.300 --> 00:02:57.916 align:middle line:84%
He became very enamored at
the hardware we had developed.

00:02:57.916 --> 00:02:59.790 align:middle line:84%
And then he purchased
the rights to replicate

00:02:59.790 --> 00:03:01.200 align:middle line:90%
this on a smaller box.

00:03:01.200 --> 00:03:04.730 align:middle line:84%
That became what was known as
the NeXT, or N-e-X-T, computer.

00:03:04.730 --> 00:03:08.620 align:middle line:84%
So that was a big tool for
the media world at the time.

00:03:08.620 --> 00:03:10.860 align:middle line:84%
Then I went on to
work in what later was

00:03:10.860 --> 00:03:13.402 align:middle line:90%
to be known as nanotechnology.

00:03:13.402 --> 00:03:15.860 align:middle line:84%
>>NOORY: Which I want to talk
with you about a lot tonight.

00:03:15.860 --> 00:03:16.660 align:middle line:90%
>>OSTMAN: Good.

00:03:16.660 --> 00:03:18.770 align:middle line:84%
Because it's my
belief that this is

00:03:18.770 --> 00:03:21.800 align:middle line:84%
a gateway to a really
wide diverse range

00:03:21.800 --> 00:03:23.910 align:middle line:84%
of different kinds
of developments,

00:03:23.910 --> 00:03:25.350 align:middle line:84%
technical disciplines,
and things

00:03:25.350 --> 00:03:26.830 align:middle line:90%
that will affect our daily life.

00:03:26.830 --> 00:03:29.310 align:middle line:84%
>>NOORY: I have heard
with nanotechnology,

00:03:29.310 --> 00:03:32.040 align:middle line:84%
that they one day will have
the ability-- they might even

00:03:32.040 --> 00:03:36.370 align:middle line:84%
have it now-- of injecting
you with little nanobots that

00:03:36.370 --> 00:03:39.390 align:middle line:84%
go and do whatever
you want them to do.

00:03:39.390 --> 00:03:41.680 align:middle line:84%
Are these little tiny
pieces of machinery?

00:03:41.680 --> 00:03:42.050 align:middle line:90%
Is that what they are?

00:03:42.050 --> 00:03:43.380 align:middle line:84%
>>OSTMAN: They actually
are little machines.

00:03:43.380 --> 00:03:46.250 align:middle line:84%
And in fact, I testified to
the FDA-- believe it or not--

00:03:46.250 --> 00:03:47.260 align:middle line:90%
on this very topic.

00:03:47.260 --> 00:03:49.820 align:middle line:84%
And the reason I was
there was because up

00:03:49.820 --> 00:03:52.930 align:middle line:84%
until that time, the
FDA's way of regulating

00:03:52.930 --> 00:03:55.835 align:middle line:84%
medical accessories, or
things in the medical market--

00:03:55.835 --> 00:03:56.635 align:middle line:90%
>>NOORY: Devices?

00:03:56.635 --> 00:03:58.010 align:middle line:84%
>>OSTMAN: Devices,
etc-- they had

00:03:58.010 --> 00:03:59.747 align:middle line:90%
chemistry on one side, drugs.

00:03:59.747 --> 00:04:02.330 align:middle line:84%
And then they had machinery on
the other side, things that you

00:04:02.330 --> 00:04:04.090 align:middle line:90%
would plug into your machines.

00:04:04.090 --> 00:04:06.790 align:middle line:84%
They would have wires and so
on, going to the human body.

00:04:06.790 --> 00:04:08.582 align:middle line:84%
They had no way
of defining things

00:04:08.582 --> 00:04:10.290 align:middle line:84%
that would go inside
the body, especially

00:04:10.290 --> 00:04:11.480 align:middle line:90%
at a micro and nano scale.

00:04:11.480 --> 00:04:14.450 align:middle line:84%
This was a completely
uncharted regulatory territory.

00:04:14.450 --> 00:04:16.930 align:middle line:84%
So they brought people like
me in to give a presentation

00:04:16.930 --> 00:04:20.110 align:middle line:84%
to explain my version of what
I thought this was going to be,

00:04:20.110 --> 00:04:22.720 align:middle line:84%
as a potential for a
regulatory compliancy

00:04:22.720 --> 00:04:24.960 align:middle line:84%
code which was eventually
going to be established.

00:04:24.960 --> 00:04:26.820 align:middle line:90%
So that was about 10 years ago.

00:04:26.820 --> 00:04:29.180 align:middle line:84%
So you fast forward
to today, where

00:04:29.180 --> 00:04:31.230 align:middle line:84%
what had been sort
of quasi theoretical,

00:04:31.230 --> 00:04:33.430 align:middle line:84%
or at a very early
age of development,

00:04:33.430 --> 00:04:35.100 align:middle line:90%
has gone much further.

00:04:35.100 --> 00:04:37.940 align:middle line:84%
And so the range of
options that exist

00:04:37.940 --> 00:04:41.430 align:middle line:84%
to enhance sensory perception,
to enhance neural capacity--

00:04:41.430 --> 00:04:44.000 align:middle line:84%
perhaps change the
way your mind works--

00:04:44.000 --> 00:04:46.840 align:middle line:84%
to interact with various
organs within the body,

00:04:46.840 --> 00:04:50.680 align:middle line:84%
to have an adaptive
predictive way of dealing

00:04:50.680 --> 00:04:54.020 align:middle line:84%
with medical situations in a
real-time continuous basis,

00:04:54.020 --> 00:04:56.350 align:middle line:84%
that's sort of the
ultimate outcome of this.

00:04:56.350 --> 00:04:58.590 align:middle line:84%
How far it's gotten
into the public world

00:04:58.590 --> 00:04:59.750 align:middle line:90%
here in the United States?

00:04:59.750 --> 00:05:01.120 align:middle line:90%
That's one question.

00:05:01.120 --> 00:05:03.450 align:middle line:84%
But I think from a
global perspective,

00:05:03.450 --> 00:05:05.330 align:middle line:84%
this development path
is moving very fast.

00:05:05.330 --> 00:05:07.680 align:middle line:84%
>>NOORY: Is that exciting
for you, as a scientist?

00:05:07.680 --> 00:05:09.280 align:middle line:84%
>>OSTMAN: I think
it's interesting.

00:05:09.280 --> 00:05:11.470 align:middle line:84%
I would suggest to you
that this is, in my mind,

00:05:11.470 --> 00:05:15.575 align:middle line:84%
like an evolutionary threshold
that we're crossing into.

00:05:15.575 --> 00:05:18.190 align:middle line:84%
Us old timers, the
gray hair and beards,

00:05:18.190 --> 00:05:19.850 align:middle line:84%
we're maybe the
last of our kind,

00:05:19.850 --> 00:05:22.430 align:middle line:90%
who are truly organic beings.

00:05:22.430 --> 00:05:24.220 align:middle line:84%
I think we're stepping
into a territory

00:05:24.220 --> 00:05:28.190 align:middle line:84%
where as an option, as a health
care maintenance perspective,

00:05:28.190 --> 00:05:30.516 align:middle line:84%
we're stepping into a world
where it's ever less going

00:05:30.516 --> 00:05:32.890 align:middle line:84%
to be what we were born with,
and ever more about what we

00:05:32.890 --> 00:05:33.780 align:middle line:90%
have access to.

00:05:33.780 --> 00:05:36.421 align:middle line:84%
>>NOORY: Are we going
to become cyborgs?

00:05:36.421 --> 00:05:38.420 align:middle line:84%
>>OSTMAN: That depends
on how you define cyborg.

00:05:38.420 --> 00:05:40.510 align:middle line:84%
Not to be cagey, but
there is one version

00:05:40.510 --> 00:05:42.730 align:middle line:84%
of a cyborg, like,
a "Terminator" robot

00:05:42.730 --> 00:05:43.630 align:middle line:90%
or something.

00:05:43.630 --> 00:05:45.070 align:middle line:90%
OK, that's the extreme version.

00:05:45.070 --> 00:05:47.400 align:middle line:84%
But I think in
small increments, we

00:05:47.400 --> 00:05:49.510 align:middle line:84%
begin to put machines
inside of our body,

00:05:49.510 --> 00:05:51.920 align:middle line:84%
monitoring systems,
sensors, things

00:05:51.920 --> 00:05:53.810 align:middle line:84%
that can dispense
chemistries over time,

00:05:53.810 --> 00:05:56.100 align:middle line:84%
things that enhance,
in some ways,

00:05:56.100 --> 00:05:58.330 align:middle line:90%
what our different organs do.

00:05:58.330 --> 00:06:00.747 align:middle line:84%
As you see it as a kind of a
gradual, incremental process,

00:06:00.747 --> 00:06:01.546 align:middle line:90%
yes.

00:06:01.546 --> 00:06:03.970 align:middle line:84%
We are sort of becoming a
less-than-organic being.

00:06:03.970 --> 00:06:05.254 align:middle line:90%
I'll just put it that way.

00:06:05.254 --> 00:06:06.670 align:middle line:84%
>>NOORY: I want
you to take a look

00:06:06.670 --> 00:06:10.360 align:middle line:84%
at a little clip of a
documentary on nanotechnology.

00:06:10.360 --> 00:06:12.450 align:middle line:84%
It will give you a very
good perspective of what

00:06:12.450 --> 00:06:15.270 align:middle line:90%
we're talking about right now.

00:06:15.270 --> 00:06:19.060 align:middle line:10%
>>Meet Jason Henderson from West
Virginia, and Keiron McCammon,

00:06:19.060 --> 00:06:19.860 align:middle line:10%
from California.

00:06:19.860 --> 00:06:23.168 align:middle line:90%
[MUSIC PLAYING]

00:06:23.168 --> 00:06:27.605 align:middle line:90%


00:06:27.605 --> 00:06:28.591 align:middle line:90%
>>Good afternoon.

00:06:28.591 --> 00:06:31.570 align:middle line:90%


00:06:31.570 --> 00:06:34.500 align:middle line:10%
So these arms are what?

00:06:34.500 --> 00:06:36.950 align:middle line:10%
I mean, how do these arms work?

00:06:36.950 --> 00:06:39.776 align:middle line:84%
>>JASON HENDERSON: The remaining
muscles that are in your arm

00:06:39.776 --> 00:06:42.640 align:middle line:84%
have electrical signals that
come from your nervous system.

00:06:42.640 --> 00:06:43.440 align:middle line:90%
>>Like these ones?

00:06:43.440 --> 00:06:44.560 align:middle line:90%
>>HENDERSON: Yeah.

00:06:44.560 --> 00:06:47.400 align:middle line:10%
>>KEIRON MCCAMMON: So I have
a myoelectric sensor one here.

00:06:47.400 --> 00:06:49.580 align:middle line:10%
And then another one
on the other side.

00:06:49.580 --> 00:06:52.960 align:middle line:10%
So when I contract one
muscle, then the hand opens.

00:06:52.960 --> 00:06:55.780 align:middle line:10%
When I contract the other
muscle, then the hand closes.

00:06:55.780 --> 00:06:57.680 align:middle line:84%
Then I have a wrist
rotation unit, which

00:06:57.680 --> 00:06:59.550 align:middle line:90%
is independent of the hand.

00:06:59.550 --> 00:07:02.350 align:middle line:84%
Where if I contract both
muscles at the same time,

00:07:02.350 --> 00:07:06.220 align:middle line:84%
I can essentially rotate the
hand one way or the other.

00:07:06.220 --> 00:07:12.400 align:middle line:84%
>>I'm now filming your bionic
hand with my bionic eye.

00:07:12.400 --> 00:07:13.780 align:middle line:90%
That's pretty cool.

00:07:13.780 --> 00:07:16.722 align:middle line:84%
>>MCCAMMON: So it's kind of I'm
thinking, but I'm not thinking,

00:07:16.722 --> 00:07:17.930 align:middle line:90%
OK, I've got to open my hand.

00:07:17.930 --> 00:07:21.160 align:middle line:84%
I'm just thinking as
if I had a hand there,

00:07:21.160 --> 00:07:24.180 align:middle line:90%
and I just want to open it.

00:07:24.180 --> 00:07:26.980 align:middle line:84%
>>NOORY: Charles, just
those applications alone,

00:07:26.980 --> 00:07:28.515 align:middle line:90%
it's absolutely astounding!

00:07:28.515 --> 00:07:29.640 align:middle line:90%
>>OSTMAN: It is astounding.

00:07:29.640 --> 00:07:31.020 align:middle line:84%
And a lot of it's
actually been driven

00:07:31.020 --> 00:07:33.120 align:middle line:84%
by-- I'm sorry to say--
people in the military who

00:07:33.120 --> 00:07:34.620 align:middle line:90%
have been badly injured.

00:07:34.620 --> 00:07:38.080 align:middle line:84%
Which, in a way, has accelerated
the funding or the range

00:07:38.080 --> 00:07:39.610 align:middle line:90%
of application development.

00:07:39.610 --> 00:07:40.994 align:middle line:84%
But in a broader
sense, yes, this

00:07:40.994 --> 00:07:43.160 align:middle line:84%
is exactly what's coming
back to the general public.

00:07:43.160 --> 00:07:46.550 align:middle line:84%
So what was being shown there
was direct neural interface.

00:07:46.550 --> 00:07:50.920 align:middle line:84%
So that your thoughts or your
desired motives, as it were,

00:07:50.920 --> 00:07:53.760 align:middle line:84%
could be translated directly
into physical machinery.

00:07:53.760 --> 00:07:55.550 align:middle line:90%
That'd be part of your body.

00:07:55.550 --> 00:07:55.790 align:middle line:90%
>>NOORY: It's dramatic.

00:07:55.790 --> 00:07:56.020 align:middle line:10%
>>OSTMAN: And this
is actually just

00:07:56.020 --> 00:07:58.910 align:middle line:10%
from one smaller subset,
really, of a larger

00:07:58.910 --> 00:08:00.150 align:middle line:10%
range of things like this.

00:08:00.150 --> 00:08:02.380 align:middle line:84%
But it was a very good
example of the concept.

00:08:02.380 --> 00:08:04.970 align:middle line:84%
>>NOORY: At what point
could you literally make

00:08:04.970 --> 00:08:07.894 align:middle line:84%
almost an entire
robot like that?

00:08:07.894 --> 00:08:09.810 align:middle line:84%
>>OSTMAN: Well, that's
where things are going.

00:08:09.810 --> 00:08:12.010 align:middle line:84%
And that's why I, in
a quasi-joking way,

00:08:12.010 --> 00:08:13.700 align:middle line:84%
made reference to
the "Terminator."

00:08:13.700 --> 00:08:16.370 align:middle line:84%
How far are we away from
having a Terminator-like thing

00:08:16.370 --> 00:08:17.360 align:middle line:90%
possible?

00:08:17.360 --> 00:08:19.040 align:middle line:90%
10, 12, maybe 15 years max.

00:08:19.040 --> 00:08:20.710 align:middle line:84%
But certainly, the
pieces of the puzzle

00:08:20.710 --> 00:08:22.500 align:middle line:90%
are quickly coming into place.

00:08:22.500 --> 00:08:24.852 align:middle line:84%
And circling back to
nanotechnology, the reason that

00:08:24.852 --> 00:08:26.310 align:middle line:84%
becomes relevant
is because now you

00:08:26.310 --> 00:08:30.440 align:middle line:84%
have access to making
specialized materials, which

00:08:30.440 --> 00:08:33.267 align:middle line:84%
are much stronger, lighter,
much higher-density energy

00:08:33.267 --> 00:08:35.600 align:middle line:84%
available in terms of batteries,
and that sort of thing,

00:08:35.600 --> 00:08:38.309 align:middle line:84%
for power management;
much smarter computing

00:08:38.309 --> 00:08:41.964 align:middle line:84%
mechanisms that can be compacted
into a portable system.

00:08:41.964 --> 00:08:43.630 align:middle line:84%
Boston Dynamics-- as
you probably know--

00:08:43.630 --> 00:08:46.060 align:middle line:84%
is the company that has
produced the robotic dog

00:08:46.060 --> 00:08:48.090 align:middle line:84%
and the robotic horse,
that sort of thing.

00:08:48.090 --> 00:08:50.000 align:middle line:84%
And now they have
a robotic biped,

00:08:50.000 --> 00:08:52.780 align:middle line:84%
which is pretty close to a
quasi-Terminator-like thing.

00:08:52.780 --> 00:08:55.320 align:middle line:84%
In other words, a machine
that really strongly

00:08:55.320 --> 00:08:57.410 align:middle line:90%
replicates a biological entity.

00:08:57.410 --> 00:08:58.830 align:middle line:90%
It's what's called biomimicry.

00:08:58.830 --> 00:09:00.870 align:middle line:90%
That's the buzzword for it.

00:09:00.870 --> 00:09:02.660 align:middle line:90%
But we're sort of there now.

00:09:02.660 --> 00:09:05.610 align:middle line:84%
And how far this goes into
the general population,

00:09:05.610 --> 00:09:07.184 align:middle line:84%
it's really only
a matter of time.

00:09:07.184 --> 00:09:09.350 align:middle line:84%
It's not if, it's just a
matter of when, and in what

00:09:09.350 --> 00:09:10.420 align:middle line:90%
increments.

00:09:10.420 --> 00:09:12.170 align:middle line:84%
>>NOORY: When we were
kids, it was a movie

00:09:12.170 --> 00:09:16.810 align:middle line:84%
that Raquel Welch was in, where
they in this little submarine.

00:09:16.810 --> 00:09:19.050 align:middle line:90%
And they shrunk it down.

00:09:19.050 --> 00:09:21.680 align:middle line:84%
And they injected
it into a human,

00:09:21.680 --> 00:09:24.369 align:middle line:84%
because he had a
stroke or something.

00:09:24.369 --> 00:09:25.410 align:middle line:90%
And they needed to do it.

00:09:25.410 --> 00:09:26.860 align:middle line:84%
It was called
"Fantastic Voyage."

00:09:26.860 --> 00:09:28.651 align:middle line:84%
>>OSTMAN: "Fantastic
Voyage," that's right.

00:09:28.651 --> 00:09:31.470 align:middle line:84%
>>NOORY: I thought that
was amazing technology,

00:09:31.470 --> 00:09:35.880 align:middle line:84%
amazing science fiction,
when I was a kid.

00:09:35.880 --> 00:09:38.131 align:middle line:84%
We are pretty darn close to
that right now, aren't we?

00:09:38.131 --> 00:09:39.546 align:middle line:84%
>>OSTMAN: We're
pretty darn close.

00:09:39.546 --> 00:09:42.100 align:middle line:84%
Maybe not shrinking people
into a submarine, per se.

00:09:42.100 --> 00:09:44.680 align:middle line:84%
But as a vision of the
concept of smart things

00:09:44.680 --> 00:09:46.430 align:middle line:84%
that can go inside the
body and interact--

00:09:46.430 --> 00:09:47.090 align:middle line:84%
>>NOORY: Well, the
nanotechnology's

00:09:47.090 --> 00:09:47.890 align:middle line:90%
the submarine now.

00:09:47.890 --> 00:09:48.970 align:middle line:90%
>>OSTMAN: Exactly.

00:09:48.970 --> 00:09:49.820 align:middle line:90%
Exactly right.

00:09:49.820 --> 00:09:51.403 align:middle line:84%
That's exactly where
things are going.

00:09:51.403 --> 00:09:53.830 align:middle line:84%
And that's why I made
mention of the FDA event

00:09:53.830 --> 00:09:56.307 align:middle line:84%
that I was integrating
with earlier.

00:09:56.307 --> 00:09:57.890 align:middle line:84%
Because people, even
then, were trying

00:09:57.890 --> 00:09:59.780 align:middle line:84%
to figure out,
how to we describe

00:09:59.780 --> 00:10:01.670 align:middle line:90%
this as a medical application?

00:10:01.670 --> 00:10:02.670 align:middle line:90%
How do we regulate this?

00:10:02.670 --> 00:10:03.570 align:middle line:90%
In what context?

00:10:03.570 --> 00:10:05.760 align:middle line:84%
If you go to your
health care provider,

00:10:05.760 --> 00:10:08.510 align:middle line:84%
do you say, I want to have
access to these things

00:10:08.510 --> 00:10:11.170 align:middle line:84%
to make my body or my
mind function better?

00:10:11.170 --> 00:10:13.840 align:middle line:84%
So that was really the
precursor of establishing

00:10:13.840 --> 00:10:16.009 align:middle line:84%
a kind of protocol
to make these things

00:10:16.009 --> 00:10:17.300 align:middle line:90%
available to the general world.

00:10:17.300 --> 00:10:19.370 align:middle line:84%
And like I said, that
was about 10 years ago.

00:10:19.370 --> 00:10:21.190 align:middle line:84%
>>NOORY: Do you
think that technology

00:10:21.190 --> 00:10:27.060 align:middle line:84%
will get so amazingly incredible
that people will get injected

00:10:27.060 --> 00:10:32.230 align:middle line:84%
with technology, with nanobots,
to go into their bodies

00:10:32.230 --> 00:10:35.650 align:middle line:84%
and help them for telepathy
and communication,

00:10:35.650 --> 00:10:36.620 align:middle line:90%
and everything else?

00:10:36.620 --> 00:10:37.420 align:middle line:90%
>>OSTMAN: Sure.

00:10:37.420 --> 00:10:40.260 align:middle line:84%
>>NOORY: That the computer, for
example, may be in your head?

00:10:40.260 --> 00:10:42.170 align:middle line:84%
Where you simply
think, all right,

00:10:42.170 --> 00:10:45.260 align:middle line:84%
let's get information
on "Beyond Belief."

00:10:45.260 --> 00:10:47.110 align:middle line:90%
And there it is, in your brain.

00:10:47.110 --> 00:10:47.985 align:middle line:90%
>>OSTMAN: Exactly so.

00:10:47.985 --> 00:10:51.012 align:middle line:84%
Well, Mark Zuckerberg-- founder
of Facebook, of course--

00:10:51.012 --> 00:10:53.220 align:middle line:84%
made a very telling comment
about two months ago now.

00:10:53.220 --> 00:10:56.830 align:middle line:84%
He said, the next big thing,
the next big industry increment

00:10:56.830 --> 00:10:59.400 align:middle line:84%
is going to be
artificial telepathy.

00:10:59.400 --> 00:11:01.220 align:middle line:84%
In other words,
connecting your thoughts

00:11:01.220 --> 00:11:04.170 align:middle line:84%
to the global blogosphere or to
the information universe, as it

00:11:04.170 --> 00:11:04.970 align:middle line:90%
were.

00:11:04.970 --> 00:11:06.250 align:middle line:90%
>>NOORY: Is that real?

00:11:06.250 --> 00:11:08.250 align:middle line:84%
>>OSTMAN: That's exactly
where things are going.

00:11:08.250 --> 00:11:11.220 align:middle line:84%
And now, I could go to
several different examples.

00:11:11.220 --> 00:11:13.170 align:middle line:84%
Paul Gallant's
laboratory at UC Berkeley

00:11:13.170 --> 00:11:16.360 align:middle line:84%
is kind of a good snapshot
of this idea-- the idea

00:11:16.360 --> 00:11:19.470 align:middle line:84%
that you can take your
thoughts, your experiences,

00:11:19.470 --> 00:11:21.650 align:middle line:84%
extract them from
your brain, play them

00:11:21.650 --> 00:11:26.190 align:middle line:84%
back as a visual content
deliverable, as it were.

00:11:26.190 --> 00:11:28.680 align:middle line:84%
So we can actually see what
it was that you experienced,

00:11:28.680 --> 00:11:31.236 align:middle line:84%
or what you thought, or what
things you were involved with.

00:11:31.236 --> 00:11:32.360 align:middle line:90%
This has already been done.

00:11:32.360 --> 00:11:34.700 align:middle line:84%
The resolution's being
tweaked a little bit.

00:11:34.700 --> 00:11:37.890 align:middle line:84%
But certainly, the precursor
is already well established.

00:11:37.890 --> 00:11:39.410 align:middle line:84%
The thing I would
like to suggest

00:11:39.410 --> 00:11:42.150 align:middle line:84%
to you is that-- it's
my opinion-- speech

00:11:42.150 --> 00:11:44.730 align:middle line:84%
is a kind of a
clumsy, slow process.

00:11:44.730 --> 00:11:48.140 align:middle line:84%
We're being trained
to adapt to a universe

00:11:48.140 --> 00:11:50.820 align:middle line:84%
where the flow of information
and the parallelism

00:11:50.820 --> 00:11:54.150 align:middle line:84%
of a million different tracks
of information simultaneously.

00:11:54.150 --> 00:11:56.407 align:middle line:84%
This is a scale of
complexity that no humans

00:11:56.407 --> 00:11:58.490 align:middle line:84%
have ever interacted with
before, that we know of.

00:11:58.490 --> 00:12:00.060 align:middle line:90%
But we're in this current time.

00:12:00.060 --> 00:12:03.850 align:middle line:84%
This is a new evolutionary
threshold of sorts.

00:12:03.850 --> 00:12:06.600 align:middle line:84%
So is this the time
where an idea that

00:12:06.600 --> 00:12:10.460 align:middle line:84%
would have been science fiction
20 or 30 years ago, but maybe

00:12:10.460 --> 00:12:12.730 align:middle line:84%
didn't have a realistic
application for it,

00:12:12.730 --> 00:12:14.790 align:middle line:84%
now it's becoming
almost a necessity.

00:12:14.790 --> 00:12:18.210 align:middle line:84%
So I would suggest the
next 10 to 20 years,

00:12:18.210 --> 00:12:21.590 align:middle line:84%
some form of neural enhancement
and direct neural interface

00:12:21.590 --> 00:12:23.870 align:middle line:84%
that allows us to use our
thoughts to communicate

00:12:23.870 --> 00:12:28.380 align:middle line:84%
directly to an outside world,
realm, is going to be required.

00:12:28.380 --> 00:12:32.320 align:middle line:84%
Not as an option, but for those
that wish to be a step ahead,

00:12:32.320 --> 00:12:34.610 align:middle line:84%
to be more functional
in the workplace

00:12:34.610 --> 00:12:37.370 align:middle line:84%
or to be more
entrepreneurial, or to have

00:12:37.370 --> 00:12:40.520 align:middle line:84%
whatever abilities is required
to make more of your life,

00:12:40.520 --> 00:12:43.360 align:middle line:84%
as it were, it'll be the
quality of access that's

00:12:43.360 --> 00:12:45.770 align:middle line:84%
going to define the
haves and the have nots.

00:12:45.770 --> 00:12:46.896 align:middle line:90%
That's how I see it.

00:12:46.896 --> 00:12:48.270 align:middle line:84%
>>NOORY: What if
one day, though,

00:12:48.270 --> 00:12:50.425 align:middle line:90%
it becomes a requirement?

00:12:50.425 --> 00:12:52.350 align:middle line:84%
As they say in the
Book of Revelations,

00:12:52.350 --> 00:12:53.960 align:middle line:90%
"The sign of the beast," right?

00:12:53.960 --> 00:12:54.200 align:middle line:90%
>>OSTMAN: I know.

00:12:54.200 --> 00:12:56.491 align:middle line:84%
>>NOORY: That you're going
to be required to have this,

00:12:56.491 --> 00:12:59.300 align:middle line:84%
you can't have the ability
to buy goods or services

00:12:59.300 --> 00:13:00.970 align:middle line:84%
or do anything
without that sign?

00:13:00.970 --> 00:13:01.280 align:middle line:90%
>>OSTMAN: Right.

00:13:01.280 --> 00:13:02.930 align:middle line:84%
>>NOORY: What if
they compel all of us

00:13:02.930 --> 00:13:06.310 align:middle line:84%
to do that, and then
they have built in,

00:13:06.310 --> 00:13:09.930 align:middle line:84%
Charles, this mechanism
to control you

00:13:09.930 --> 00:13:11.000 align:middle line:90%
at a touch of a button?

00:13:11.000 --> 00:13:12.390 align:middle line:84%
>>OSTMAN: I know exactly
where you're going.

00:13:12.390 --> 00:13:13.920 align:middle line:90%
And I tend to agree with you.

00:13:13.920 --> 00:13:16.140 align:middle line:84%
I'm not gleefully saying
this is a wonderful thing.

00:13:16.140 --> 00:13:18.140 align:middle line:90%
I'm just saying, is it what is?

00:13:18.140 --> 00:13:20.220 align:middle line:84%
And maybe it's, at this
point, that if there

00:13:20.220 --> 00:13:22.460 align:middle line:84%
is an interest in
interacting with this process

00:13:22.460 --> 00:13:25.700 align:middle line:84%
before it becomes mandatory--
which I think is possible--

00:13:25.700 --> 00:13:27.540 align:middle line:84%
this might be a
good time for people

00:13:27.540 --> 00:13:28.840 align:middle line:90%
to look at this more carefully.

00:13:28.840 --> 00:13:30.339 align:middle line:84%
>>NOORY: I mean,
we've seen protests

00:13:30.339 --> 00:13:33.180 align:middle line:84%
all around the country over
a number of things-- police

00:13:33.180 --> 00:13:34.245 align:middle line:90%
shootings, whatever.

00:13:34.245 --> 00:13:35.220 align:middle line:90%
>>OSTMAN: Yeah, terrible things.

00:13:35.220 --> 00:13:37.840 align:middle line:84%
>>NOORY: What if they have that
technology, where everybody's

00:13:37.840 --> 00:13:41.900 align:middle line:84%
been injected since they
were a baby, and they say,

00:13:41.900 --> 00:13:45.180 align:middle line:84%
I'm shutting these
protesters down right now.

00:13:45.180 --> 00:13:47.810 align:middle line:84%
And you hit a button, and
they're all like, locked up,

00:13:47.810 --> 00:13:50.310 align:middle line:90%
frozen, is that conceivable?

00:13:50.310 --> 00:13:51.560 align:middle line:90%
>>OSTMAN: That is conceivable.

00:13:51.560 --> 00:13:55.410 align:middle line:84%
Now, how far it would get is
less of a technology question

00:13:55.410 --> 00:13:58.610 align:middle line:84%
than it is a social policy or
perhaps a political question.

00:13:58.610 --> 00:14:01.820 align:middle line:84%
And that's maybe why we're
having this discussion now.

00:14:01.820 --> 00:14:04.580 align:middle line:84%
I think it's inevitable that
the tools that would make that

00:14:04.580 --> 00:14:06.280 align:middle line:90%
possible are well within range.

00:14:06.280 --> 00:14:08.130 align:middle line:84%
Give it a decade,
maybe two decades max,

00:14:08.130 --> 00:14:09.640 align:middle line:84%
but we can certainly
see a timeline

00:14:09.640 --> 00:14:12.230 align:middle line:84%
where those critical marker
points along this process

00:14:12.230 --> 00:14:13.830 align:middle line:90%
become available.

00:14:13.830 --> 00:14:15.837 align:middle line:84%
To what extent it
might be applied here

00:14:15.837 --> 00:14:16.670 align:middle line:90%
could be questioned.

00:14:16.670 --> 00:14:18.336 align:middle line:84%
But I think in other
parts of the world,

00:14:18.336 --> 00:14:21.380 align:middle line:84%
in other governments and
other cultural norms,

00:14:21.380 --> 00:14:24.120 align:middle line:84%
as it were, this might
become more deployed.

00:14:24.120 --> 00:14:26.400 align:middle line:84%
In other words, using the
United-States-centric way

00:14:26.400 --> 00:14:28.380 align:middle line:84%
of looking at things
may be a bit misleading.

00:14:28.380 --> 00:14:29.838 align:middle line:84%
But I can certainly
see other parts

00:14:29.838 --> 00:14:33.120 align:middle line:84%
of the world becoming much
more adaptive to this idea--

00:14:33.120 --> 00:14:34.380 align:middle line:90%
like it or not.

00:14:34.380 --> 00:14:37.100 align:middle line:84%
Some pieces of the puzzle are
coming together as we speak.

00:14:37.100 --> 00:14:39.580 align:middle line:84%
>>NOORY: So if I want to
send Charles Ostman a text,

00:14:39.580 --> 00:14:41.970 align:middle line:84%
I no longer have to
use my smartphone.

00:14:41.970 --> 00:14:44.260 align:middle line:84%
I just think about it
and I send it to you?

00:14:44.260 --> 00:14:45.060 align:middle line:90%
>>OSTMAN: Correct.

00:14:45.060 --> 00:14:47.940 align:middle line:84%
That is exactly where
things are aimed at.

00:14:47.940 --> 00:14:51.430 align:middle line:84%
>>NOORY: What if I over-burden
you, and I keep sending texts?

00:14:51.430 --> 00:14:52.590 align:middle line:90%
Do I drive you nuts?

00:14:52.590 --> 00:14:54.839 align:middle line:84%
Do you have the capability
of shutting me off?

00:14:54.839 --> 00:14:56.880 align:middle line:84%
>>OSTMAN: Neuro spam,
There's even a term for it.

00:14:56.880 --> 00:14:57.620 align:middle line:90%
>>NOORY: Ha!

00:14:57.620 --> 00:14:58.578 align:middle line:90%
They're ready for that?

00:14:58.578 --> 00:14:59.750 align:middle line:90%
>>OSTMAN: Yeah, indeed so.

00:14:59.750 --> 00:15:02.180 align:middle line:84%
In fact, I've been to several
of these so-called NIBC

00:15:02.180 --> 00:15:02.980 align:middle line:90%
conferences.

00:15:02.980 --> 00:15:07.040 align:middle line:84%
This is the-- sorry for this--
Nano-Info-Bio-Cogno Tech

00:15:07.040 --> 00:15:08.010 align:middle line:90%
Integration Conference.

00:15:08.010 --> 00:15:09.430 align:middle line:84%
This was actually the
United States government's--

00:15:09.430 --> 00:15:10.990 align:middle line:84%
>>NOORY: Who comes
up with these names?

00:15:10.990 --> 00:15:12.406 align:middle line:84%
>>OSTMAN: Well,
these actually are

00:15:12.406 --> 00:15:14.760 align:middle line:84%
some of the top
scientists in the world.

00:15:14.760 --> 00:15:16.820 align:middle line:84%
And this actually was
headed by Mihail Roco, who

00:15:16.820 --> 00:15:18.830 align:middle line:84%
was the head of the
National Nanotechnology

00:15:18.830 --> 00:15:21.740 align:middle line:84%
Initiative, which was a
federally-funded project

00:15:21.740 --> 00:15:24.274 align:middle line:84%
to bring together
the best of the best

00:15:24.274 --> 00:15:25.690 align:middle line:84%
in these different
science domains

00:15:25.690 --> 00:15:27.940 align:middle line:84%
to say, OK, everybody
come together.

00:15:27.940 --> 00:15:29.920 align:middle line:84%
Figure out how these
things are blending

00:15:29.920 --> 00:15:32.380 align:middle line:84%
into an operational
ecology of sorts.

00:15:32.380 --> 00:15:33.570 align:middle line:90%
And then develop policies.

00:15:33.570 --> 00:15:36.081 align:middle line:84%
And this, again, goes
back about 10, 12 years.

00:15:36.081 --> 00:15:37.830 align:middle line:84%
So at the most recent
one I was at-- which

00:15:37.830 --> 00:15:40.940 align:middle line:84%
was at UCLA-- a woman from
UC Berkeley-- once again,

00:15:40.940 --> 00:15:43.580 align:middle line:84%
my Alma mater-- gave
the presentation

00:15:43.580 --> 00:15:45.460 align:middle line:84%
based around the idea
of what she called

00:15:45.460 --> 00:15:47.120 align:middle line:90%
neurological sovereignty.

00:15:47.120 --> 00:15:50.100 align:middle line:84%
That is, how do you
protect what should be

00:15:50.100 --> 00:15:53.360 align:middle line:90%
your internal sense of being?

00:15:53.360 --> 00:15:54.750 align:middle line:90%
>>NOORY: Exactly, your privacy.

00:15:54.750 --> 00:15:55.874 align:middle line:90%
>>OSTMAN: You have privacy.

00:15:55.874 --> 00:15:58.300 align:middle line:84%
Just how you identify
as a human being.

00:15:58.300 --> 00:16:00.670 align:middle line:84%
And in fact, I'm working on
a friend of mine's TED Talk

00:16:00.670 --> 00:16:02.670 align:middle line:84%
presentation where, a
three weeks from now, this

00:16:02.670 --> 00:16:03.680 align:middle line:90%
is exactly the topic.

00:16:03.680 --> 00:16:06.420 align:middle line:84%
In other words, where
are we surrendering

00:16:06.420 --> 00:16:09.590 align:middle line:84%
our personal identity
into this ubiquitous cloud

00:16:09.590 --> 00:16:13.280 align:middle line:84%
out there, this presence, that's
no longer confined by this?

00:16:13.280 --> 00:16:17.120 align:middle line:84%
So I thought it was fascinating
that 10 years ago, this woman

00:16:17.120 --> 00:16:20.050 align:middle line:84%
would come up with this idea
of neurological sovereignty.

00:16:20.050 --> 00:16:22.000 align:middle line:84%
And now today, we
have Mark Zuckerberg,

00:16:22.000 --> 00:16:24.540 align:middle line:84%
and many others behind him,
saying, actually, we're

00:16:24.540 --> 00:16:29.310 align:middle line:84%
going to convert this into a
ubiquitous interactive domain.

00:16:29.310 --> 00:16:30.900 align:middle line:84%
Remember now, it's
Mark Zuckerberg

00:16:30.900 --> 00:16:33.150 align:middle line:84%
that came up with the concept
of you are the product.

00:16:33.150 --> 00:16:37.100 align:middle line:84%
So if your thoughts and your
desires and your interests

00:16:37.100 --> 00:16:39.780 align:middle line:84%
become the product, you can
see where this might have

00:16:39.780 --> 00:16:41.640 align:middle line:90%
a somewhat darkish side to it.

00:16:41.640 --> 00:16:42.440 align:middle line:90%
>>NOORY: Sure.

00:16:42.440 --> 00:16:45.120 align:middle line:84%
And what if they want
to beam messages to us

00:16:45.120 --> 00:16:48.460 align:middle line:90%
or advertisements, or anything?

00:16:48.460 --> 00:16:50.586 align:middle line:90%
Would they have that capability?

00:16:50.586 --> 00:16:52.460 align:middle line:10%
>>OSTMAN: The idea of
neuro spam, once again.

00:16:52.460 --> 00:16:56.070 align:middle line:10%
So as a stopgap measure
along this path,

00:16:56.070 --> 00:16:58.530 align:middle line:10%
there's what's called
augmented reality.

00:16:58.530 --> 00:17:01.320 align:middle line:10%
Augmented reality means you can
wear a headset, like a Google

00:17:01.320 --> 00:17:02.637 align:middle line:10%
Glass type of thing.

00:17:02.637 --> 00:17:04.970 align:middle line:10%
And you walk down the street
or you drive your car, etc.

00:17:04.970 --> 00:17:07.589 align:middle line:84%
And you see these things
presented to you in real time.

00:17:07.589 --> 00:17:08.630 align:middle line:84%
>>NOORY: How can
you drive your car

00:17:08.630 --> 00:17:09.490 align:middle line:90%
and see that at the same time?

00:17:09.490 --> 00:17:11.573 align:middle line:84%
>>OSTMAN: Well, actually,
this is being developed.

00:17:11.573 --> 00:17:13.069 align:middle line:84%
I know it sounds
a little bizarre.

00:17:13.069 --> 00:17:15.790 align:middle line:84%
But imagine we're sitting
here, having a conversation.

00:17:15.790 --> 00:17:18.380 align:middle line:84%
And meanwhile, some sort
of e-mail message comes up,

00:17:18.380 --> 00:17:19.920 align:middle line:84%
or something I
was thinking about

00:17:19.920 --> 00:17:23.020 align:middle line:84%
suddenly pops into the
view, as I'm talking to you.

00:17:23.020 --> 00:17:26.230 align:middle line:90%
They call it Push Media Content.

00:17:26.230 --> 00:17:29.470 align:middle line:84%
So the whole idea of being
able to translate Push Media

00:17:29.470 --> 00:17:32.090 align:middle line:84%
Content into a
wearable thing that

00:17:32.090 --> 00:17:35.250 align:middle line:84%
is part of your daily life,
like the next generation

00:17:35.250 --> 00:17:37.970 align:middle line:84%
of smartphone, this is
already being put out there

00:17:37.970 --> 00:17:40.470 align:middle line:90%
as an experimental concept.

00:17:40.470 --> 00:17:45.732 align:middle line:84%
This is the clumsy almost
Rube Goldberg-ish first layer

00:17:45.732 --> 00:17:46.940 align:middle line:90%
of what you're talking about.

00:17:46.940 --> 00:17:49.465 align:middle line:84%
Where 10 years from now, forget
wearing the special glasses

00:17:49.465 --> 00:17:50.680 align:middle line:90%
and that sort of thing.

00:17:50.680 --> 00:17:53.300 align:middle line:84%
It'll just be happening
directly inside your head.

00:17:53.300 --> 00:17:56.320 align:middle line:84%
To what extent will the general
population actually accept

00:17:56.320 --> 00:17:57.790 align:middle line:90%
this as an idea?

00:17:57.790 --> 00:17:58.990 align:middle line:90%
Depends on marketing.

00:17:58.990 --> 00:18:03.360 align:middle line:84%
Depends on the political way
it's packaged, you might say.

00:18:03.360 --> 00:18:06.270 align:middle line:84%
>>NOORY: We talked a little bit
earlier about the "Terminator."

00:18:06.270 --> 00:18:07.070 align:middle line:90%
>>OSTMAN: Yeah.

00:18:07.070 --> 00:18:10.510 align:middle line:84%
>>NOORY: Let's look
at one of those clips.

00:18:10.510 --> 00:18:12.269 align:middle line:10%
>>Why him?

00:18:12.269 --> 00:18:14.310 align:middle line:10%
>>In a few months he
creates an evolutionary type

00:18:14.310 --> 00:18:16.580 align:middle line:10%
of microprocessor.

00:18:16.580 --> 00:18:17.380 align:middle line:90%
>>Go on.

00:18:17.380 --> 00:18:18.870 align:middle line:90%
Then what?

00:18:18.870 --> 00:18:21.550 align:middle line:84%
>>In three years, Cyberdyne
will become the largest supplier

00:18:21.550 --> 00:18:24.110 align:middle line:90%
of military computer systems.

00:18:24.110 --> 00:18:26.780 align:middle line:84%
All stealth bombers are upgraded
with Cyberdyne computers,

00:18:26.780 --> 00:18:28.420 align:middle line:90%
becoming fully unmanned.

00:18:28.420 --> 00:18:32.010 align:middle line:84%
Afterwards, they'll fly with
a perfect operational record.

00:18:32.010 --> 00:18:34.120 align:middle line:84%
The Skynet funding
bill is passed.

00:18:34.120 --> 00:18:37.570 align:middle line:84%
The system goes online
on August 4, 1997.

00:18:37.570 --> 00:18:40.370 align:middle line:84%
Human decisions are removed
from strategic defense.

00:18:40.370 --> 00:18:43.210 align:middle line:84%
Skynet begins to learn
at a geometric rate.

00:18:43.210 --> 00:18:48.260 align:middle line:84%
It becomes self-aware at 2:14
AM, Eastern time, August 29.

00:18:48.260 --> 00:18:51.780 align:middle line:84%
In a panic, they
try to put the plug.

00:18:51.780 --> 00:18:53.570 align:middle line:90%
>>Skynet fights back?

00:18:53.570 --> 00:18:54.370 align:middle line:90%
>>Yes.

00:18:54.370 --> 00:18:57.140 align:middle line:84%
It launches its missiles
against the targets in Russia.

00:18:57.140 --> 00:18:58.080 align:middle line:90%
>>Why attack Russia?

00:18:58.080 --> 00:18:59.940 align:middle line:90%
Aren't they our friends now?

00:18:59.940 --> 00:19:02.320 align:middle line:84%
>>Because Skynet knows that
the Russian counterattack

00:19:02.320 --> 00:19:04.086 align:middle line:84%
will eliminate its
enemies over here.

00:19:04.086 --> 00:19:04.886 align:middle line:90%
>>Jesus.

00:19:04.886 --> 00:19:08.170 align:middle line:90%


00:19:08.170 --> 00:19:11.400 align:middle line:84%
>>NOORY: So what was Arnold
talking about in that movie?

00:19:11.400 --> 00:19:14.020 align:middle line:84%
>>OSTMAN: The concept
of awareness--

00:19:14.020 --> 00:19:16.370 align:middle line:84%
and forgive the buzzword,
but there is a term out there

00:19:16.370 --> 00:19:18.070 align:middle line:90%
called synthetic sentience.

00:19:18.070 --> 00:19:20.820 align:middle line:84%
That is when a system
becomes aware of itself

00:19:20.820 --> 00:19:23.420 align:middle line:84%
and will independently
determine what

00:19:23.420 --> 00:19:24.980 align:middle line:84%
it thinks its best
response might

00:19:24.980 --> 00:19:28.230 align:middle line:84%
be to a series of perceived
challenges or just events

00:19:28.230 --> 00:19:31.470 align:middle line:84%
that it is processing--
and this is very, very much

00:19:31.470 --> 00:19:32.440 align:middle line:90%
on the front burner.

00:19:32.440 --> 00:19:34.410 align:middle line:84%
I can tell you from direct
personal experience,

00:19:34.410 --> 00:19:35.950 align:middle line:84%
this is exactly where
things are going now.

00:19:35.950 --> 00:19:37.490 align:middle line:84%
>>NOORY: So artificial
intelligence

00:19:37.490 --> 00:19:39.000 align:middle line:90%
makes up its own mind.

00:19:39.000 --> 00:19:40.080 align:middle line:90%
>>OSTMAN: Correct.

00:19:40.080 --> 00:19:42.364 align:middle line:84%
And there's a process called
Evolutionary Computing.

00:19:42.364 --> 00:19:44.030 align:middle line:84%
I was actually on the
board of a company

00:19:44.030 --> 00:19:45.960 align:middle line:90%
called Evolutionary Networks.

00:19:45.960 --> 00:19:47.790 align:middle line:10%
That's what our
job was, to create

00:19:47.790 --> 00:19:51.610 align:middle line:10%
self-correcting, self-healing
networks in the world of what

00:19:51.610 --> 00:19:54.560 align:middle line:10%
are called biological
computing platforms,

00:19:54.560 --> 00:19:56.600 align:middle line:10%
things that behave biologically.

00:19:56.600 --> 00:20:00.320 align:middle line:84%
It's no longer writing in
lines of code or mechanically

00:20:00.320 --> 00:20:02.510 align:middle line:84%
telling the thing
what to do at step x.

00:20:02.510 --> 00:20:07.300 align:middle line:84%
It's more like you create an
environmental sort of realm

00:20:07.300 --> 00:20:09.360 align:middle line:90%
that the system lives inside of.

00:20:09.360 --> 00:20:11.860 align:middle line:84%
And it processes constantly,
thousands if not millions,

00:20:11.860 --> 00:20:14.090 align:middle line:84%
of threads of information,
and reconstructs

00:20:14.090 --> 00:20:17.100 align:middle line:84%
its own anticipatory
analysis of where

00:20:17.100 --> 00:20:19.560 align:middle line:84%
it thinks the next thing
of interest should be.

00:20:19.560 --> 00:20:23.100 align:middle line:84%
So I gave a talk at
Lockheed in 2006,

00:20:23.100 --> 00:20:26.100 align:middle line:84%
on the biological metaphors
in computing event

00:20:26.100 --> 00:20:27.420 align:middle line:90%
they were having there.

00:20:27.420 --> 00:20:29.860 align:middle line:84%
The person who preceded
me was from Motorola.

00:20:29.860 --> 00:20:31.685 align:middle line:84%
The guy who invented
the term digital DNA,

00:20:31.685 --> 00:20:33.299 align:middle line:90%
kind of a famous guy.

00:20:33.299 --> 00:20:35.840 align:middle line:84%
And then the whole collection
of people, for three days, this

00:20:35.840 --> 00:20:37.760 align:middle line:90%
was the whole concept.

00:20:37.760 --> 00:20:39.130 align:middle line:90%
That was 10 years ago.

00:20:39.130 --> 00:20:41.690 align:middle line:84%
I can assure you, things
have moved much further

00:20:41.690 --> 00:20:43.360 align:middle line:90%
than what they were then.

00:20:43.360 --> 00:20:46.150 align:middle line:10%
So in these sort of
worst-case scenario,

00:20:46.150 --> 00:20:49.570 align:middle line:10%
could there be an
event-- for instance,

00:20:49.570 --> 00:20:52.030 align:middle line:10%
you've talked a lot about
the power grids going down,

00:20:52.030 --> 00:20:53.830 align:middle line:10%
which, by the way, I
very strongly support.

00:20:53.830 --> 00:20:55.288 align:middle line:84%
And thank you for
bringing this up.

00:20:55.288 --> 00:20:56.810 align:middle line:84%
It's an extremely
important topic.

00:20:56.810 --> 00:20:57.430 align:middle line:90%
>>NOORY: It's critical.

00:20:57.430 --> 00:20:58.050 align:middle line:90%
>>OSTMAN: It's critical.

00:20:58.050 --> 00:20:59.680 align:middle line:84%
And I think astonishing
that we haven't

00:20:59.680 --> 00:21:01.430 align:middle line:84%
done almost like a
Manhattan-scale project

00:21:01.430 --> 00:21:02.400 align:middle line:90%
to correct this.

00:21:02.400 --> 00:21:03.200 align:middle line:90%
It's amazing to me.

00:21:03.200 --> 00:21:07.410 align:middle line:84%
But imagine an event now,
where power grid goes down.

00:21:07.410 --> 00:21:08.780 align:middle line:90%
Networks go down.

00:21:08.780 --> 00:21:09.960 align:middle line:90%
Peoples' ATMs don't work.

00:21:09.960 --> 00:21:11.020 align:middle line:90%
Their cell phones don't work.

00:21:11.020 --> 00:21:11.700 align:middle line:90%
>>NOORY: Nothing works.

00:21:11.700 --> 00:21:12.400 align:middle line:90%
>>OSTMAN: Nothing works.

00:21:12.400 --> 00:21:13.350 align:middle line:90%
People start to panic.

00:21:13.350 --> 00:21:14.666 align:middle line:84%
You're going to have
chaos in the streets.

00:21:14.666 --> 00:21:15.466 align:middle line:90%
>>NOORY: Yeah.

00:21:15.466 --> 00:21:17.380 align:middle line:84%
>>OSTMAN: If a
Skynet-like something

00:21:17.380 --> 00:21:19.610 align:middle line:84%
were in the background
saying, OK we're

00:21:19.610 --> 00:21:21.750 align:middle line:84%
at DEFCON status--
whatever it's going

00:21:21.750 --> 00:21:23.910 align:middle line:90%
to be-- we better take over.

00:21:23.910 --> 00:21:26.810 align:middle line:84%
And forget the general
population's interest

00:21:26.810 --> 00:21:27.610 align:middle line:90%
at the moment.

00:21:27.610 --> 00:21:29.670 align:middle line:84%
We need to take the
larger view of things.

00:21:29.670 --> 00:21:31.151 align:middle line:90%
What do we do?

00:21:31.151 --> 00:21:32.650 align:middle line:84%
You almost, at a
certain point, have

00:21:32.650 --> 00:21:35.440 align:middle line:84%
to surrender the
control over what

00:21:35.440 --> 00:21:38.070 align:middle line:84%
would be a chaotic
realm into the hands

00:21:38.070 --> 00:21:40.430 align:middle line:84%
of this artificial
intelligence ecology of sorts.

00:21:40.430 --> 00:21:42.190 align:middle line:84%
>>NOORY: Just like,
give it to them?

00:21:42.190 --> 00:21:42.990 align:middle line:90%
>>OSTMAN: Exactly.

00:21:42.990 --> 00:21:45.532 align:middle line:84%
And there's very
credible scenarios.

00:21:45.532 --> 00:21:47.490 align:middle line:84%
I've actually worked on
these scenarios myself.

00:21:47.490 --> 00:21:50.150 align:middle line:84%
Part of my think
tank job in the past

00:21:50.150 --> 00:21:51.850 align:middle line:84%
has been to do exactly
this, to come up

00:21:51.850 --> 00:21:53.320 align:middle line:90%
with these option matrices.

00:21:53.320 --> 00:21:56.294 align:middle line:84%
To say, given the criteria,
these events occurring,

00:21:56.294 --> 00:21:57.960 align:middle line:84%
given the range of
options to work with,

00:21:57.960 --> 00:21:59.860 align:middle line:84%
what's your best
potential response,

00:21:59.860 --> 00:22:01.700 align:middle line:90%
given these variables?

00:22:01.700 --> 00:22:03.770 align:middle line:84%
Those were the people
trying to work this out.

00:22:03.770 --> 00:22:07.010 align:middle line:84%
But in this realm, the
scale of complexity

00:22:07.010 --> 00:22:08.860 align:middle line:84%
and the pace of
change is so extreme,

00:22:08.860 --> 00:22:12.120 align:middle line:84%
that it transcends what people
can even do effectively.

00:22:12.120 --> 00:22:16.240 align:middle line:84%
You almost have to surrender to
an artificial-intelligence-like

00:22:16.240 --> 00:22:19.920 align:middle line:84%
living thing, that can take
over in those situations.

00:22:19.920 --> 00:22:22.190 align:middle line:90%
>>NOORY: Are we going too fast?

00:22:22.190 --> 00:22:23.410 align:middle line:90%
>>OSTMAN: We might be.

00:22:23.410 --> 00:22:27.140 align:middle line:84%
I will submit to you the idea--
and you may see differently,

00:22:27.140 --> 00:22:29.660 align:middle line:84%
but it's just a thought--
I think this has

00:22:29.660 --> 00:22:31.180 align:middle line:90%
happened in many other worlds.

00:22:31.180 --> 00:22:32.060 align:middle line:90%
This is common.

00:22:32.060 --> 00:22:33.524 align:middle line:90%
This is not that unusual.

00:22:33.524 --> 00:22:34.690 align:middle line:90%
>>NOORY: It's the evolution.

00:22:34.690 --> 00:22:36.000 align:middle line:84%
>>OSTMAN: It's the
evolutionary process.

00:22:36.000 --> 00:22:37.540 align:middle line:84%
I tend to view
evolution as a sort

00:22:37.540 --> 00:22:39.970 align:middle line:84%
of a trauma-induced
mechanism, as it were.

00:22:39.970 --> 00:22:44.340 align:middle line:84%
And provided that the
periodicity or the cycle time

00:22:44.340 --> 00:22:47.920 align:middle line:84%
and the extremes of the trauma
cycles aren't too severe,

00:22:47.920 --> 00:22:50.660 align:middle line:84%
the system in question can
respond and adapt accordingly.

00:22:50.660 --> 00:22:53.630 align:middle line:84%
Or it may be perishes, and
then something else comes in.

00:22:53.630 --> 00:22:56.290 align:middle line:84%
So in other worlds, you
have a life form hominid

00:22:56.290 --> 00:22:59.750 align:middle line:84%
or something else that says,
many millennia to slowly figure

00:22:59.750 --> 00:23:00.550 align:middle line:90%
out what to do.

00:23:00.550 --> 00:23:03.985 align:middle line:84%
And they become more organized,
certain technology points

00:23:03.985 --> 00:23:04.860 align:middle line:90%
happen along the way.

00:23:04.860 --> 00:23:07.620 align:middle line:84%
And then there's a sudden burst,
radical change in population

00:23:07.620 --> 00:23:10.220 align:middle line:84%
density, many technologies
synergistically

00:23:10.220 --> 00:23:11.810 align:middle line:84%
interact each other--
nanotechnology

00:23:11.810 --> 00:23:14.310 align:middle line:84%
being a good example-- where
all of a sudden, the life

00:23:14.310 --> 00:23:16.310 align:middle line:84%
form in question-- within
a handful of decades--

00:23:16.310 --> 00:23:19.150 align:middle line:84%
has the capacity to
change the planet,

00:23:19.150 --> 00:23:24.220 align:middle line:84%
change itself, go through all
these radical disruptive--

00:23:24.220 --> 00:23:26.750 align:middle line:84%
if you will--
technology moments.

00:23:26.750 --> 00:23:29.280 align:middle line:84%
And then they
either successively

00:23:29.280 --> 00:23:33.140 align:middle line:84%
figure out what to do
next, or it fails and goes

00:23:33.140 --> 00:23:33.940 align:middle line:90%
into remission.

00:23:33.940 --> 00:23:35.550 align:middle line:84%
And eventually
something else comes in.

00:23:35.550 --> 00:23:37.424 align:middle line:84%
I think we're at one of
those thresholds now.

00:23:37.424 --> 00:23:38.290 align:middle line:90%
That's how I see it.

00:23:38.290 --> 00:23:40.100 align:middle line:84%
>>NOORY: In your
opinion, Charles,

00:23:40.100 --> 00:23:44.230 align:middle line:84%
is all this technology--
nanotechnology

00:23:44.230 --> 00:23:48.060 align:middle line:84%
artificial technology--
is that all good for us?

00:23:48.060 --> 00:23:50.764 align:middle line:84%
Are you glad we're
going this way?

00:23:50.764 --> 00:23:52.180 align:middle line:84%
>>OSTMAN: I'm not
saying I'm glad.

00:23:52.180 --> 00:23:53.870 align:middle line:84%
I'm just saying,
it's inevitable.

00:23:53.870 --> 00:23:57.140 align:middle line:84%
It's the natural,
organic way of things.

00:23:57.140 --> 00:23:59.090 align:middle line:90%
I know that sounds a bit odd.

00:23:59.090 --> 00:24:02.320 align:middle line:84%
But people often
argue about the tools.

00:24:02.320 --> 00:24:05.490 align:middle line:84%
They're so dangerous and
they're so evil and conflicting

00:24:05.490 --> 00:24:06.930 align:middle line:90%
with organic ways of being.

00:24:06.930 --> 00:24:08.700 align:middle line:90%
No, wrong answer.

00:24:08.700 --> 00:24:11.240 align:middle line:84%
Developing better
tools is what happens

00:24:11.240 --> 00:24:12.526 align:middle line:90%
in an evolutionary process.

00:24:12.526 --> 00:24:14.400 align:middle line:84%
We just happen to be
the organism in question

00:24:14.400 --> 00:24:17.470 align:middle line:84%
that, given a range of time and
the events that have happened,

00:24:17.470 --> 00:24:19.000 align:middle line:90%
OK we made our better tool box.

00:24:19.000 --> 00:24:21.250 align:middle line:84%
This reminds me,
actually-- speaking

00:24:21.250 --> 00:24:23.380 align:middle line:84%
of films-- in "2011:
Space Odyssey,"

00:24:23.380 --> 00:24:25.360 align:middle line:84%
in the very opening
scene, there are

00:24:25.360 --> 00:24:27.840 align:middle line:84%
the quasi-hominid
ape-like entities.

00:24:27.840 --> 00:24:30.610 align:middle line:84%
And they're sitting there,
having their arguments.

00:24:30.610 --> 00:24:32.860 align:middle line:84%
Then one of them comes up
and touches the obelisk.

00:24:32.860 --> 00:24:33.730 align:middle line:90%
>>NOORY: Yeah.

00:24:33.730 --> 00:24:34.990 align:middle line:84%
>>OSTMAN: And all of
a sudden-- presto.

00:24:34.990 --> 00:24:35.520 align:middle line:90%
>>NOORY: Bing.

00:24:35.520 --> 00:24:36.740 align:middle line:90%
>>OSTMAN: Something happens.

00:24:36.740 --> 00:24:39.736 align:middle line:84%
The first thing he
does, picks up a bone,

00:24:39.736 --> 00:24:41.860 align:middle line:84%
and bangs it in the head
of his neighbor as they're

00:24:41.860 --> 00:24:43.799 align:middle line:90%
fighting for a pond of water.

00:24:43.799 --> 00:24:46.090 align:middle line:84%
Then he throws the bone up
in the air and spins around.

00:24:46.090 --> 00:24:49.420 align:middle line:84%
And all of a sudden you have
the orbiting spacecraft.

00:24:49.420 --> 00:24:52.120 align:middle line:84%
Well, that was an
evolutionary tool.

00:24:52.120 --> 00:24:53.270 align:middle line:90%
That's what we have now.

00:24:53.270 --> 00:24:55.530 align:middle line:84%
We're at the point where
the bone's spinning around.

00:24:55.530 --> 00:24:57.570 align:middle line:90%
Suddenly there's a spacecraft.

00:24:57.570 --> 00:25:01.160 align:middle line:84%
At a certain point, you have
to step back and say, OK,

00:25:01.160 --> 00:25:03.850 align:middle line:84%
are they going to make it
past this next evolutionary

00:25:03.850 --> 00:25:05.160 align:middle line:90%
challenge or not?

00:25:05.160 --> 00:25:08.980 align:middle line:84%
I would submit to you that if
life is common-- I think it is.

00:25:08.980 --> 00:25:10.170 align:middle line:90%
Is intelligent life common?

00:25:10.170 --> 00:25:11.360 align:middle line:90%
I think it is.

00:25:11.360 --> 00:25:13.470 align:middle line:84%
I think we're just a
dot on a giant map.

00:25:13.470 --> 00:25:17.430 align:middle line:84%
We're like a grain of
sand in the cosmic ocean.

00:25:17.430 --> 00:25:19.740 align:middle line:84%
I would guess the
majority of worlds

00:25:19.740 --> 00:25:21.780 align:middle line:84%
have probably gone
through multiple stages

00:25:21.780 --> 00:25:24.400 align:middle line:84%
like this, where they get
to a certain threshold,

00:25:24.400 --> 00:25:25.200 align:middle line:90%
then there's chaos.

00:25:25.200 --> 00:25:26.574 align:middle line:84%
Then something
terrible happens--

00:25:26.574 --> 00:25:29.140 align:middle line:84%
a war or a biological
event or something.

00:25:29.140 --> 00:25:30.450 align:middle line:90%
Everything goes in remission.

00:25:30.450 --> 00:25:32.330 align:middle line:84%
Chaos, and then something
eventually comes up

00:25:32.330 --> 00:25:35.460 align:middle line:84%
out of the noise floor,
and a new thing appears.

00:25:35.460 --> 00:25:37.040 align:middle line:90%
We may not be that unique.

00:25:37.040 --> 00:25:40.860 align:middle line:84%
I think we're more way in the
middle, like, the average.

00:25:40.860 --> 00:25:43.720 align:middle line:84%
I don't take a human-centric
way of looking at the universe.

00:25:43.720 --> 00:25:47.120 align:middle line:84%
I see us more as just a
momentary blip in a larger

00:25:47.120 --> 00:25:48.700 align:middle line:90%
cosmology of things.

00:25:48.700 --> 00:25:51.110 align:middle line:84%
But what is interesting
is we are at that point

00:25:51.110 --> 00:25:53.745 align:middle line:84%
now-- more than any other
point in time that we know of,

00:25:53.745 --> 00:25:56.730 align:middle line:84%
at least here-- we are at that
very critical mass threshold,

00:25:56.730 --> 00:25:58.990 align:middle line:84%
where we're going to determine
how we proceed forward

00:25:58.990 --> 00:26:01.030 align:middle line:90%
or stay in remission.

00:26:01.030 --> 00:26:03.230 align:middle line:84%
>>NOORY: Will this
technology, Charles,

00:26:03.230 --> 00:26:06.655 align:middle line:84%
get us closer to that
answer of who are we?

00:26:06.655 --> 00:26:07.455 align:middle line:90%
What are we?

00:26:07.455 --> 00:26:08.820 align:middle line:90%
What is God?

00:26:08.820 --> 00:26:09.970 align:middle line:90%
How'd we get here?

00:26:09.970 --> 00:26:10.770 align:middle line:90%
>>OSTMAN: Yes.

00:26:10.770 --> 00:26:14.020 align:middle line:84%
I think we have the potential
of applying it that way.

00:26:14.020 --> 00:26:17.020 align:middle line:84%
And sadly-- and I say this
very, very gently-- even

00:26:17.020 --> 00:26:19.460 align:middle line:84%
today, given all of the
range of different belief

00:26:19.460 --> 00:26:24.580 align:middle line:84%
systems, religious orientations,
cultural orientations, etc,

00:26:24.580 --> 00:26:27.450 align:middle line:84%
we are far-- in my
opinion-- from having

00:26:27.450 --> 00:26:30.470 align:middle line:84%
the spiritual maturity-- to
use a better choice of words--

00:26:30.470 --> 00:26:33.440 align:middle line:84%
to match the rate of
technological change.

00:26:33.440 --> 00:26:35.190 align:middle line:84%
I see it like two
lines in a graph.

00:26:35.190 --> 00:26:37.730 align:middle line:84%
The technological change is
a vertical line like this.

00:26:37.730 --> 00:26:40.320 align:middle line:84%
And the spiritual maturity
nexus, somewhere down here.

00:26:40.320 --> 00:26:43.030 align:middle line:84%
In my opinion, if we're going
to have a chance, at least,

00:26:43.030 --> 00:26:44.590 align:middle line:84%
of getting past
this next point, you

00:26:44.590 --> 00:26:47.100 align:middle line:84%
want to see those two lines
coming closer together.

00:26:47.100 --> 00:26:49.872 align:middle line:84%
I don't know how close we
can get those lines together.

00:26:49.872 --> 00:26:50.955 align:middle line:90%
To me, that's a gray zone.

00:26:50.955 --> 00:26:52.288 align:middle line:90%
I don't know what the answer is.

00:26:52.288 --> 00:26:54.644 align:middle line:84%
>>NOORY: Soldiers-- will
they all be robots one day?

00:26:54.644 --> 00:26:56.060 align:middle line:84%
>>OSTMAN: I think
it's inevitable.

00:26:56.060 --> 00:26:57.680 align:middle line:84%
I think at this very
moment-- speaking

00:26:57.680 --> 00:26:59.054 align:middle line:84%
of artificial
intelligence-- this

00:26:59.054 --> 00:27:01.510 align:middle line:84%
was sort of the
latest news blip--

00:27:01.510 --> 00:27:06.170 align:middle line:84%
the area where AI is really
is being put in the fast lane

00:27:06.170 --> 00:27:07.560 align:middle line:90%
is in flying machinery.

00:27:07.560 --> 00:27:11.120 align:middle line:84%
The whole idea that fighter
pilots are being pushed

00:27:11.120 --> 00:27:13.140 align:middle line:84%
to ever-more-challenging
conditions--

00:27:13.140 --> 00:27:15.526 align:middle line:84%
when they fly the plane
they go into multiple G's.

00:27:15.526 --> 00:27:16.900 align:middle line:84%
They have to
respond very quickly

00:27:16.900 --> 00:27:19.130 align:middle line:84%
to multiple threats,
that kind of thing--

00:27:19.130 --> 00:27:21.330 align:middle line:84%
it's already far
beyond human capacity.

00:27:21.330 --> 00:27:24.610 align:middle line:84%
The machinery outpaces
the human pilots.

00:27:24.610 --> 00:27:26.200 align:middle line:84%
So just a couple
of weeks ago, there

00:27:26.200 --> 00:27:28.480 align:middle line:84%
was, essentially,
a virtual dogfight

00:27:28.480 --> 00:27:30.770 align:middle line:84%
where it was the AI
versus the human pilot.

00:27:30.770 --> 00:27:32.160 align:middle line:90%
And the AI won.

00:27:32.160 --> 00:27:33.592 align:middle line:90%
Now, this is what was published.

00:27:33.592 --> 00:27:35.800 align:middle line:84%
But I can tell you, from
behind-the-scenes knowledge,

00:27:35.800 --> 00:27:37.160 align:middle line:84%
that this has been going
on for a long time.

00:27:37.160 --> 00:27:38.500 align:middle line:84%
And pilots that I
know personally,

00:27:38.500 --> 00:27:39.790 align:middle line:84%
they tell me oh yeah, it's
just a matter of years

00:27:39.790 --> 00:27:41.460 align:middle line:84%
before there won't
be any pilots.

00:27:41.460 --> 00:27:43.260 align:middle line:84%
It'll all be machinery
flying around.

00:27:43.260 --> 00:27:46.320 align:middle line:84%
>>NOORY: Well, I remember
as a younger person,

00:27:46.320 --> 00:27:52.990 align:middle line:84%
the big thing was chess masters
playing the big IBM computer.

00:27:52.990 --> 00:27:53.940 align:middle line:90%
Who would win?

00:27:53.940 --> 00:27:54.740 align:middle line:90%
>>OSTMAN: Right.

00:27:54.740 --> 00:27:56.323 align:middle line:84%
>>NOORY: To me, that
was the beginning

00:27:56.323 --> 00:27:58.090 align:middle line:90%
of artificial intelligence.

00:27:58.090 --> 00:28:01.430 align:middle line:84%
And then it just got better
and better and better.

00:28:01.430 --> 00:28:04.390 align:middle line:84%
>>OSTMAN: Well, more robust,
more biological in nature,

00:28:04.390 --> 00:28:06.260 align:middle line:90%
more evolutionary, if I may.

00:28:06.260 --> 00:28:10.240 align:middle line:84%
And in fact, there's several
products out there now--

00:28:10.240 --> 00:28:13.480 align:middle line:84%
the front end of this-- there's
something called ROSS, R-O-S-S.

00:28:13.480 --> 00:28:16.510 align:middle line:84%
And this is the first time
ever it's publicly available.

00:28:16.510 --> 00:28:18.320 align:middle line:84%
This is the Watson
IBM supercomputer.

00:28:18.320 --> 00:28:20.300 align:middle line:84%
And now you, George,
if you wanted to,

00:28:20.300 --> 00:28:23.050 align:middle line:84%
you could sort of purchase
your own ROSS account.

00:28:23.050 --> 00:28:26.110 align:middle line:84%
What this would do for you is it
would let you extend your mind

00:28:26.110 --> 00:28:27.730 align:middle line:90%
into this other realm.

00:28:27.730 --> 00:28:29.510 align:middle line:84%
It becomes like a
personal assistant,

00:28:29.510 --> 00:28:31.350 align:middle line:90%
but a smart personal assistant.

00:28:31.350 --> 00:28:34.970 align:middle line:84%
And the first virtual attorneys
are now coming to light,

00:28:34.970 --> 00:28:36.706 align:middle line:90%
with this mechanism.

00:28:36.706 --> 00:28:38.080 align:middle line:84%
The next big thing
is going to be

00:28:38.080 --> 00:28:40.090 align:middle line:84%
a virtual middle-level
management.

00:28:40.090 --> 00:28:42.382 align:middle line:84%
In the corporate world,
you have lots and lots

00:28:42.382 --> 00:28:44.090 align:middle line:84%
of middle-management
people who interface

00:28:44.090 --> 00:28:47.335 align:middle line:84%
between the high-in-positions
making the general workplace

00:28:47.335 --> 00:28:48.490 align:middle line:90%
of what's going on.

00:28:48.490 --> 00:28:49.290 align:middle line:90%
Ah.

00:28:49.290 --> 00:28:50.030 align:middle line:90%
>>NOORY: Gone, right?

00:28:50.030 --> 00:28:50.580 align:middle line:90%
>>OSTMAN: That's it.

00:28:50.580 --> 00:28:51.440 align:middle line:90%
Exactly.

00:28:51.440 --> 00:28:51.960 align:middle line:90%
>>NOORY: Scary.

00:28:51.960 --> 00:28:52.860 align:middle line:84%
>>OSTMAN: And I'm not
saying this is good or bad.

00:28:52.860 --> 00:28:54.510 align:middle line:84%
I'm just saying,
this is what is.

00:28:54.510 --> 00:28:57.070 align:middle line:84%
So in that context,
trying to render

00:28:57.070 --> 00:29:00.280 align:middle line:84%
ever-more complex
mission-critical decisions

00:29:00.280 --> 00:29:02.960 align:middle line:84%
compressed into
ever-shorter time scales--

00:29:02.960 --> 00:29:04.960 align:middle line:84%
there is something called
psychological noise,

00:29:04.960 --> 00:29:08.844 align:middle line:84%
which interferes with the
better range of choices.

00:29:08.844 --> 00:29:11.010 align:middle line:84%
So not just because it's a
way to get rid of workers

00:29:11.010 --> 00:29:13.551 align:middle line:84%
and not pay them anything, it's
actually seen as a better way

00:29:13.551 --> 00:29:16.870 align:middle line:84%
to get better decision rendering
under these complex condition

00:29:16.870 --> 00:29:17.720 align:middle line:90%
sets.

00:29:17.720 --> 00:29:20.237 align:middle line:84%
And this is just
the consumer edge.

00:29:20.237 --> 00:29:22.570 align:middle line:84%
I can tell you that from a
different point of view, more

00:29:22.570 --> 00:29:25.840 align:middle line:84%
in the military strategic
world, this is very much

00:29:25.840 --> 00:29:28.000 align:middle line:90%
going in that direction.

00:29:28.000 --> 00:29:29.880 align:middle line:84%
>>NOORY: That's kind
of scary, though.

00:29:29.880 --> 00:29:33.170 align:middle line:84%
>>OSTMAN: Like the Skynet
version, when the system

00:29:33.170 --> 00:29:37.010 align:middle line:84%
itself thinks OK, the humans are
no longer capable of rendering

00:29:37.010 --> 00:29:37.980 align:middle line:90%
appropriate decisions.

00:29:37.980 --> 00:29:40.090 align:middle line:84%
I need to take over
to prevent this

00:29:40.090 --> 00:29:41.510 align:middle line:90%
perceived-- whatever it is.

00:29:41.510 --> 00:29:42.260 align:middle line:84%
>>NOORY: Prevent
mistakes, right?

00:29:42.260 --> 00:29:43.385 align:middle line:90%
>>OSTMAN: Prevent mistakes.

00:29:43.385 --> 00:29:47.540 align:middle line:84%
And then you get into the role
of define mistake, or define

00:29:47.540 --> 00:29:51.040 align:middle line:84%
ethics, or define
moral imperative.

00:29:51.040 --> 00:29:53.037 align:middle line:84%
And one of the things
I've said for many years,

00:29:53.037 --> 00:29:54.870 align:middle line:84%
when people ask me these
kinds of questions,

00:29:54.870 --> 00:29:57.060 align:middle line:84%
is if you're coming
up with systems

00:29:57.060 --> 00:29:59.810 align:middle line:84%
that learn from
what they encounter,

00:29:59.810 --> 00:30:02.550 align:middle line:84%
what they learn is what they
see from our interactions

00:30:02.550 --> 00:30:03.350 align:middle line:90%
with them.

00:30:03.350 --> 00:30:06.460 align:middle line:84%
So if a majority of
humans tend to have

00:30:06.460 --> 00:30:10.400 align:middle line:84%
somewhat predatory
less-than-pleasant ways

00:30:10.400 --> 00:30:12.520 align:middle line:84%
of looking at the
world, as it were,

00:30:12.520 --> 00:30:14.380 align:middle line:90%
that's what the AI learns.

00:30:14.380 --> 00:30:17.030 align:middle line:84%
And that's what it
determines to respond to.

00:30:17.030 --> 00:30:19.340 align:middle line:84%
And it will evolve and
adapt to figure out ways

00:30:19.340 --> 00:30:21.680 align:middle line:84%
around those negative
behaviors, by whatever

00:30:21.680 --> 00:30:23.301 align:middle line:90%
means it deems are necessary.

00:30:23.301 --> 00:30:24.550 align:middle line:90%
And that's exactly what it is.

00:30:24.550 --> 00:30:27.190 align:middle line:84%
It's not so much that
people are going to invent

00:30:27.190 --> 00:30:29.150 align:middle line:90%
these horrible, evil machines.

00:30:29.150 --> 00:30:31.850 align:middle line:84%
But the machines will
learn from what they see.

00:30:31.850 --> 00:30:35.250 align:middle line:84%
And if they perceive really
bad behavior-- for a better

00:30:35.250 --> 00:30:37.500 align:middle line:84%
choice of words--
then they'll adapt

00:30:37.500 --> 00:30:39.889 align:middle line:90%
to respond to that accordingly.

00:30:39.889 --> 00:30:41.430 align:middle line:84%
>>NOORY: Charles,
we had some emails,

00:30:41.430 --> 00:30:44.140 align:middle line:84%
and some folks want to know--
Sandra, from Tennessee,

00:30:44.140 --> 00:30:48.030 align:middle line:84%
for example-- "Do you see a
time when our police forces will

00:30:48.030 --> 00:30:50.137 align:middle line:90%
be made up entirely of robots?"

00:30:50.137 --> 00:30:51.470 align:middle line:90%
Now, that's an interesting take.

00:30:51.470 --> 00:30:54.440 align:middle line:84%
>>OSTMAN: Maybe not entirely,
but certainly as an assist.

00:30:54.440 --> 00:30:56.534 align:middle line:84%
I absolutely can see a
range of applications.

00:30:56.534 --> 00:30:58.450 align:middle line:84%
>>NOORY: Well, we have
robotics now in police.

00:30:58.450 --> 00:30:59.570 align:middle line:90%
>>OSTMAN: We have robotics now.

00:30:59.570 --> 00:31:00.930 align:middle line:84%
And it's just a matter
of expanding that rate.

00:31:00.930 --> 00:31:02.410 align:middle line:84%
>>NOORY: They detonate
bombs and everything else.

00:31:02.410 --> 00:31:03.785 align:middle line:84%
>>OSTMAN: Correct,
exactly right.

00:31:03.785 --> 00:31:07.210 align:middle line:84%
In fact-- horrible to say this,
but-- the mass shooter that we

00:31:07.210 --> 00:31:10.570 align:middle line:84%
just had, where he shot several
people from the parking lot,

00:31:10.570 --> 00:31:12.790 align:middle line:84%
the way he was killed was
they sent a little robot

00:31:12.790 --> 00:31:15.090 align:middle line:84%
up there that essentially
blew up and killed him off.

00:31:15.090 --> 00:31:16.420 align:middle line:90%
And that was a good thing.

00:31:16.420 --> 00:31:17.220 align:middle line:90%
I'm very glad.

00:31:17.220 --> 00:31:18.180 align:middle line:84%
I mean, it was
horrible, what happened.

00:31:18.180 --> 00:31:19.040 align:middle line:90%
>>NOORY: Sure.

00:31:19.040 --> 00:31:20.690 align:middle line:84%
>>OSTMAN: But that's
a beginning edge

00:31:20.690 --> 00:31:22.967 align:middle line:90%
of a larger range of things.

00:31:22.967 --> 00:31:24.800 align:middle line:84%
As I was mentioning
earlier, Boston Dynamics

00:31:24.800 --> 00:31:27.000 align:middle line:84%
has the smart
animals, as it were,

00:31:27.000 --> 00:31:28.500 align:middle line:84%
that are used to
go out in the field

00:31:28.500 --> 00:31:31.530 align:middle line:84%
and carry packs and other
military equipment, and also

00:31:31.530 --> 00:31:35.430 align:middle line:84%
smart devices to, in fact,
shoot at or neutralize

00:31:35.430 --> 00:31:36.660 align:middle line:90%
incoming enemies.

00:31:36.660 --> 00:31:39.920 align:middle line:84%
So is a non-militarized
version of that going

00:31:39.920 --> 00:31:41.170 align:middle line:90%
to be available to the police?

00:31:41.170 --> 00:31:41.780 align:middle line:90%
I think so.

00:31:41.780 --> 00:31:42.520 align:middle line:90%
I think it's inevitable.

00:31:42.520 --> 00:31:44.620 align:middle line:84%
And if we see more of
these kinds of events--

00:31:44.620 --> 00:31:46.350 align:middle line:84%
and I think we
probably will-- it's

00:31:46.350 --> 00:31:48.850 align:middle line:84%
going to become a
matter of numbers.

00:31:48.850 --> 00:31:51.050 align:middle line:84%
At what threshold is
it the better choice

00:31:51.050 --> 00:31:54.326 align:middle line:84%
to have fewer officers
being killed or threatened,

00:31:54.326 --> 00:31:56.700 align:middle line:84%
and simply let the machines
take on the more risky roles?

00:31:56.700 --> 00:32:00.930 align:middle line:84%
I think it's a very
fathomable threshold to reach.

00:32:00.930 --> 00:32:03.850 align:middle line:84%
>>NOORY: How much of this
technology is secret?

00:32:03.850 --> 00:32:06.250 align:middle line:84%
Is part of secret
government programs?

00:32:06.250 --> 00:32:09.000 align:middle line:84%
Let's take a look at
this from "Deep Space"

00:32:09.000 --> 00:32:11.975 align:middle line:90%
documentary, "One".

00:32:11.975 --> 00:32:13.890 align:middle line:10%
>>BILLY CARSON: I
feel that NASA is

00:32:13.890 --> 00:32:17.124 align:middle line:10%
using private space and
private industry as a cover up.

00:32:17.124 --> 00:32:18.540 align:middle line:10%
And the reason why
is because when

00:32:18.540 --> 00:32:21.650 align:middle line:10%
you take everything out of
governmental into private,

00:32:21.650 --> 00:32:23.690 align:middle line:10%
you can do a lot more
things behind the scenes.

00:32:23.690 --> 00:32:25.840 align:middle line:84%
And you don't have
to answer to anybody.

00:32:25.840 --> 00:32:29.660 align:middle line:84%
>>I feel like anytime NASA's
involved, I'm very suspicious.

00:32:29.660 --> 00:32:31.210 align:middle line:84%
Because I don't
trust them, based

00:32:31.210 --> 00:32:32.920 align:middle line:84%
on my research and
years of experience

00:32:32.920 --> 00:32:34.360 align:middle line:90%
in dealing with them.

00:32:34.360 --> 00:32:36.500 align:middle line:84%
I don't trust them
on political issues.

00:32:36.500 --> 00:32:39.350 align:middle line:84%
And I worry that they're
going to somehow undermine

00:32:39.350 --> 00:32:41.540 align:middle line:84%
the private company
and undermine SpaceX.

00:32:41.540 --> 00:32:44.380 align:middle line:84%
>>Waiting operator's moving to
procedure 11.100 on recovering

00:32:44.380 --> 00:32:45.180 align:middle line:90%
that.

00:32:45.180 --> 00:32:50.559 align:middle line:90%


00:32:50.559 --> 00:32:52.350 align:middle line:10%
>>RICHARD DOLAN: You
think of it this way--

00:32:52.350 --> 00:32:54.970 align:middle line:10%
the United States, a
couple of years ago,

00:32:54.970 --> 00:32:58.180 align:middle line:10%
made some public
statement that well, we're

00:32:58.180 --> 00:33:02.060 align:middle line:10%
eliminating the manned
component of our space program.

00:33:02.060 --> 00:33:04.475 align:middle line:84%
Not only is it untrue, but
it makes absolutely no sense.

00:33:04.475 --> 00:33:09.540 align:middle line:84%
The United States, for it to be
the dominant global hegemonic

00:33:09.540 --> 00:33:13.330 align:middle line:84%
power-- which it will never
voluntarily cease to be--

00:33:13.330 --> 00:33:16.940 align:middle line:84%
must control space as a
platform of operations.

00:33:16.940 --> 00:33:19.830 align:middle line:84%
This means having
classified space programs

00:33:19.830 --> 00:33:23.375 align:middle line:84%
at a military base as
an absolute priority.

00:33:23.375 --> 00:33:25.500 align:middle line:84%
>>NOORY: Charles, that's
our friend, Richard Dolan,

00:33:25.500 --> 00:33:28.620 align:middle line:84%
of course, talking about a
secret shadowy government

00:33:28.620 --> 00:33:30.080 align:middle line:90%
program.

00:33:30.080 --> 00:33:30.944 align:middle line:90%
That's going on.

00:33:30.944 --> 00:33:32.110 align:middle line:90%
There's no doubt about that.

00:33:32.110 --> 00:33:32.420 align:middle line:90%
>>OSTMAN: Yeah, absolutely.

00:33:32.420 --> 00:33:33.680 align:middle line:90%
>>NOORY: Is it necessary?

00:33:33.680 --> 00:33:35.320 align:middle line:84%
>>OSTMAN: I think
it is necessary.

00:33:35.320 --> 00:33:37.570 align:middle line:84%
But the reason you may
or may not agree with.

00:33:37.570 --> 00:33:39.490 align:middle line:90%
But it's just how I see it.

00:33:39.490 --> 00:33:42.140 align:middle line:84%
As I was saying earlier,
we're stepping into an era

00:33:42.140 --> 00:33:45.780 align:middle line:84%
where the complexity
and pace of change

00:33:45.780 --> 00:33:48.750 align:middle line:84%
is so extreme, that
even for people

00:33:48.750 --> 00:33:53.900 align:middle line:84%
who are very educated and very
adept at learning new things,

00:33:53.900 --> 00:33:56.230 align:middle line:84%
this is going beyond
way beyond the capacity

00:33:56.230 --> 00:33:59.790 align:middle line:84%
for the average population to
really process in real time

00:33:59.790 --> 00:34:03.020 align:middle line:84%
and actually understand
what we're dealing with.

00:34:03.020 --> 00:34:05.410 align:middle line:84%
So in a certain way
of looking at things,

00:34:05.410 --> 00:34:09.679 align:middle line:84%
it may actually be appropriate
to have a realm of development

00:34:09.679 --> 00:34:14.850 align:middle line:84%
which simply does not have to be
confined by public acceptance.

00:34:14.850 --> 00:34:16.380 align:middle line:90%
And I know that sounds strange.

00:34:16.380 --> 00:34:16.800 align:middle line:90%
>>NOORY: I understand.

00:34:16.800 --> 00:34:19.310 align:middle line:84%
>>OSTMAN: I understand where
that lex sounds kind of dark.

00:34:19.310 --> 00:34:20.624 align:middle line:90%
But I understand this.

00:34:20.624 --> 00:34:22.790 align:middle line:84%
And I'm not saying it's a
good thing or a bad thing.

00:34:22.790 --> 00:34:24.679 align:middle line:90%
It's just how it is.

00:34:24.679 --> 00:34:26.860 align:middle line:84%
Obviously, as one
can imagine, this

00:34:26.860 --> 00:34:30.440 align:middle line:84%
can be used in a very bad
way, to take advantage

00:34:30.440 --> 00:34:34.340 align:middle line:84%
of that resource base, and go
in directions the public would

00:34:34.340 --> 00:34:35.840 align:middle line:90%
never agree with.

00:34:35.840 --> 00:34:39.667 align:middle line:84%
But I think even right now, in
just general information areas

00:34:39.667 --> 00:34:41.500 align:middle line:84%
that we were talking
about-- nanotechnology,

00:34:41.500 --> 00:34:43.929 align:middle line:84%
medical modification,
genetic modification,

00:34:43.929 --> 00:34:46.620 align:middle line:84%
neural enhancements--
just those kinds of things

00:34:46.620 --> 00:34:49.340 align:middle line:84%
are complex enough
to where if it

00:34:49.340 --> 00:34:52.107 align:middle line:84%
had to be up to a general
population's interaction

00:34:52.107 --> 00:34:54.440 align:middle line:84%
with the process, it would
probably never really happen.

00:34:54.440 --> 00:34:56.606 align:middle line:84%
At least, not happen in a
way that would make sense.

00:34:56.606 --> 00:34:58.680 align:middle line:84%
>>NOORY: I think if the
public, Charles, knew

00:34:58.680 --> 00:35:02.390 align:middle line:84%
what kind of technology
we really had,

00:35:02.390 --> 00:35:03.412 align:middle line:90%
they'd be blown away.

00:35:03.412 --> 00:35:04.870 align:middle line:84%
>>OSTMAN: They
would be blown away.

00:35:04.870 --> 00:35:07.687 align:middle line:84%
And I personally feel
strongly that a lot

00:35:07.687 --> 00:35:09.770 align:middle line:84%
of the problems that we're
facing in today's world

00:35:09.770 --> 00:35:11.670 align:middle line:84%
would be very
different if we had

00:35:11.670 --> 00:35:13.470 align:middle line:90%
access to those technologies.

00:35:13.470 --> 00:35:16.930 align:middle line:84%
This is where I probably
have some thoughts.

00:35:16.930 --> 00:35:20.260 align:middle line:84%
Because I think these
things should be out there.

00:35:20.260 --> 00:35:22.570 align:middle line:84%
Alternative energy,
different types

00:35:22.570 --> 00:35:24.120 align:middle line:84%
of energy platforms,
which I think

00:35:24.120 --> 00:35:25.350 align:middle line:90%
should radically change the--

00:35:25.350 --> 00:35:25.695 align:middle line:90%
>>NOORY: Of course, yeah.

00:35:25.695 --> 00:35:26.340 align:middle line:84%
Medical treatments,
all kinds of things.

00:35:26.340 --> 00:35:28.410 align:middle line:84%
>>OSTMAN: Medical
treatments, exactly.

00:35:28.410 --> 00:35:30.770 align:middle line:84%
We could have a very
different, actually,

00:35:30.770 --> 00:35:35.170 align:middle line:84%
much better life if there
was more balanced access.

00:35:35.170 --> 00:35:38.630 align:middle line:84%
And I'm sorry to say, that
because of greed, perhaps,

00:35:38.630 --> 00:35:41.960 align:middle line:84%
or just hegemonic ways of
looking at things-- you know,

00:35:41.960 --> 00:35:42.940 align:middle line:90%
I want to control this.

00:35:42.940 --> 00:35:43.950 align:middle line:90%
And this is our little world.

00:35:43.950 --> 00:35:45.741 align:middle line:84%
And we're going to
change things to suit us

00:35:45.741 --> 00:35:48.160 align:middle line:84%
as opposed to the
larger world-- is

00:35:48.160 --> 00:35:51.670 align:middle line:84%
that a function of the
human condition that is

00:35:51.670 --> 00:35:53.700 align:middle line:84%
poisoning our
current civilization?

00:35:53.700 --> 00:35:54.500 align:middle line:90%
I would say so.

00:35:54.500 --> 00:35:56.300 align:middle line:84%
When I was talking
earlier about being

00:35:56.300 --> 00:35:58.600 align:middle line:84%
at an evolutionary
threshold, this

00:35:58.600 --> 00:36:00.720 align:middle line:84%
is the kind of thing
which may prevent us

00:36:00.720 --> 00:36:02.792 align:middle line:84%
from getting past
this next increment.

00:36:02.792 --> 00:36:04.750 align:middle line:84%
It's not so much the
technology question marks.

00:36:04.750 --> 00:36:06.630 align:middle line:90%
I think those are doable.

00:36:06.630 --> 00:36:08.970 align:middle line:84%
It's more of the
human condition that

00:36:08.970 --> 00:36:11.922 align:middle line:84%
shapes how these technologies
are allowed and presented

00:36:11.922 --> 00:36:12.880 align:middle line:90%
into the outside world.

00:36:12.880 --> 00:36:14.390 align:middle line:84%
>>NOORY: With so
many people working

00:36:14.390 --> 00:36:18.419 align:middle line:84%
on these secret projects,
how do they keep them secret?

00:36:18.419 --> 00:36:20.210 align:middle line:84%
>>OSTMAN: Actually,
it's surprisingly easy.

00:36:20.210 --> 00:36:23.550 align:middle line:84%
It seems difficult to imagine
from the outside world.

00:36:23.550 --> 00:36:26.290 align:middle line:84%
But having worked on some
of these things myself,

00:36:26.290 --> 00:36:28.030 align:middle line:90%
it's compartmentalized.

00:36:28.030 --> 00:36:31.860 align:middle line:84%
You're in a certain
zone of acceptance,

00:36:31.860 --> 00:36:36.260 align:middle line:84%
or whatever your credentials are
allowing you to get access to.

00:36:36.260 --> 00:36:39.970 align:middle line:84%
It's amazing, actually, how
these very complex situations

00:36:39.970 --> 00:36:43.280 align:middle line:84%
can be brought into
fruition, comprising

00:36:43.280 --> 00:36:45.750 align:middle line:84%
of lots of little nodes,
which all intersect together.

00:36:45.750 --> 00:36:48.090 align:middle line:84%
But the nodes are actually
kept very compartmentalized.

00:36:48.090 --> 00:36:51.260 align:middle line:84%
And there's a sort of
meta process of organizing

00:36:51.260 --> 00:36:54.616 align:middle line:84%
everything, so it comes out
with this larger-scale outcome.

00:36:54.616 --> 00:36:56.240 align:middle line:84%
But this has been
going on for decades.

00:36:56.240 --> 00:36:58.310 align:middle line:84%
It's a very
well-defined process.

00:36:58.310 --> 00:37:02.080 align:middle line:84%
>>NOORY: Beth from
Albuquerque wants to know--

00:37:02.080 --> 00:37:04.610 align:middle line:84%
"Are we in a shadow
government situation

00:37:04.610 --> 00:37:06.500 align:middle line:90%
because of other countries?"

00:37:06.500 --> 00:37:09.090 align:middle line:84%
>>OSTMAN: I think the word
government is, perhaps,

00:37:09.090 --> 00:37:10.240 align:middle line:90%
misleading.

00:37:10.240 --> 00:37:13.210 align:middle line:84%
I would look at more
transnational entities, that

00:37:13.210 --> 00:37:15.470 align:middle line:84%
are not really
defined by sovereignty

00:37:15.470 --> 00:37:17.450 align:middle line:84%
in their traditional
sense, that are more

00:37:17.450 --> 00:37:18.839 align:middle line:90%
defined by quasi govern--

00:37:18.839 --> 00:37:20.630 align:middle line:84%
>>NOORY: They've got
their own thing going.

00:37:20.630 --> 00:37:22.130 align:middle line:84%
>>OSTMAN: They have
their own thing.

00:37:22.130 --> 00:37:24.660 align:middle line:84%
And it's really
industry leaders,

00:37:24.660 --> 00:37:26.650 align:middle line:84%
people that come from
certain families that

00:37:26.650 --> 00:37:28.630 align:middle line:84%
have had traditional--
for many decades,

00:37:28.630 --> 00:37:31.960 align:middle line:84%
even centuries-- authoritative
influence on the world's

00:37:31.960 --> 00:37:35.440 align:middle line:84%
economies, that kind of thing,
mixed together with entities

00:37:35.440 --> 00:37:38.460 align:middle line:84%
from various governments that
filter into this mechanism.

00:37:38.460 --> 00:37:41.120 align:middle line:84%
But governments, in my mind,
are more like a surface veneer.

00:37:41.120 --> 00:37:46.440 align:middle line:84%
They're like a thin layer
of ice, or like an iceberg,

00:37:46.440 --> 00:37:49.150 align:middle line:84%
whereas the real iceberg is down
below the surface of the water.

00:37:49.150 --> 00:37:53.680 align:middle line:84%
And as I see it, these sorts
of government entities,

00:37:53.680 --> 00:37:55.640 align:middle line:84%
it would be wrong
to say, well, it's

00:37:55.640 --> 00:37:57.840 align:middle line:84%
the US government versus
some other entity.

00:37:57.840 --> 00:37:58.850 align:middle line:90%
>>NOORY: China, Russia.

00:37:58.850 --> 00:38:00.350 align:middle line:90%
>>OSTMAN: Right, exactly.

00:38:00.350 --> 00:38:03.640 align:middle line:84%
It's really oligarchs
and key players

00:38:03.640 --> 00:38:05.620 align:middle line:84%
that behind the scenes
actually interact

00:38:05.620 --> 00:38:07.772 align:middle line:84%
to suit their own agendas,
whatever those might be.

00:38:07.772 --> 00:38:09.480 align:middle line:84%
>>NOORY: Charles, I
want to talk with you

00:38:09.480 --> 00:38:11.820 align:middle line:84%
for a little bit about
weather manipulation,

00:38:11.820 --> 00:38:13.000 align:middle line:90%
and what's going on there.

00:38:13.000 --> 00:38:15.310 align:middle line:84%
Are you convinced
that governments

00:38:15.310 --> 00:38:17.400 align:middle line:90%
are manipulating the weather?

00:38:17.400 --> 00:38:20.390 align:middle line:84%
>>OSTMAN: Not only governments,
but private entities.

00:38:20.390 --> 00:38:22.000 align:middle line:84%
Like the film we
just saw, this is

00:38:22.000 --> 00:38:24.780 align:middle line:84%
another one of those examples,
where private entities can

00:38:24.780 --> 00:38:26.480 align:middle line:84%
pursue things that
are not confined

00:38:26.480 --> 00:38:31.370 align:middle line:84%
by the dictates of policy
or appropriate legislation

00:38:31.370 --> 00:38:33.050 align:middle line:90%
controls, that kind of thing.

00:38:33.050 --> 00:38:35.970 align:middle line:84%
And actually-- sorry
about the pun--

00:38:35.970 --> 00:38:39.100 align:middle line:84%
whether it's localized weather
phenomenon, the managing

00:38:39.100 --> 00:38:42.220 align:middle line:84%
of storms, let's say, or
preventing or encouraging

00:38:42.220 --> 00:38:43.870 align:middle line:84%
precipitation on
a localized basis,

00:38:43.870 --> 00:38:45.680 align:middle line:84%
or on a more planetary
scale, where there's

00:38:45.680 --> 00:38:47.179 align:middle line:84%
climate modification--
which I think

00:38:47.179 --> 00:38:49.410 align:middle line:84%
is the more important
issue, actually.

00:38:49.410 --> 00:38:53.050 align:middle line:84%
Again, this has gone far beyond
experimental or theoretical

00:38:53.050 --> 00:38:53.850 align:middle line:90%
ideas.

00:38:53.850 --> 00:38:55.920 align:middle line:84%
It's more in the
application area.

00:38:55.920 --> 00:38:59.260 align:middle line:84%
And it's entities that
say, we can deliver this.

00:38:59.260 --> 00:39:00.560 align:middle line:90%
Tell us what you need.

00:39:00.560 --> 00:39:01.960 align:middle line:90%
We'll make it happen.

00:39:01.960 --> 00:39:05.040 align:middle line:84%
Now, how that actually
gets put into practice,

00:39:05.040 --> 00:39:08.170 align:middle line:84%
one could argue the chain
of command, as it were.

00:39:08.170 --> 00:39:10.900 align:middle line:84%
But in a large scheme of
things, it's not really

00:39:10.900 --> 00:39:12.840 align:middle line:84%
dictated by a particular
government saying,

00:39:12.840 --> 00:39:13.910 align:middle line:90%
we want this to happen.

00:39:13.910 --> 00:39:16.810 align:middle line:84%
It's more like a consortium of
entities that have the capacity

00:39:16.810 --> 00:39:18.164 align:middle line:90%
to make it possible.

00:39:18.164 --> 00:39:19.080 align:middle line:90%
And they have clients.

00:39:19.080 --> 00:39:20.790 align:middle line:84%
And the clients pay
for those capacities.

00:39:20.790 --> 00:39:24.210 align:middle line:84%
>>NOORY: Do they manipulate
the weather because of warfare?

00:39:24.210 --> 00:39:27.200 align:middle line:84%
I mean, do they try to
create droughts in countries

00:39:27.200 --> 00:39:28.630 align:middle line:90%
to squeeze them?

00:39:28.630 --> 00:39:30.540 align:middle line:84%
>>OSTMAN: There is
a concept of what's

00:39:30.540 --> 00:39:32.560 align:middle line:84%
called-- and forgive the
buzzword-- asymmetrical

00:39:32.560 --> 00:39:33.360 align:middle line:90%
warfare.

00:39:33.360 --> 00:39:36.650 align:middle line:84%
Which means as opposed to
a traditional war, where

00:39:36.650 --> 00:39:39.680 align:middle line:84%
you have tanks and ships
and boots on the ground,

00:39:39.680 --> 00:39:42.042 align:middle line:84%
as a declared war,
and here's one enemy

00:39:42.042 --> 00:39:43.000 align:middle line:90%
versus the other enemy.

00:39:43.000 --> 00:39:44.500 align:middle line:84%
And they go at it
for a couple years

00:39:44.500 --> 00:39:46.430 align:middle line:84%
and then something happens
and that's the end,

00:39:46.430 --> 00:39:48.180 align:middle line:84%
this is a very
different kind of realm,

00:39:48.180 --> 00:39:50.890 align:middle line:84%
where it's more to do
with economic warfare

00:39:50.890 --> 00:39:52.630 align:middle line:90%
and geopolitical strategy.

00:39:52.630 --> 00:39:55.450 align:middle line:84%
Where over time, over a length
of years or even decades,

00:39:55.450 --> 00:39:58.220 align:middle line:84%
one can shift the
epicenters of power

00:39:58.220 --> 00:40:01.000 align:middle line:84%
from one realm to
the next because they

00:40:01.000 --> 00:40:03.990 align:middle line:84%
can do things like
inflict climate change

00:40:03.990 --> 00:40:05.110 align:middle line:90%
upon a given region.

00:40:05.110 --> 00:40:07.590 align:middle line:84%
Or they can inflict some
kind of collateral damage

00:40:07.590 --> 00:40:10.060 align:middle line:84%
on a large scale
that, over time, will

00:40:10.060 --> 00:40:14.290 align:middle line:84%
change their economic status
in the global configuration.

00:40:14.290 --> 00:40:17.530 align:middle line:84%
And at least that's one of
the areas where this really

00:40:17.530 --> 00:40:19.020 align:middle line:90%
is taking place.

00:40:19.020 --> 00:40:22.850 align:middle line:84%
>>NOORY: In this program, we've
talked about nanotechnology.

00:40:22.850 --> 00:40:25.480 align:middle line:84%
We've talked about
artificial intelligence.

00:40:25.480 --> 00:40:28.520 align:middle line:84%
We've talked about a
secret government program.

00:40:28.520 --> 00:40:31.360 align:middle line:84%
When you look at
the entire package,

00:40:31.360 --> 00:40:36.000 align:middle line:84%
would you say, all of this is
beneficial to the human race

00:40:36.000 --> 00:40:36.800 align:middle line:90%
in the long run?

00:40:36.800 --> 00:40:38.530 align:middle line:84%
>>OSTMAN: I would
say, it could be.

00:40:38.530 --> 00:40:43.580 align:middle line:84%
Depends on how it's managed, or
at least how it's interactively

00:40:43.580 --> 00:40:46.260 align:middle line:84%
conveyed from one
step to the next.

00:40:46.260 --> 00:40:48.980 align:middle line:84%
In the current scheme
of things, if I

00:40:48.980 --> 00:40:52.710 align:middle line:84%
were rolling the dice,
50/50, one way or the other?

00:40:52.710 --> 00:40:54.840 align:middle line:90%
It's a little darkish looking.

00:40:54.840 --> 00:40:56.740 align:middle line:90%
But I try to be an optimist.

00:40:56.740 --> 00:40:58.390 align:middle line:84%
But as I said
earlier, I think it's

00:40:58.390 --> 00:41:00.580 align:middle line:90%
part of an evolutionary test.

00:41:00.580 --> 00:41:03.220 align:middle line:84%
And we're about to be tested in
a way we've never been tested

00:41:03.220 --> 00:41:05.550 align:middle line:90%
before, on a planetary scale.

00:41:05.550 --> 00:41:08.240 align:middle line:84%
That is, are we going to
become the victim of the tools

00:41:08.240 --> 00:41:09.420 align:middle line:90%
we have invented?

00:41:09.420 --> 00:41:11.190 align:middle line:84%
Or can we benefit
from those tools

00:41:11.190 --> 00:41:13.330 align:middle line:84%
to progress to a
different way of being?

00:41:13.330 --> 00:41:15.170 align:middle line:84%
And I would circle
back, once again,

00:41:15.170 --> 00:41:18.360 align:middle line:84%
to this idea of a spiritual
maturity index matching

00:41:18.360 --> 00:41:20.720 align:middle line:84%
our technology and
development trends,

00:41:20.720 --> 00:41:22.500 align:middle line:90%
or the rate of those changes.

00:41:22.500 --> 00:41:24.050 align:middle line:84%
And I'm not sure
we're there yet.

00:41:24.050 --> 00:41:25.360 align:middle line:90%
I think it's possible.

00:41:25.360 --> 00:41:28.504 align:middle line:84%
But it's certainly a
rolling of the dice.

00:41:28.504 --> 00:41:30.920 align:middle line:84%
I don't think it's possible
predict, one way or the other,

00:41:30.920 --> 00:41:31.650 align:middle line:90%
exactly how it's going to go.

00:41:31.650 --> 00:41:34.108 align:middle line:84%
>>NOORY: Well, we've seen the
incredible applications, just

00:41:34.108 --> 00:41:36.000 align:middle line:84%
in some of the videos
and some of the things

00:41:36.000 --> 00:41:37.740 align:middle line:90%
we've talked about today.

00:41:37.740 --> 00:41:41.970 align:middle line:84%
You know, biological
arms and legs and eyes.

00:41:41.970 --> 00:41:44.790 align:middle line:84%
And to me, that's amazing
technology, Charles.

00:41:44.790 --> 00:41:48.660 align:middle line:84%
And I just hope we can
continue to put that together

00:41:48.660 --> 00:41:49.802 align:middle line:90%
to better humankind.

00:41:49.802 --> 00:41:51.260 align:middle line:84%
>>OSTMAN: I would
absolutely agree.

00:41:51.260 --> 00:41:54.650 align:middle line:10%
And I would hope it becomes
accessible and less expensive,

00:41:54.650 --> 00:41:55.540 align:middle line:10%
and more common.

00:41:55.540 --> 00:41:57.830 align:middle line:10%
And that almost anyone
that has the need

00:41:57.830 --> 00:42:00.410 align:middle line:10%
can have a way to improve
their quality of life.

00:42:00.410 --> 00:42:01.940 align:middle line:90%
That, to me, is the real goal.

00:42:01.940 --> 00:42:03.720 align:middle line:84%
>>NOORY: Charles, thanks for
being on "Beyond Belief."

00:42:03.720 --> 00:42:04.160 align:middle line:84%
>>OSTMAN: Thanks
for having me here.

00:42:04.160 --> 00:42:05.210 align:middle line:90%
>>NOORY: Really appreciate it.

00:42:05.210 --> 00:42:05.840 align:middle line:90%
>>OSTMAN: Thank you.

00:42:05.840 --> 00:42:07.298 align:middle line:10%
>>NOORY: And there's
no need for me

00:42:07.298 --> 00:42:09.940 align:middle line:10%
to sign off, because I'm
just going to think it

00:42:09.940 --> 00:42:11.043 align:middle line:10%
and you'll get it.

00:42:11.043 --> 00:42:14.480 align:middle line:90%
[THEME MUSIC]

00:42:14.480 --> 00:42:17.962 align:middle line:90%