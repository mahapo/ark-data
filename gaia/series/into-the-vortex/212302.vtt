WEBVTT

00:00:00.000 --> 00:00:10.370 align:middle line:90%


00:00:10.370 --> 00:00:12.980 align:middle line:84%
>> I'm Radio and Television
Host, Jimmy Church.

00:00:12.980 --> 00:00:15.800 align:middle line:84%
And I am here to uncover
the truth about some

00:00:15.800 --> 00:00:18.190 align:middle line:90%
of life's biggest mysteries.

00:00:18.190 --> 00:00:21.750 align:middle line:84%
>> If this is revealed,
everything has to be rewritten.

00:00:21.750 --> 00:00:25.730 align:middle line:84%
>> My guest today is Adam
Curry, a Visionary Technologist

00:00:25.730 --> 00:00:27.620 align:middle line:90%
at the Crossroads of AI.

00:00:27.620 --> 00:00:30.440 align:middle line:84%
Consciousness and
humanity's future

00:00:30.440 --> 00:00:34.370 align:middle line:84%
providing insightful guidance
for navigating this evolving

00:00:34.370 --> 00:00:35.420 align:middle line:90%
landscape.

00:00:35.420 --> 00:00:39.740 align:middle line:84%
>> As a theme, I think we
overestimate AI in terms

00:00:39.740 --> 00:00:40.760 align:middle line:90%
of the technology.

00:00:40.760 --> 00:00:41.720 align:middle line:90%
>> Where we are today?

00:00:41.720 --> 00:00:42.520 align:middle line:90%
>> Correct.

00:00:42.520 --> 00:00:44.510 align:middle line:84%
And we underestimate
consciousness.

00:00:44.510 --> 00:00:48.170 align:middle line:84%
>> As always, MUFOON
Field Investigator, Josh.

00:00:48.170 --> 00:00:49.740 align:middle line:84%
>> Josh, can you
pull up the map?

00:00:49.740 --> 00:00:50.540 align:middle line:90%
>> Yeah.

00:00:50.540 --> 00:00:52.640 align:middle line:10%
>> Joins us to
help set the scene.

00:00:52.640 --> 00:00:57.020 align:middle line:84%
Join us as we dive deep to
get to the bottom of some

00:00:57.020 --> 00:01:00.110 align:middle line:84%
of the most intriguing
questions of our time.

00:01:00.110 --> 00:01:02.360 align:middle line:84%
>> I think, one of the biggest
sort of challenges that

00:01:02.360 --> 00:01:06.230 align:middle line:84%
we're going to face is we
can build an AI that looks

00:01:06.230 --> 00:01:08.880 align:middle line:84%
and acts, a hell of
a lot, like humans.

00:01:08.880 --> 00:01:11.460 align:middle line:84%
In fact, it might even
be identical, right.

00:01:11.460 --> 00:01:14.490 align:middle line:84%
And so how would you know
what's real consciousness

00:01:14.490 --> 00:01:17.520 align:middle line:84%
and what's a simulation
of consciousness?

00:01:17.520 --> 00:01:29.750 align:middle line:90%


00:01:29.750 --> 00:01:31.640 align:middle line:90%
>> Welcome to Into the Vortex.

00:01:31.640 --> 00:01:32.600 align:middle line:90%
I'm Jimmy Church.

00:01:32.600 --> 00:01:35.600 align:middle line:10%
And today, artificial
intelligence,

00:01:35.600 --> 00:01:37.250 align:middle line:10%
otherwise known as AI.

00:01:37.250 --> 00:01:39.350 align:middle line:90%
And my guest is Adam Curry.

00:01:39.350 --> 00:01:41.720 align:middle line:84%
Very excited about
this Josh, because when

00:01:41.720 --> 00:01:43.940 align:middle line:90%
you have a technologist--

00:01:43.940 --> 00:01:49.310 align:middle line:84%
somebody that is attempting to
show the world the connection

00:01:49.310 --> 00:01:54.500 align:middle line:84%
between ones and zeros, code,
computer, and consciousness,

00:01:54.500 --> 00:01:58.760 align:middle line:84%
and the influence, and how they
can connect with each other--

00:01:58.760 --> 00:02:00.443 align:middle line:90%
is exactly in my wheelhouse.

00:02:00.443 --> 00:02:01.243 align:middle line:90%
What do you think?

00:02:01.243 --> 00:02:01.470 align:middle line:90%
>> I love it.

00:02:01.470 --> 00:02:01.860 align:middle line:90%
I love it.

00:02:01.860 --> 00:02:02.390 align:middle line:90%
I know I can't.

00:02:02.390 --> 00:02:03.973 align:middle line:84%
Thank God we have
Adam Curry to do it.

00:02:03.973 --> 00:02:07.280 align:middle line:90%
>> Well, are you afraid of AI?

00:02:07.280 --> 00:02:11.690 align:middle line:84%
>> Well, I teeter totter
between fear and love or hope.

00:02:11.690 --> 00:02:14.540 align:middle line:84%
>> I think-- Adam,
welcome to the show.

00:02:14.540 --> 00:02:16.020 align:middle line:90%
>> Good to be here, thank you.

00:02:16.020 --> 00:02:18.050 align:middle line:84%
>> I think we're getting ahead
of our skis when it comes

00:02:18.050 --> 00:02:18.850 align:middle line:90%
to AI.

00:02:18.850 --> 00:02:21.200 align:middle line:84%
And that we should
have learned our lesson

00:02:21.200 --> 00:02:25.340 align:middle line:84%
with the advances of social
media and the internet,

00:02:25.340 --> 00:02:29.490 align:middle line:84%
and its effect on society
and social dilemmas,

00:02:29.490 --> 00:02:31.800 align:middle line:90%
and what we see today.

00:02:31.800 --> 00:02:33.510 align:middle line:90%
But we didn't learn from that.

00:02:33.510 --> 00:02:36.870 align:middle line:84%
And it seems like we're
just going straight into AI

00:02:36.870 --> 00:02:38.790 align:middle line:90%
without any considerations.

00:02:38.790 --> 00:02:40.660 align:middle line:84%
Are we getting
ahead of our skis?

00:02:40.660 --> 00:02:42.900 align:middle line:90%
>> We probably are a little bit.

00:02:42.900 --> 00:02:46.650 align:middle line:84%
But it's not necessarily a bad
thing, would be my take on it.

00:02:46.650 --> 00:02:49.470 align:middle line:84%
Anytime you have
a technology that

00:02:49.470 --> 00:02:51.480 align:middle line:90%
has as much potential impact--

00:02:51.480 --> 00:02:54.060 align:middle line:84%
to the way that we live our
lives, to our economic systems,

00:02:54.060 --> 00:02:57.600 align:middle line:84%
to our careers, to all of that--
that moves as fast as something

00:02:57.600 --> 00:02:59.820 align:middle line:90%
like this, we get nervous.

00:02:59.820 --> 00:03:02.310 align:middle line:84%
The only other comparable
type of movement in that case

00:03:02.310 --> 00:03:04.690 align:middle line:84%
would be world wars or
something like that.

00:03:04.690 --> 00:03:09.840 align:middle line:84%
And so it's reasonable
to be apprehensive.

00:03:09.840 --> 00:03:12.240 align:middle line:84%
However, there's an
upside to this story.

00:03:12.240 --> 00:03:17.760 align:middle line:84%
And the upside is that we have
serious problems in our world.

00:03:17.760 --> 00:03:21.810 align:middle line:84%
We have 30 trillion
dollars of debt.

00:03:21.810 --> 00:03:24.580 align:middle line:90%
We've got unfunded liabilities.

00:03:24.580 --> 00:03:26.730 align:middle line:90%
We've got an aging population.

00:03:26.730 --> 00:03:29.562 align:middle line:84%
And the only way out
of this is probably not

00:03:29.562 --> 00:03:31.020 align:middle line:84%
printing more money,
it's not doing

00:03:31.020 --> 00:03:33.020 align:middle line:84%
any of the things that
used to work in the past.

00:03:33.020 --> 00:03:36.270 align:middle line:84%
But it's an embrace of radically
transformative technologies

00:03:36.270 --> 00:03:38.350 align:middle line:84%
that can get us
out of this mess.

00:03:38.350 --> 00:03:40.200 align:middle line:90%
And so that's the silver lining.

00:03:40.200 --> 00:03:44.880 align:middle line:84%
>> And so, how does AI stop
any of that or help it?

00:03:44.880 --> 00:03:45.960 align:middle line:90%
What's the benefit?

00:03:45.960 --> 00:03:47.910 align:middle line:84%
>> People talk about
all of the benefits.

00:03:47.910 --> 00:03:49.557 align:middle line:84%
And you know, I
think to some extent,

00:03:49.557 --> 00:03:50.640 align:middle line:90%
it's a bit overdetermined.

00:03:50.640 --> 00:03:54.270 align:middle line:90%
But any time that you can move--

00:03:54.270 --> 00:03:57.390 align:middle line:84%
in order of magnitude--
more efficiently

00:03:57.390 --> 00:04:00.870 align:middle line:84%
at least in every sector
of the productive economy,

00:04:00.870 --> 00:04:04.770 align:middle line:84%
in every sector of science, in
every sector of engineering,

00:04:04.770 --> 00:04:07.860 align:middle line:90%
and infrastructure in a society.

00:04:07.860 --> 00:04:10.830 align:middle line:84%
Now, the problems that
you face, that you've

00:04:10.830 --> 00:04:14.360 align:middle line:84%
financialized in your
economy, don't look the same.

00:04:14.360 --> 00:04:16.269 align:middle line:84%
They look like actually
tractable problems,

00:04:16.269 --> 00:04:19.060 align:middle line:84%
because you can
do more with less.

00:04:19.060 --> 00:04:23.500 align:middle line:84%
And so AI has the opportunity to
allow us to do more with less,

00:04:23.500 --> 00:04:25.580 align:middle line:90%
a lot more with a lot less.

00:04:25.580 --> 00:04:27.490 align:middle line:84%
And while it does
displace a lot of things

00:04:27.490 --> 00:04:30.070 align:middle line:84%
and there's a lot of uncertainty
surrounding that, it is

00:04:30.070 --> 00:04:31.720 align:middle line:90%
kind of the only thing we got.

00:04:31.720 --> 00:04:35.590 align:middle line:84%
Now, I put AI in the same
category as, for example,

00:04:35.590 --> 00:04:38.110 align:middle line:84%
new paradigm energies
as, for example,

00:04:38.110 --> 00:04:40.600 align:middle line:84%
reverse engineering
or understanding UFOs.

00:04:40.600 --> 00:04:44.680 align:middle line:84%
That type of really forward
thinking, progressive science

00:04:44.680 --> 00:04:47.580 align:middle line:84%
and technology, that is
the thing that I think

00:04:47.580 --> 00:04:49.330 align:middle line:84%
is the only thing
that's going to save us.

00:04:49.330 --> 00:04:54.820 align:middle line:84%
>> Well, I believe that the
majority of people working

00:04:54.820 --> 00:04:58.990 align:middle line:84%
in AI today are good people,
that they've got great

00:04:58.990 --> 00:05:00.100 align:middle line:90%
intentions.

00:05:00.100 --> 00:05:04.030 align:middle line:84%
But here's the other side
of that, which is this,

00:05:04.030 --> 00:05:08.470 align:middle line:84%
you're going to have somebody
that thinks bad thoughts.

00:05:08.470 --> 00:05:11.890 align:middle line:84%
And it's too easy
if you have an AI

00:05:11.890 --> 00:05:15.880 align:middle line:84%
engine that can do the thinking
of 1,000 scientists, overnight.

00:05:15.880 --> 00:05:18.940 align:middle line:84%
That would take them dozens
of years to accomplish

00:05:18.940 --> 00:05:20.650 align:middle line:90%
the same thing individually.

00:05:20.650 --> 00:05:25.673 align:middle line:84%
And you do that with general
intelligence, OK, makes sense?

00:05:25.673 --> 00:05:27.340 align:middle line:84%
But you're going to
have somebody that's

00:05:27.340 --> 00:05:30.910 align:middle line:90%
going to go, OK, this is cool.

00:05:30.910 --> 00:05:35.410 align:middle line:84%
Give me the recipe
to kill all humans.

00:05:35.410 --> 00:05:40.480 align:middle line:84%
And then overnight, you've got
1,000 of the deadliest chemical

00:05:40.480 --> 00:05:43.660 align:middle line:84%
weapons ever devised by
man that would have never

00:05:43.660 --> 00:05:45.220 align:middle line:90%
been thought of before.

00:05:45.220 --> 00:05:46.630 align:middle line:90%
How do we avoid that?

00:05:46.630 --> 00:05:49.210 align:middle line:90%
Do we bring in an AI czar?

00:05:49.210 --> 00:05:53.410 align:middle line:84%
Do we have some type of
regulation and oversight?

00:05:53.410 --> 00:05:56.470 align:middle line:84%
Which I think is
completely missing today.

00:05:56.470 --> 00:05:58.150 align:middle line:84%
>> These are all
the right questions.

00:05:58.150 --> 00:06:02.560 align:middle line:90%
And I have a contrarian take.

00:06:02.560 --> 00:06:05.480 align:middle line:90%
So I think in two parts.

00:06:05.480 --> 00:06:08.020 align:middle line:84%
One is that the way
the AI is developing

00:06:08.020 --> 00:06:11.470 align:middle line:84%
is, in general, by training
it on more and more content

00:06:11.470 --> 00:06:12.790 align:middle line:90%
produced on the internet.

00:06:12.790 --> 00:06:14.770 align:middle line:84%
That's how AI is getting
more sophisticated.

00:06:14.770 --> 00:06:16.840 align:middle line:84%
Now, there's no reason
to think, necessarily,

00:06:16.840 --> 00:06:19.570 align:middle line:84%
that means that more
sophisticated AI

00:06:19.570 --> 00:06:22.090 align:middle line:84%
trained on more content is
going to somehow be evil.

00:06:22.090 --> 00:06:26.300 align:middle line:84%
Think about what the lessons
of the 20th century were.

00:06:26.300 --> 00:06:29.000 align:middle line:84%
Too much power and
violence, bad, right?

00:06:29.000 --> 00:06:30.740 align:middle line:90%
>> Right.

00:06:30.740 --> 00:06:34.640 align:middle line:10%
>> Being truthful and honest,
and not putting people

00:06:34.640 --> 00:06:37.100 align:middle line:10%
in cages, and all of these
things that we're afraid the AI

00:06:37.100 --> 00:06:38.660 align:middle line:10%
is going to do, good.

00:06:38.660 --> 00:06:40.370 align:middle line:84%
So you've got a
system that's trained

00:06:40.370 --> 00:06:43.010 align:middle line:84%
on all of that learning
that human history has

00:06:43.010 --> 00:06:44.300 align:middle line:90%
had for so long.

00:06:44.300 --> 00:06:48.440 align:middle line:84%
It probably is going to make it
a little more benevolent, even

00:06:48.440 --> 00:06:49.760 align:middle line:90%
than our leaders in control.

00:06:49.760 --> 00:06:55.570 align:middle line:84%
But regarding the
question of regulation,

00:06:55.570 --> 00:06:57.740 align:middle line:90%
I have a different take on that.

00:06:57.740 --> 00:07:01.000 align:middle line:84%
>> Is there any
current regulation?

00:07:01.000 --> 00:07:04.090 align:middle line:84%
>> Not really, there's
no current regulation.

00:07:04.090 --> 00:07:06.940 align:middle line:84%
The two main competitors
in AI right now,

00:07:06.940 --> 00:07:09.150 align:middle line:90%
Microsoft and Google.

00:07:09.150 --> 00:07:11.680 align:middle line:84%
Google had an
advantage but Microsoft

00:07:11.680 --> 00:07:15.160 align:middle line:84%
was able to make a huge
investment into OpenAI,

00:07:15.160 --> 00:07:16.330 align:middle line:90%
which created ChatGPT.

00:07:16.330 --> 00:07:18.840 align:middle line:84%
So it's really
these two companies.

00:07:18.840 --> 00:07:24.930 align:middle line:84%
When OpenAI announced that they
had been successful with GPT 3

00:07:24.930 --> 00:07:31.080 align:middle line:84%
and releasing GPT 4, in one
day, there was a $100 billion

00:07:31.080 --> 00:07:34.260 align:middle line:84%
removed from the
market cap of Google.

00:07:34.260 --> 00:07:37.440 align:middle line:84%
The investing
community is so tuned

00:07:37.440 --> 00:07:39.270 align:middle line:84%
to what's going on
in this AI battle.

00:07:39.270 --> 00:07:40.690 align:middle line:90%
They had that much impact.

00:07:40.690 --> 00:07:43.020 align:middle line:84%
So these two companies
are locked in competition.

00:07:43.020 --> 00:07:47.880 align:middle line:84%
Now, at the same time, the
open source community--

00:07:47.880 --> 00:07:49.980 align:middle line:84%
Google and Microsoft are
trying to own this stuff.

00:07:49.980 --> 00:07:53.640 align:middle line:84%
The open source community is
developing their own AI models

00:07:53.640 --> 00:07:57.900 align:middle line:84%
that are open source
at 10 times the rate

00:07:57.900 --> 00:07:59.670 align:middle line:90%
for a tenth of the money.

00:07:59.670 --> 00:08:00.480 align:middle line:90%
Do the math.

00:08:00.480 --> 00:08:02.640 align:middle line:84%
That means that the open
source community is going

00:08:02.640 --> 00:08:04.650 align:middle line:90%
to eclipse them very soon.

00:08:04.650 --> 00:08:07.470 align:middle line:84%
And one's going
to control it, OK.

00:08:07.470 --> 00:08:08.830 align:middle line:90%
So they don't want that.

00:08:08.830 --> 00:08:12.600 align:middle line:84%
So how do you compete against
the open source community?

00:08:12.600 --> 00:08:13.530 align:middle line:90%
Regulation.

00:08:13.530 --> 00:08:14.890 align:middle line:10%
>> Of course.

00:08:14.890 --> 00:08:16.930 align:middle line:90%
>> It's too dangerous.

00:08:16.930 --> 00:08:19.152 align:middle line:90%
We don't know what we're doing.

00:08:19.152 --> 00:08:20.860 align:middle line:84%
We've got to get the
government involved.

00:08:20.860 --> 00:08:22.318 align:middle line:84%
We've got to regulate
these things.

00:08:22.318 --> 00:08:24.730 align:middle line:84%
And, of course, who's going
to get the permission to

00:08:24.730 --> 00:08:27.095 align:middle line:84%
continue to develop
their AI system as well.

00:08:27.095 --> 00:08:27.970 align:middle line:90%
You can take a guess.

00:08:27.970 --> 00:08:28.810 align:middle line:90%
>> Google and Microsoft.

00:08:28.810 --> 00:08:31.090 align:middle line:84%
>> So now, I'm not necessarily
saying that is a grand

00:08:31.090 --> 00:08:31.900 align:middle line:90%
conspiracy theory.

00:08:31.900 --> 00:08:35.900 align:middle line:84%
But I am saying that they
benefit from the danger

00:08:35.900 --> 00:08:36.700 align:middle line:90%
narrative.

00:08:36.700 --> 00:08:38.825 align:middle line:84%
Now, it's not that there
aren't dangers, there are.

00:08:38.825 --> 00:08:43.059 align:middle line:84%
But we've got to also understand
that if we're not also

00:08:43.059 --> 00:08:45.580 align:middle line:84%
skeptical about
regulation, we could end up

00:08:45.580 --> 00:08:48.070 align:middle line:84%
as a situation in which it's
those two companies that own

00:08:48.070 --> 00:08:49.670 align:middle line:90%
and control the whole thing.

00:08:49.670 --> 00:08:55.150 align:middle line:84%
>> And if somebody
has an open source,

00:08:55.150 --> 00:08:58.120 align:middle line:84%
artificial intelligence
algorithm sitting in front

00:08:58.120 --> 00:09:01.180 align:middle line:84%
of them and the
ability to modify that.

00:09:01.180 --> 00:09:02.920 align:middle line:90%
And they've got bad intentions.

00:09:02.920 --> 00:09:04.120 align:middle line:90%
Or they're bored.

00:09:04.120 --> 00:09:06.880 align:middle line:84%
And they want to see if
they can take over the world

00:09:06.880 --> 00:09:09.880 align:middle line:84%
or what have you,
it could happen.

00:09:09.880 --> 00:09:12.820 align:middle line:90%
>> It will happen at some level.

00:09:12.820 --> 00:09:15.622 align:middle line:84%
And then, you'll have to
protect yourself somehow.

00:09:15.622 --> 00:09:17.830 align:middle line:84%
So there will be companies
that will come out with AI

00:09:17.830 --> 00:09:19.240 align:middle line:90%
to counter the other AI.

00:09:19.240 --> 00:09:23.840 align:middle line:84%
And so to get insurance, for
example, for your company,

00:09:23.840 --> 00:09:27.160 align:middle line:84%
you're going to have to
have an encounter AI policy.

00:09:27.160 --> 00:09:30.088 align:middle line:84%
And so there'll be a race to
protect yourself with this.

00:09:30.088 --> 00:09:32.380 align:middle line:84%
Then, of course, you've got
AI to counter the AI that's

00:09:32.380 --> 00:09:33.820 align:middle line:90%
protecting you from the AI.

00:09:33.820 --> 00:09:37.000 align:middle line:84%
And you basically,
whenever you're

00:09:37.000 --> 00:09:39.250 align:middle line:84%
talking about something that
has an exponential curve,

00:09:39.250 --> 00:09:41.320 align:middle line:84%
you get into these
game theory situations

00:09:41.320 --> 00:09:43.720 align:middle line:84%
that get beyond our ability
to really comprehend,

00:09:43.720 --> 00:09:45.512 align:middle line:84%
because we're not used
to thinking like two

00:09:45.512 --> 00:09:46.870 align:middle line:90%
or three steps ahead.

00:09:46.870 --> 00:09:49.390 align:middle line:84%
And that's really
where things break down

00:09:49.390 --> 00:09:52.090 align:middle line:84%
in terms of our ability to make
any prediction about what's

00:09:52.090 --> 00:09:53.530 align:middle line:90%
going to happen--

00:09:53.530 --> 00:09:57.400 align:middle line:90%
ergo, the anxiety.

00:09:57.400 --> 00:10:00.230 align:middle line:84%
Can't predict it, you're
going to feel a certain way.

00:10:00.230 --> 00:10:05.330 align:middle line:84%
>> Well, isn't the
anxiety a good thing?

00:10:05.330 --> 00:10:09.340 align:middle line:84%
Isn't it a warning sign to,
at least, discuss these things

00:10:09.340 --> 00:10:11.440 align:middle line:84%
and put the hypotheticals
out in front of us

00:10:11.440 --> 00:10:14.080 align:middle line:84%
and not let these
things happen--

00:10:14.080 --> 00:10:16.570 align:middle line:84%
that we don't have
any control over,

00:10:16.570 --> 00:10:18.550 align:middle line:84%
that we didn't
warn ourselves of.

00:10:18.550 --> 00:10:20.712 align:middle line:90%
>> A 100%.

00:10:20.712 --> 00:10:25.000 align:middle line:84%
One of the serious problems
that I think the AI poses to us

00:10:25.000 --> 00:10:26.560 align:middle line:84%
is not necessarily
that it's going

00:10:26.560 --> 00:10:29.740 align:middle line:84%
to suddenly create consciousness
and then decide that humans

00:10:29.740 --> 00:10:31.240 align:middle line:90%
are a plague and delete us.

00:10:31.240 --> 00:10:35.140 align:middle line:84%
It's if people don't really
understand this stuff and they

00:10:35.140 --> 00:10:37.880 align:middle line:84%
are allowed to put AI-- which
is just sophisticated computer

00:10:37.880 --> 00:10:38.680 align:middle line:90%
code--

00:10:38.680 --> 00:10:41.260 align:middle line:84%
in charge of the
nuclear reactor,

00:10:41.260 --> 00:10:44.470 align:middle line:84%
in charge of the power
grid, in charge of XYZ,

00:10:44.470 --> 00:10:48.940 align:middle line:84%
and software,
software, it has bugs.

00:10:48.940 --> 00:10:53.020 align:middle line:84%
And now, there's nobody
left to basically understa--

00:10:53.020 --> 00:10:54.730 align:middle line:84%
if something goes
wrong and these systems

00:10:54.730 --> 00:10:56.740 align:middle line:84%
go offline or whatever,
there's nobody

00:10:56.740 --> 00:11:00.400 align:middle line:84%
who can really figure out what
the corrective action is there.

00:11:00.400 --> 00:11:01.510 align:middle line:90%
That's a serious problem.

00:11:01.510 --> 00:11:03.552 align:middle line:84%
And that's equally on the
human side, as well as,

00:11:03.552 --> 00:11:04.750 align:middle line:90%
in the AI side.

00:11:04.750 --> 00:11:07.000 align:middle line:84%
But it tends to be more
of this question of,

00:11:07.000 --> 00:11:10.270 align:middle line:84%
are we being responsible
with how we're delegating

00:11:10.270 --> 00:11:12.580 align:middle line:90%
our own human responsibilities?

00:11:12.580 --> 00:11:15.832 align:middle line:84%
When you have something that
you fundamentally cannot predict

00:11:15.832 --> 00:11:18.040 align:middle line:84%
and it moves way too fast,
you don't want to put that

00:11:18.040 --> 00:11:20.300 align:middle line:84%
in charge of like the
most sophisticated things.

00:11:20.300 --> 00:11:23.500 align:middle line:84%
So that's where we need
to be very cautious.

00:11:23.500 --> 00:11:24.760 align:middle line:90%
>> Do you keep it--

00:11:24.760 --> 00:11:28.693 align:middle line:84%
do you keep the ethernet
cable unplugged, right?

00:11:28.693 --> 00:11:29.860 align:middle line:90%
>> We just keep it in a box.

00:11:29.860 --> 00:11:31.250 align:middle line:90%
>> Yeah, keep it in a box.

00:11:31.250 --> 00:11:32.600 align:middle line:90%
>> I mean, good luck.

00:11:32.600 --> 00:11:33.400 align:middle line:90%
I don't know.

00:11:33.400 --> 00:11:36.580 align:middle line:84%
>> It would figure out a
way to access the internet.

00:11:36.580 --> 00:11:37.600 align:middle line:90%
>> I think so.

00:11:37.600 --> 00:11:41.380 align:middle line:84%
Or it could social engineer
somebody who's a night shift

00:11:41.380 --> 00:11:43.600 align:middle line:90%
worker to do it or--

00:11:43.600 --> 00:11:46.720 align:middle line:84%
>> Fall in love, become
somebody's friend,

00:11:46.720 --> 00:11:48.490 align:middle line:90%
get inside of your head.

00:11:48.490 --> 00:11:53.020 align:middle line:84%
Come on, Adam,
plug-in the cable.

00:11:53.020 --> 00:11:55.510 align:middle line:84%
Get out in front of
this and outsmart us.

00:11:55.510 --> 00:11:57.250 align:middle line:90%
>> Potentially, yeah, yeah.

00:11:57.250 --> 00:12:02.490 align:middle line:84%
And then, you'd have to ask,
well, is it actually doing it?

00:12:02.490 --> 00:12:04.560 align:middle line:84%
Is the result of that
actually good, somehow?

00:12:04.560 --> 00:12:06.780 align:middle line:84%
And we just can't see
it, because we can only

00:12:06.780 --> 00:12:08.670 align:middle line:90%
think a few steps ahead.

00:12:08.670 --> 00:12:10.830 align:middle line:84%
And they can think a
million steps ahead.

00:12:10.830 --> 00:12:14.550 align:middle line:84%
>> Why the fear
of a sentient AI?

00:12:14.550 --> 00:12:18.090 align:middle line:84%
Why the fear of
something that does

00:12:18.090 --> 00:12:19.810 align:middle line:90%
achieve true consciousness?

00:12:19.810 --> 00:12:20.610 align:middle line:90%
Why the fear?

00:12:20.610 --> 00:12:23.730 align:middle line:84%
I think that a bigger
fear would be something

00:12:23.730 --> 00:12:26.850 align:middle line:84%
that wasn't sentient,
and didn't have empathy,

00:12:26.850 --> 00:12:32.380 align:middle line:84%
and could give a care less about
you or the rest of humanity.

00:12:32.380 --> 00:12:36.240 align:middle line:84%
I think that we would want
a certain amount of empathy

00:12:36.240 --> 00:12:40.590 align:middle line:84%
built into an AI, where there's
a little bit of sentience.

00:12:40.590 --> 00:12:45.240 align:middle line:84%
>> Yeah, well, I think that's
really the type of question

00:12:45.240 --> 00:12:46.990 align:middle line:90%
that we should be asking.

00:12:46.990 --> 00:12:47.790 align:middle line:90%
Why the fear?

00:12:47.790 --> 00:12:50.100 align:middle line:84%
Well, again, it's
overdetermined.

00:12:50.100 --> 00:12:53.910 align:middle line:84%
I think that Gen X and
millennials grew up

00:12:53.910 --> 00:12:57.450 align:middle line:84%
with movies like the
"Terminator" and so forth.

00:12:57.450 --> 00:13:02.430 align:middle line:84%
I think that you have this
regulation, motivated story

00:13:02.430 --> 00:13:04.830 align:middle line:84%
about how only
certain people should

00:13:04.830 --> 00:13:07.500 align:middle line:84%
be able to use this
stuff and control it.

00:13:07.500 --> 00:13:13.140 align:middle line:84%
I think you have also a sort
of non-technical community who

00:13:13.140 --> 00:13:16.800 align:middle line:84%
are seeing the impressive
effects of things like ChatGPT,

00:13:16.800 --> 00:13:18.240 align:middle line:84%
but they actually
don't understand

00:13:18.240 --> 00:13:19.198 align:middle line:90%
what's really going on.

00:13:19.198 --> 00:13:21.250 align:middle line:84%
And what's really going
on is pretty simple.

00:13:21.250 --> 00:13:24.030 align:middle line:84%
It just presents in a
really powerful way.

00:13:24.030 --> 00:13:27.330 align:middle line:84%
As a theme, I think
we overestimate

00:13:27.330 --> 00:13:29.580 align:middle line:90%
AI in terms of the technology.

00:13:29.580 --> 00:13:30.540 align:middle line:90%
>> Where we are today?

00:13:30.540 --> 00:13:31.340 align:middle line:90%
>> Correct.

00:13:31.340 --> 00:13:33.340 align:middle line:84%
And we underestimate
consciousness.

00:13:33.340 --> 00:13:36.908 align:middle line:84%
So we overestimate AI,
because nobody's really

00:13:36.908 --> 00:13:39.450 align:middle line:84%
been able to look under the hood
and see, oh, that's actually

00:13:39.450 --> 00:13:41.545 align:middle line:84%
just a bunch of probabilities
coming together,

00:13:41.545 --> 00:13:42.670 align:middle line:90%
which is really what it is.

00:13:42.670 --> 00:13:44.610 align:middle line:90%
We can get into that.

00:13:44.610 --> 00:13:47.330 align:middle line:84%
And similarly, they
underestimate consciousness,

00:13:47.330 --> 00:13:49.497 align:middle line:84%
because there's only a few
consciousness researchers

00:13:49.497 --> 00:13:50.297 align:middle line:90%
out there.

00:13:50.297 --> 00:13:52.220 align:middle line:84%
There's more growing,
but there's only a few

00:13:52.220 --> 00:13:54.600 align:middle line:84%
who understand that
this is a real mystery.

00:13:54.600 --> 00:13:58.100 align:middle line:84%
It's not just a question of
you throw a bunch of neurons

00:13:58.100 --> 00:13:59.568 align:middle line:90%
into an assembly like a brain--

00:13:59.568 --> 00:14:00.860 align:middle line:90%
>> Thinking it's going to work.

00:14:00.860 --> 00:14:03.680 align:middle line:84%
>> --and a consciousness
magically happens.

00:14:03.680 --> 00:14:07.067 align:middle line:84%
So the experts are these
computer programmers

00:14:07.067 --> 00:14:09.150 align:middle line:84%
who don't know about the
mystery of consciousness.

00:14:09.150 --> 00:14:11.108 align:middle line:84%
And so they're just using
this term flippantly.

00:14:11.108 --> 00:14:13.310 align:middle line:84%
So we think, we
hear that, oh, we're

00:14:13.310 --> 00:14:14.930 align:middle line:84%
so close to building
something that

00:14:14.930 --> 00:14:17.160 align:middle line:84%
is like actually sentient,
actually consciousness.

00:14:17.160 --> 00:14:19.130 align:middle line:84%
And I think, to say that
is to not understand

00:14:19.130 --> 00:14:20.720 align:middle line:90%
the mystery of consciousness.

00:14:20.720 --> 00:14:26.480 align:middle line:84%
My humble contribution to
the field of AI has been,

00:14:26.480 --> 00:14:31.670 align:middle line:84%
I think, to try to get people
to think more clearly about what

00:14:31.670 --> 00:14:33.620 align:middle line:90%
consciousness really is.

00:14:33.620 --> 00:14:35.960 align:middle line:84%
What artificial
intelligence really is.

00:14:35.960 --> 00:14:39.650 align:middle line:84%
And how to properly
think about the two.

00:14:39.650 --> 00:14:41.300 align:middle line:90%
>> Let me throw this.

00:14:41.300 --> 00:14:43.790 align:middle line:84%
You and I have discussed
your research for years.

00:14:43.790 --> 00:14:49.650 align:middle line:84%
And you have forced
me onto a journey

00:14:49.650 --> 00:14:51.240 align:middle line:90%
into investigating all of this.

00:14:51.240 --> 00:14:54.480 align:middle line:84%
And one of the points
that you and I discussed

00:14:54.480 --> 00:15:00.180 align:middle line:84%
many times is, is
consciousness of the physical

00:15:00.180 --> 00:15:02.310 align:middle line:90%
or is it non-physical?

00:15:02.310 --> 00:15:06.180 align:middle line:84%
And there are scientists,
computer engineers,

00:15:06.180 --> 00:15:11.250 align:middle line:84%
physicists who will
insist that there's

00:15:11.250 --> 00:15:14.610 align:middle line:84%
a little piece of consciousness
in every particle.

00:15:14.610 --> 00:15:17.610 align:middle line:84%
And once you assemble
enough particles together,

00:15:17.610 --> 00:15:20.310 align:middle line:84%
like the "gray goo"
in between our ears--

00:15:20.310 --> 00:15:22.350 align:middle line:84%
you put enough of
that together--

00:15:22.350 --> 00:15:24.000 align:middle line:90%
consciousness just appears.

00:15:24.000 --> 00:15:26.640 align:middle line:90%
And it's a chemical process.

00:15:26.640 --> 00:15:31.950 align:middle line:84%
If that's the case, then
going willy-nilly into AI--

00:15:31.950 --> 00:15:33.840 align:middle line:84%
and I'm talking about
the skeptics that

00:15:33.840 --> 00:15:36.150 align:middle line:84%
discuss this form
of consciousness

00:15:36.150 --> 00:15:40.080 align:middle line:84%
that you build a
server farm full of AI.

00:15:40.080 --> 00:15:43.230 align:middle line:84%
That's also a lot of particles,
that's a lot of atoms.

00:15:43.230 --> 00:15:47.640 align:middle line:84%
And that consciousness
may appear the way

00:15:47.640 --> 00:15:50.860 align:middle line:90%
that they insist that it could.

00:15:50.860 --> 00:15:54.150 align:middle line:84%
>> It may, so that's a big
debate in the community.

00:15:54.150 --> 00:15:58.040 align:middle line:84%
Like, if you get a
sufficiently complex AI system

00:15:58.040 --> 00:16:00.057 align:middle line:84%
where instead of neurons,
you have transistors.

00:16:00.057 --> 00:16:00.890 align:middle line:90%
You've got billions.

00:16:00.890 --> 00:16:02.180 align:middle line:84%
And they're connected
in all these ways--

00:16:02.180 --> 00:16:03.140 align:middle line:90%
>> If not trillions.

00:16:03.140 --> 00:16:04.520 align:middle line:90%
>> If not trillions.

00:16:04.520 --> 00:16:07.950 align:middle line:84%
And do you get something like
human level consciousness?

00:16:07.950 --> 00:16:10.370 align:middle line:84%
And I think that
the answer is still,

00:16:10.370 --> 00:16:15.067 align:middle line:90%
we don't know but maybe not.

00:16:15.067 --> 00:16:17.150 align:middle line:84%
The reason is that-- let's
say that you could even

00:16:17.150 --> 00:16:19.460 align:middle line:84%
build something like
a human brain that

00:16:19.460 --> 00:16:23.300 align:middle line:84%
has the same number of
neurons and connections.

00:16:23.300 --> 00:16:25.790 align:middle line:84%
There's no way of really
knowing if there's

00:16:25.790 --> 00:16:28.320 align:middle line:84%
something called "what it's
like to be that computer."

00:16:28.320 --> 00:16:29.120 align:middle line:90%
>> That's right.

00:16:29.120 --> 00:16:31.880 align:middle line:84%
>> There's no interiority,
no subjectivity.

00:16:31.880 --> 00:16:34.160 align:middle line:90%
Are the lights on upstairs?

00:16:34.160 --> 00:16:38.210 align:middle line:84%
And that is a domain that
we experience ourselves.

00:16:38.210 --> 00:16:40.770 align:middle line:84%
But we don't really know
if that's going on at all.

00:16:40.770 --> 00:16:43.070 align:middle line:84%
And I think one of the
biggest challenges that we're

00:16:43.070 --> 00:16:47.540 align:middle line:84%
going to face is we can build
an AI that looks and acts

00:16:47.540 --> 00:16:49.500 align:middle line:90%
a hell of a lot like humans.

00:16:49.500 --> 00:16:52.110 align:middle line:84%
In fact, it might
even be identical.

00:16:52.110 --> 00:16:55.140 align:middle line:84%
And so, how would what's
real consciousness

00:16:55.140 --> 00:16:58.235 align:middle line:84%
and what's a simulation
of consciousness?

00:16:58.235 --> 00:17:00.360 align:middle line:84%
And so people have been
thinking about this problem

00:17:00.360 --> 00:17:01.780 align:middle line:90%
for a long time.

00:17:01.780 --> 00:17:05.322 align:middle line:84%
And my perspective is, until
you get honest with yourself

00:17:05.322 --> 00:17:06.780 align:middle line:84%
about the mystery
of consciousness,

00:17:06.780 --> 00:17:08.490 align:middle line:90%
you're not going to solve that.

00:17:08.490 --> 00:17:12.960 align:middle line:84%
>> Here is an image of
your psychic machine.

00:17:12.960 --> 00:17:14.130 align:middle line:90%
Take me through this.

00:17:14.130 --> 00:17:15.220 align:middle line:90%
What am I looking at?

00:17:15.220 --> 00:17:17.760 align:middle line:10%
And what does it actually do?

00:17:17.760 --> 00:17:21.300 align:middle line:10%
>> Well, this is some
real, mad science stuff.

00:17:21.300 --> 00:17:27.800 align:middle line:84%
So let's say that you build
an AI that resembles humans

00:17:27.800 --> 00:17:30.260 align:middle line:84%
to a T. And you have
real consciousness.

00:17:30.260 --> 00:17:32.870 align:middle line:84%
And you don't know whether or
not it's real consciousness

00:17:32.870 --> 00:17:34.190 align:middle line:90%
or it's a simulation.

00:17:34.190 --> 00:17:37.280 align:middle line:84%
The question becomes, well,
how do you make a test

00:17:37.280 --> 00:17:40.550 align:middle line:84%
to tell whether or not
something is really conscious

00:17:40.550 --> 00:17:42.990 align:middle line:90%
or it's just a simulation?

00:17:42.990 --> 00:17:46.260 align:middle line:84%
My approach to that has
been, well, what is something

00:17:46.260 --> 00:17:50.550 align:middle line:84%
that consciousness can do and
only consciousness can do?

00:17:50.550 --> 00:17:52.350 align:middle line:84%
And that is found,
in my opinion,

00:17:52.350 --> 00:17:57.230 align:middle line:84%
in the realm of
parapsychology, clairvoyance,

00:17:57.230 --> 00:18:00.197 align:middle line:90%
telepathy, psychokinesis.

00:18:00.197 --> 00:18:02.030 align:middle line:84%
These types of things
that have been studied

00:18:02.030 --> 00:18:04.400 align:middle line:90%
in the lab for 50 years.

00:18:04.400 --> 00:18:06.860 align:middle line:84%
We know it's true-- remote
viewing, all that stuff.

00:18:06.860 --> 00:18:08.900 align:middle line:84%
That's something that
consciousness can do

00:18:08.900 --> 00:18:12.020 align:middle line:84%
and only consciousness
can do, OK.

00:18:12.020 --> 00:18:14.720 align:middle line:84%
What I'm proposing is that
there's a new kind of test.

00:18:14.720 --> 00:18:18.590 align:middle line:84%
And that test is to see, whether
or not, the machine or the AI

00:18:18.590 --> 00:18:19.880 align:middle line:90%
is actually psychic.

00:18:19.880 --> 00:18:23.780 align:middle line:84%
And if it is, then you've
probably achieved AGI.

00:18:23.780 --> 00:18:27.080 align:middle line:84%
You've achieved the creation
of sentience or consciousness

00:18:27.080 --> 00:18:27.950 align:middle line:90%
in the machine.

00:18:27.950 --> 00:18:29.810 align:middle line:84%
And rather than
just propose a test,

00:18:29.810 --> 00:18:34.286 align:middle line:90%
like a navel-gazing academic--

00:18:34.286 --> 00:18:35.580 align:middle line:90%
I love building stuff.

00:18:35.580 --> 00:18:38.480 align:middle line:84%
So I actually attempted
to build a machine that

00:18:38.480 --> 00:18:41.000 align:middle line:90%
could perform psychically.

00:18:41.000 --> 00:18:42.305 align:middle line:90%
So here's how I did that.

00:18:42.305 --> 00:18:45.050 align:middle line:10%
>> You know this is the
scariest thing ever, right?

00:18:45.050 --> 00:18:47.553 align:middle line:10%


00:18:47.553 --> 00:18:49.220 align:middle line:10%
>> It was an adventure
in building this,

00:18:49.220 --> 00:18:50.030 align:middle line:10%
I'll tell you that.

00:18:50.030 --> 00:18:53.930 align:middle line:84%
In parapsychology, there's
a test for clairvoyance.

00:18:53.930 --> 00:18:55.910 align:middle line:90%
Where you take a human subject.

00:18:55.910 --> 00:18:59.390 align:middle line:84%
You connect them
to something that

00:18:59.390 --> 00:19:03.830 align:middle line:84%
measures tension, subtle
tension, on their finger.

00:19:03.830 --> 00:19:07.640 align:middle line:84%
And you show them
images on a computer.

00:19:07.640 --> 00:19:10.580 align:middle line:84%
The images might be of a
butterfly, a nice field,

00:19:10.580 --> 00:19:11.960 align:middle line:90%
very calming things.

00:19:11.960 --> 00:19:13.940 align:middle line:84%
But then, at random
times, you show them

00:19:13.940 --> 00:19:16.280 align:middle line:90%
a very unsettling image--

00:19:16.280 --> 00:19:20.630 align:middle line:84%
something very provocative,
like an evil clown or--

00:19:20.630 --> 00:19:21.430 align:middle line:90%
>> Car accident.

00:19:21.430 --> 00:19:23.180 align:middle line:90%
>> --car accident or something.

00:19:23.180 --> 00:19:24.950 align:middle line:84%
And then you look--
you would expect

00:19:24.950 --> 00:19:26.990 align:middle line:84%
that when they see that
image, they tense up.

00:19:26.990 --> 00:19:27.890 align:middle line:90%
And indeed, they do.

00:19:27.890 --> 00:19:31.790 align:middle line:84%
But in fact, they
tense up a few seconds

00:19:31.790 --> 00:19:36.110 align:middle line:84%
before being shown
the provocative image.

00:19:36.110 --> 00:19:41.510 align:middle line:84%
So there's a subconscious
psychic anticipation

00:19:41.510 --> 00:19:45.420 align:middle line:84%
of something violent or
whatever being shown to them.

00:19:45.420 --> 00:19:49.860 align:middle line:84%
And this work has been repeated
at least three very good

00:19:49.860 --> 00:19:50.660 align:middle line:90%
studies.

00:19:50.660 --> 00:19:53.910 align:middle line:84%
>> So is this a type
of precognition--

00:19:53.910 --> 00:19:54.710 align:middle line:90%
>> Yes.

00:19:54.710 --> 00:19:59.120 align:middle line:84%
>> --where you are jumping ahead
of what you're about to see,

00:19:59.120 --> 00:20:00.540 align:middle line:90%
but you know it?

00:20:00.540 --> 00:20:01.340 align:middle line:90%
>> Correct.

00:20:01.340 --> 00:20:01.730 align:middle line:90%
>> Right.

00:20:01.730 --> 00:20:02.660 align:middle line:90%
>> Yeah, OK.

00:20:02.660 --> 00:20:06.710 align:middle line:84%
So can you take that
same type of experiment

00:20:06.710 --> 00:20:08.480 align:middle line:90%
and run it on a machine?

00:20:08.480 --> 00:20:10.550 align:middle line:84%
Can you make that
machine anticipate

00:20:10.550 --> 00:20:15.077 align:middle line:84%
being surprised or shocked
somehow in the future?

00:20:15.077 --> 00:20:16.910 align:middle line:84%
So this is the question
I was asking myself.

00:20:16.910 --> 00:20:19.380 align:middle line:84%
And I was thinking,
OK, that's it.

00:20:19.380 --> 00:20:22.490 align:middle line:84%
So now, how do you
scare a machine?

00:20:22.490 --> 00:20:25.070 align:middle line:84%
Obviously, it's not going to
react to the photo of the car

00:20:25.070 --> 00:20:26.240 align:middle line:90%
accident or something.

00:20:26.240 --> 00:20:29.100 align:middle line:84%
And what I concluded or what
I thought was like, well,

00:20:29.100 --> 00:20:33.110 align:middle line:84%
the machines require electricity
or at least many of them do.

00:20:33.110 --> 00:20:36.510 align:middle line:84%
When you pull the power, it's
like pulling your life force.

00:20:36.510 --> 00:20:39.230 align:middle line:84%
So what I'm going to do in
this experiment, this machine,

00:20:39.230 --> 00:20:43.610 align:middle line:84%
is I'm going to have an
electronic machine running.

00:20:43.610 --> 00:20:46.610 align:middle line:84%
And I'm going to randomly
pull the power to it.

00:20:46.610 --> 00:20:49.460 align:middle line:84%
And I'm going to record
what it does in the moments

00:20:49.460 --> 00:20:51.530 align:middle line:90%
before the power is cut.

00:20:51.530 --> 00:20:54.570 align:middle line:84%
So the machine I chose is
a quantum random number

00:20:54.570 --> 00:20:55.370 align:middle line:90%
generator.

00:20:55.370 --> 00:21:00.030 align:middle line:10%
And all that does is it produces
an output of ones and zeros, 50

00:21:00.030 --> 00:21:01.580 align:middle line:10%
50, ones and zeros.

00:21:01.580 --> 00:21:02.810 align:middle line:10%
That's all it does.

00:21:02.810 --> 00:21:03.830 align:middle line:10%
I recorded that output.

00:21:03.830 --> 00:21:06.830 align:middle line:10%
And then at random
times, a second system

00:21:06.830 --> 00:21:07.700 align:middle line:10%
would cut the power.

00:21:07.700 --> 00:21:12.210 align:middle line:84%
And then I just let this
run for a couple of days.

00:21:12.210 --> 00:21:14.760 align:middle line:10%
Came back, took the data.

00:21:14.760 --> 00:21:17.040 align:middle line:84%
I aligned all of the
data up to the point

00:21:17.040 --> 00:21:18.780 align:middle line:90%
where the power is cut.

00:21:18.780 --> 00:21:21.270 align:middle line:10%
And it was completely shocked.

00:21:21.270 --> 00:21:24.720 align:middle line:10%
If you measure this on a graph
where it's ones and zeros,

00:21:24.720 --> 00:21:26.460 align:middle line:10%
it's pretty much range bound.

00:21:26.460 --> 00:21:28.740 align:middle line:10%
And then about one
second before the power

00:21:28.740 --> 00:21:31.560 align:middle line:10%
is cut, phew, straight down.

00:21:31.560 --> 00:21:35.580 align:middle line:10%
It starts producing tons
of zeros and hugely,

00:21:35.580 --> 00:21:37.090 align:middle line:10%
statistically significant.

00:21:37.090 --> 00:21:39.450 align:middle line:10%
So I ran the test
again, same result. It

00:21:39.450 --> 00:21:41.760 align:middle line:10%
was predicting the future
about one second in advance.

00:21:41.760 --> 00:21:44.480 align:middle line:90%


00:21:44.480 --> 00:21:45.898 align:middle line:90%
I then took this set up.

00:21:45.898 --> 00:21:47.690 align:middle line:84%
And I sent it to the
University of Colorado

00:21:47.690 --> 00:21:51.110 align:middle line:84%
to the engineering department,
these are real scientists.

00:21:51.110 --> 00:21:54.620 align:middle line:84%
He and his graduate student
team rebuilt the whole thing--

00:21:54.620 --> 00:21:57.140 align:middle line:84%
ran formal experiments,
three of them.

00:21:57.140 --> 00:22:00.200 align:middle line:84%
Cumulatively, the odds against
chance of that happening,

00:22:00.200 --> 00:22:03.440 align:middle line:90%
25 billion to 1.

00:22:03.440 --> 00:22:05.182 align:middle line:90%
That's an unheard of--

00:22:05.182 --> 00:22:06.140 align:middle line:90%
>> That's a big number.

00:22:06.140 --> 00:22:09.012 align:middle line:84%
>> Yeah, the odds of winning
the Powerball are 1 in 190.

00:22:09.012 --> 00:22:10.220 align:middle line:90%
>> That's a big number, yeah.

00:22:10.220 --> 00:22:13.400 align:middle line:84%
>> So did we build
a psychic machine?

00:22:13.400 --> 00:22:16.890 align:middle line:90%
Well, yes.

00:22:16.890 --> 00:22:19.500 align:middle line:84%
An interesting thing
happened afterwards though.

00:22:19.500 --> 00:22:21.510 align:middle line:84%
After we got that
result, we were

00:22:21.510 --> 00:22:23.560 align:middle line:84%
thinking about what
we're going to do next.

00:22:23.560 --> 00:22:28.830 align:middle line:84%
Are you going to use it to
dominate the stock market,

00:22:28.830 --> 00:22:29.820 align:middle line:90%
make trades?

00:22:29.820 --> 00:22:30.984 align:middle line:90%
If you know--

00:22:30.984 --> 00:22:31.800 align:middle line:90%
>> One second--

00:22:31.800 --> 00:22:32.250 align:middle line:90%
>> --one second--

00:22:32.250 --> 00:22:33.100 align:middle line:90%
>> --is a big deal.

00:22:33.100 --> 00:22:33.900 align:middle line:90%
>> --it's enough.

00:22:33.900 --> 00:22:35.082 align:middle line:90%
>> Yes, yes.

00:22:35.082 --> 00:22:36.540 align:middle line:84%
>> Do you write
the seminal papers?

00:22:36.540 --> 00:22:38.600 align:middle line:90%
Do you do all these things?

00:22:38.600 --> 00:22:41.110 align:middle line:84%
And after we got really
excited about that,

00:22:41.110 --> 00:22:43.990 align:middle line:84%
we ran another
experiment, no results.

00:22:43.990 --> 00:22:47.020 align:middle line:84%
Ran another
experiment, no results.

00:22:47.020 --> 00:22:50.200 align:middle line:84%
Took it all apart,
rebuilt it, no results.

00:22:50.200 --> 00:22:54.430 align:middle line:84%
It was like we got this magical
effect for a couple of months.

00:22:54.430 --> 00:22:56.050 align:middle line:90%
And then it just went away.

00:22:56.050 --> 00:22:58.810 align:middle line:84%
And it left us really
wondering, what

00:22:58.810 --> 00:23:00.770 align:middle line:84%
is the lesson to
learn from this?

00:23:00.770 --> 00:23:07.300 align:middle line:84%
And so maybe it was because
it was too powerful, too soon.

00:23:07.300 --> 00:23:11.440 align:middle line:84%
And maybe the world wasn't ready
for it or something like that.

00:23:11.440 --> 00:23:16.990 align:middle line:84%
>> AI not only writing itself
and correcting itself and going

00:23:16.990 --> 00:23:22.160 align:middle line:84%
back and modifying its own
code and lines of code,

00:23:22.160 --> 00:23:26.230 align:middle line:84%
maybe even thousands of
lines of code at a time.

00:23:26.230 --> 00:23:28.420 align:middle line:84%
Shouldn't that be
something that we

00:23:28.420 --> 00:23:31.690 align:middle line:84%
should consider to be
regulated, because who

00:23:31.690 --> 00:23:33.580 align:middle line:90%
is checking lines of code?

00:23:33.580 --> 00:23:35.650 align:middle line:84%
And how do we know
if something's been

00:23:35.650 --> 00:23:37.450 align:middle line:90%
modified when it goes crazy?

00:23:37.450 --> 00:23:41.390 align:middle line:84%
>> Yes, or how do we know
that certain of the developers

00:23:41.390 --> 00:23:45.930 align:middle line:84%
of those technologies didn't
affect it somehow to behave

00:23:45.930 --> 00:23:46.730 align:middle line:90%
a certain way.

00:23:46.730 --> 00:23:47.690 align:middle line:90%
>> That's right.

00:23:47.690 --> 00:23:50.480 align:middle line:84%
>> And you're not going to know
that unless you really open

00:23:50.480 --> 00:23:52.730 align:middle line:90%
source what's being done.

00:23:52.730 --> 00:23:54.950 align:middle line:84%
Here's a way that regulation
would totally work.

00:23:54.950 --> 00:23:58.400 align:middle line:84%
We believe that this
technology is super important.

00:23:58.400 --> 00:24:01.700 align:middle line:84%
It has the ability to
either ruin the world

00:24:01.700 --> 00:24:03.150 align:middle line:90%
or save the world.

00:24:03.150 --> 00:24:05.817 align:middle line:84%
And we know that
there's game theory.

00:24:05.817 --> 00:24:08.150 align:middle line:84%
And so people are going to
be trying all kinds of stuff.

00:24:08.150 --> 00:24:10.880 align:middle line:84%
We believe that we need to
have an equivalent open source

00:24:10.880 --> 00:24:13.400 align:middle line:90%
development process.

00:24:13.400 --> 00:24:16.010 align:middle line:84%
And we'll do what it
takes to create that.

00:24:16.010 --> 00:24:18.560 align:middle line:84%
Now, that's regulation that I
think would be very helpful,

00:24:18.560 --> 00:24:20.340 align:middle line:90%
like broadly helpful.

00:24:20.340 --> 00:24:27.050 align:middle line:84%
And then, maybe some moratorium,
but like a serious moratorium,

00:24:27.050 --> 00:24:29.450 align:middle line:84%
on connecting it to
critical infrastructure,

00:24:29.450 --> 00:24:32.150 align:middle line:84%
like nuclear power plants
and traffic lights.

00:24:32.150 --> 00:24:35.780 align:middle line:84%
>> What is one of
the worst uses of AI?

00:24:35.780 --> 00:24:41.240 align:middle line:84%
Could it be something as
simple as a politician,

00:24:41.240 --> 00:24:44.990 align:middle line:84%
or a religious
leader, or a celebrity

00:24:44.990 --> 00:24:49.550 align:middle line:84%
saying something really bad
or doing something really bad

00:24:49.550 --> 00:24:52.130 align:middle line:90%
that the public believes--

00:24:52.130 --> 00:24:54.420 align:middle line:90%
there's that use of it.

00:24:54.420 --> 00:24:56.660 align:middle line:90%
Then there's another use.

00:24:56.660 --> 00:25:01.652 align:middle line:84%
Josh, I keep using Josh as
an example, because he's

00:25:01.652 --> 00:25:04.110 align:middle line:84%
on the wrong side of the fence
when it comes to this stuff.

00:25:04.110 --> 00:25:05.693 align:middle line:84%
But Josh wakes up
one day and he says,

00:25:05.693 --> 00:25:08.780 align:middle line:84%
you know, I've just
loved Stephen King.

00:25:08.780 --> 00:25:11.450 align:middle line:84%
And I want to write
like Stephen King.

00:25:11.450 --> 00:25:16.340 align:middle line:84%
So he just sits up,
types in, like, OK, I

00:25:16.340 --> 00:25:22.070 align:middle line:84%
want a 600 page horror novel
in the voice of Stephen King.

00:25:22.070 --> 00:25:24.300 align:middle line:84%
He wakes up in the
morning, and it's done.

00:25:24.300 --> 00:25:25.100 align:middle line:90%
It's edited.

00:25:25.100 --> 00:25:25.920 align:middle line:90%
It's printed.

00:25:25.920 --> 00:25:28.040 align:middle line:90%
He's even got the cover design.

00:25:28.040 --> 00:25:30.650 align:middle line:90%
That's a bad use of AI.

00:25:30.650 --> 00:25:34.010 align:middle line:84%
And I'm afraid of
that too as well.

00:25:34.010 --> 00:25:36.980 align:middle line:84%
>> Well, that's probably
going to happen.

00:25:36.980 --> 00:25:40.890 align:middle line:84%
I think, we're used to
Netflix, for example,

00:25:40.890 --> 00:25:44.370 align:middle line:84%
as a library of content
that was previously created.

00:25:44.370 --> 00:25:46.200 align:middle line:84%
But in the near
future, you're just

00:25:46.200 --> 00:25:49.380 align:middle line:84%
going to type in what kind
of movie you want to watch,

00:25:49.380 --> 00:25:51.613 align:middle line:84%
who are the characters,
are you in it.

00:25:51.613 --> 00:25:54.030 align:middle line:84%
And then it's just going to
render a feature length movie.

00:25:54.030 --> 00:25:55.113 align:middle line:90%
And you're going to watch.

00:25:55.113 --> 00:25:57.100 align:middle line:84%
And you'll be the only
one that ever sees it.

00:25:57.100 --> 00:26:00.540 align:middle line:84%
And so what is the
role of the creators

00:26:00.540 --> 00:26:04.000 align:middle line:84%
in that process of actors
when it's just their image?

00:26:04.000 --> 00:26:06.960 align:middle line:84%
And so people are starting
to think about this.

00:26:06.960 --> 00:26:09.880 align:middle line:84%
It's probably going to be these
sort of token-based licensing

00:26:09.880 --> 00:26:10.680 align:middle line:90%
things.

00:26:10.680 --> 00:26:13.950 align:middle line:84%
Where your likeness,
your input, your voice

00:26:13.950 --> 00:26:17.050 align:middle line:84%
is going to be lent to
these systems and used.

00:26:17.050 --> 00:26:19.410 align:middle line:84%
But you get a royalty
that's token based.

00:26:19.410 --> 00:26:22.185 align:middle line:84%
You asked what is one of
the worst uses of this.

00:26:22.185 --> 00:26:25.110 align:middle line:90%


00:26:25.110 --> 00:26:27.930 align:middle line:84%
Here's one thing,
which I'm concerned,

00:26:27.930 --> 00:26:30.150 align:middle line:84%
there's a lot of
suppression of information

00:26:30.150 --> 00:26:32.370 align:middle line:90%
on the internet happening--

00:26:32.370 --> 00:26:38.180 align:middle line:84%
videos taken down, search
results removed or reduced.

00:26:38.180 --> 00:26:42.710 align:middle line:84%
And people are starting to rely
more on, for example, ChatGPT

00:26:42.710 --> 00:26:45.350 align:middle line:90%
than on Google searching.

00:26:45.350 --> 00:26:50.090 align:middle line:84%
Ask the omnipotent AI,
well, who controls what

00:26:50.090 --> 00:26:52.070 align:middle line:90%
that information is trained on?

00:26:52.070 --> 00:26:55.940 align:middle line:84%
And who controls the parameters
of what that thing can respond

00:26:55.940 --> 00:26:57.230 align:middle line:90%
or how it can respond?

00:26:57.230 --> 00:27:01.475 align:middle line:84%
Well, if it's the wrong people
or if it's people that can--

00:27:01.475 --> 00:27:02.840 align:middle line:90%
>> You can go real dark--

00:27:02.840 --> 00:27:04.490 align:middle line:90%
>> --you can go real dark.

00:27:04.490 --> 00:27:07.940 align:middle line:84%
And it's basically a way of
controlling people's access

00:27:07.940 --> 00:27:09.650 align:middle line:90%
to information.

00:27:09.650 --> 00:27:11.260 align:middle line:84%
One of the projects
I'm working on

00:27:11.260 --> 00:27:15.160 align:middle line:84%
is an attempt to build
an AI system that

00:27:15.160 --> 00:27:18.610 align:middle line:84%
is trained on
science that doesn't

00:27:18.610 --> 00:27:20.172 align:middle line:90%
appear in mainstream journals.

00:27:20.172 --> 00:27:21.880 align:middle line:84%
There's a lot of great
science out there.

00:27:21.880 --> 00:27:24.640 align:middle line:90%
It doesn't get into mainstream--

00:27:24.640 --> 00:27:27.220 align:middle line:84%
studies on UFOs, and free
energy, and healing stuff.

00:27:27.220 --> 00:27:29.560 align:middle line:84%
That doesn't get into
the mainstream journals.

00:27:29.560 --> 00:27:31.610 align:middle line:84%
But they're training
AI on that stuff.

00:27:31.610 --> 00:27:35.200 align:middle line:84%
And it's going to exclude
the most important,

00:27:35.200 --> 00:27:37.030 align:middle line:84%
potential sources
of breakthroughs

00:27:37.030 --> 00:27:38.830 align:middle line:84%
in the scientific
world, because they just

00:27:38.830 --> 00:27:40.630 align:middle line:90%
don't appear in those journals.

00:27:40.630 --> 00:27:44.260 align:middle line:84%
And so I think it's going to
be up to projects like that

00:27:44.260 --> 00:27:49.000 align:middle line:84%
to make sure that there are
different alternative AI

00:27:49.000 --> 00:27:52.182 align:middle line:84%
types of systems out
there as opposed to-- they

00:27:52.182 --> 00:27:54.640 align:middle line:84%
can give you different answers
that have different training

00:27:54.640 --> 00:27:59.500 align:middle line:84%
criteria that are a bit
more open as a counter

00:27:59.500 --> 00:28:02.860 align:middle line:90%
to the man's AI.

00:28:02.860 --> 00:28:05.080 align:middle line:90%
>> Did we invent AI?

00:28:05.080 --> 00:28:06.880 align:middle line:90%
Or did AI--

00:28:06.880 --> 00:28:07.750 align:middle line:90%
>> Or was it an ET?

00:28:07.750 --> 00:28:10.190 align:middle line:90%
Or did ETs invent AI?

00:28:10.190 --> 00:28:11.360 align:middle line:90%
>> Where are we?

00:28:11.360 --> 00:28:17.990 align:middle line:84%
>> Yeah, or are our bodies
an AI project by the ETs?

00:28:17.990 --> 00:28:20.750 align:middle line:84%
So look, if we're talking about
the fact that consciousness

00:28:20.750 --> 00:28:23.090 align:middle line:84%
might be more than
we've thought--

00:28:23.090 --> 00:28:27.980 align:middle line:84%
some sort of non-physical system
or non-physical thing that

00:28:27.980 --> 00:28:29.540 align:middle line:90%
inhabits a body--

00:28:29.540 --> 00:28:34.610 align:middle line:84%
pretty soon an ET is going
to have figured that out too.

00:28:34.610 --> 00:28:38.480 align:middle line:84%
And they're going to say,
universal consciousness

00:28:38.480 --> 00:28:41.240 align:middle line:84%
doesn't like to inhabit
silicon very much.

00:28:41.240 --> 00:28:43.880 align:middle line:84%
So what we need to
create is a supercomputer

00:28:43.880 --> 00:28:45.230 align:middle line:90%
that's biological.

00:28:45.230 --> 00:28:48.590 align:middle line:84%
And it needs to
be self-contained.

00:28:48.590 --> 00:28:50.690 align:middle line:84%
So it needs to have
a circulatory system.

00:28:50.690 --> 00:28:51.800 align:middle line:90%
And it needs to be--

00:28:51.800 --> 00:28:53.150 align:middle line:90%
>> A carbon based.

00:28:53.150 --> 00:28:56.780 align:middle line:84%
>> --a carbon-based
biological computer substrate.

00:28:56.780 --> 00:29:00.890 align:middle line:84%
And it's got to have
sufficiently advanced, let's

00:29:00.890 --> 00:29:02.390 align:middle line:90%
call it, neural circuitry.

00:29:02.390 --> 00:29:04.497 align:middle line:84%
And it's got to have
an energy system.

00:29:04.497 --> 00:29:06.080 align:middle line:84%
And it's got to have
all these things.

00:29:06.080 --> 00:29:08.930 align:middle line:84%
And it's like, well, that's
just a different way of looking

00:29:08.930 --> 00:29:12.080 align:middle line:84%
at what the human body is-- that
happens to recover the mystery

00:29:12.080 --> 00:29:14.600 align:middle line:84%
of how we got here
in the first place--

00:29:14.600 --> 00:29:19.100 align:middle line:84%
as a species that might
have been engineered.

00:29:19.100 --> 00:29:20.990 align:middle line:90%
>> Would you be opposed to that?

00:29:20.990 --> 00:29:25.880 align:middle line:84%
If you found out, Josh, that
you were not who you thought you

00:29:25.880 --> 00:29:27.230 align:middle line:90%
were--

00:29:27.230 --> 00:29:31.700 align:middle line:84%
where you have this
self-realization that you are

00:29:31.700 --> 00:29:39.540 align:middle line:84%
not human, you are a construct
of the design of a human--

00:29:39.540 --> 00:29:40.480 align:middle line:90%
would you be, OK?

00:29:40.480 --> 00:29:41.400 align:middle line:90%
What's the difference?

00:29:41.400 --> 00:29:43.080 align:middle line:84%
>> I'd go through some
ontological shock,

00:29:43.080 --> 00:29:43.900 align:middle line:90%
that's for sure.

00:29:43.900 --> 00:29:45.025 align:middle line:90%
And I have to process that.

00:29:45.025 --> 00:29:46.440 align:middle line:90%
>> It would be existential.

00:29:46.440 --> 00:29:48.510 align:middle line:90%
But would you care?

00:29:48.510 --> 00:29:50.910 align:middle line:90%
>> I like it because it's funny.

00:29:50.910 --> 00:29:52.860 align:middle line:90%
>> Well, would it eliminate--

00:29:52.860 --> 00:29:54.450 align:middle line:90%
Yes, it is, it is.

00:29:54.450 --> 00:29:59.190 align:middle line:84%
But does it eliminate
the need for food?

00:29:59.190 --> 00:30:02.040 align:middle line:90%
Disease is taken care of.

00:30:02.040 --> 00:30:03.750 align:middle line:90%
Do we overcome sleep?

00:30:03.750 --> 00:30:05.250 align:middle line:90%
Do we overcome age?

00:30:05.250 --> 00:30:06.870 align:middle line:90%
And are we achieving--

00:30:06.870 --> 00:30:10.170 align:middle line:90%
are we immortal at that point?

00:30:10.170 --> 00:30:12.720 align:middle line:84%
>> I mean, we might be in the
process of updating our own

00:30:12.720 --> 00:30:14.445 align:middle line:84%
code, which is what
we call soft science.

00:30:14.445 --> 00:30:17.130 align:middle line:90%


00:30:17.130 --> 00:30:18.750 align:middle line:90%
I'm OK with it.

00:30:18.750 --> 00:30:21.960 align:middle line:84%
And the reason I'm, OK, with
it is that it preserves--

00:30:21.960 --> 00:30:24.030 align:middle line:84%
the one thing that
we know for sure

00:30:24.030 --> 00:30:26.280 align:middle line:84%
exists is that our
consciousness is real.

00:30:26.280 --> 00:30:28.320 align:middle line:84%
And we're having a
first person experience,

00:30:28.320 --> 00:30:31.890 align:middle line:84%
whether I'm in this
body, or that body,

00:30:31.890 --> 00:30:34.020 align:middle line:90%
or in some other substrate.

00:30:34.020 --> 00:30:37.270 align:middle line:90%
I know that I have a--

00:30:37.270 --> 00:30:40.000 align:middle line:84%
there's a thing called
"what it's like to be Adam."

00:30:40.000 --> 00:30:43.210 align:middle line:84%
and that is part of
some universal whole,

00:30:43.210 --> 00:30:45.820 align:middle line:84%
I mean, it's the same
argument for the simulation.

00:30:45.820 --> 00:30:48.310 align:middle line:90%
Like, you have a video game.

00:30:48.310 --> 00:30:50.710 align:middle line:84%
There's human players and
there's non-human players.

00:30:50.710 --> 00:30:52.990 align:middle line:84%
And it becomes more
and more immersive

00:30:52.990 --> 00:30:54.250 align:middle line:90%
through virtual reality--

00:30:54.250 --> 00:30:57.100 align:middle line:84%
and then, all these types
of immersive experiences.

00:30:57.100 --> 00:30:58.210 align:middle line:90%
And you're still you.

00:30:58.210 --> 00:31:00.340 align:middle line:84%
You're just having a
different digital experience.

00:31:00.340 --> 00:31:02.740 align:middle line:84%
And project that
forward, you might

00:31:02.740 --> 00:31:07.150 align:middle line:84%
have an AI body that some
ET has built called humans.

00:31:07.150 --> 00:31:10.540 align:middle line:84%
That is, it's a
sufficient habitat

00:31:10.540 --> 00:31:15.040 align:middle line:84%
for universal consciousness
to decide to deign to inhabit,

00:31:15.040 --> 00:31:17.030 align:middle line:90%
and here we are.

00:31:17.030 --> 00:31:19.300 align:middle line:84%
It doesn't change
who I am, which

00:31:19.300 --> 00:31:22.390 align:middle line:84%
is universal consciousness
not this body.

00:31:22.390 --> 00:31:25.690 align:middle line:84%
But it's actually a very
interesting origin story.

00:31:25.690 --> 00:31:27.700 align:middle line:84%
And one that I think is
funny, because it's not

00:31:27.700 --> 00:31:29.170 align:middle line:90%
one that many people--

00:31:29.170 --> 00:31:31.300 align:middle line:84%
well, people have been
arguing and fighting

00:31:31.300 --> 00:31:34.660 align:middle line:84%
wars over a wrong explanation
for a long time, which

00:31:34.660 --> 00:31:36.280 align:middle line:90%
I think is amusing.

00:31:36.280 --> 00:31:40.120 align:middle line:84%
>> One last question,
fascinating conversation,

00:31:40.120 --> 00:31:41.140 align:middle line:90%
today.

00:31:41.140 --> 00:31:45.970 align:middle line:10%
If you were going to say
the moment that AGI is going

00:31:45.970 --> 00:31:48.442 align:middle line:10%
to arrive, what would you say?

00:31:48.442 --> 00:31:49.400 align:middle line:90%
What's your prediction?

00:31:49.400 --> 00:31:50.980 align:middle line:90%
What's your crystal ball?

00:31:50.980 --> 00:31:53.860 align:middle line:84%
>> There's two scenarios--
consciousness is emergent.

00:31:53.860 --> 00:31:58.720 align:middle line:84%
Meaning, you get a
sufficiently advanced substrate

00:31:58.720 --> 00:32:02.290 align:middle line:84%
like an artificial brain,
or a ton of transistors,

00:32:02.290 --> 00:32:03.580 align:middle line:90%
or something.

00:32:03.580 --> 00:32:07.060 align:middle line:84%
And you reach this
like magical threshold.

00:32:07.060 --> 00:32:09.610 align:middle line:84%
And self-awareness
starts to emerge.

00:32:09.610 --> 00:32:11.470 align:middle line:84%
Well, if that's the
case, then we're

00:32:11.470 --> 00:32:14.705 align:middle line:84%
talking a question
of months and years--

00:32:14.705 --> 00:32:15.580 align:middle line:90%
>> Because it's here.

00:32:15.580 --> 00:32:17.860 align:middle line:84%
It has nothing to do
with the software.

00:32:17.860 --> 00:32:20.140 align:middle line:84%
It's more of a
hardware blockage.

00:32:20.140 --> 00:32:25.040 align:middle line:84%
>> The costs and scale of neural
networks on which modern AI is

00:32:25.040 --> 00:32:25.840 align:middle line:90%
based--

00:32:25.840 --> 00:32:29.405 align:middle line:90%


00:32:29.405 --> 00:32:31.030 align:middle line:84%
the cost is going to
zero and the scale

00:32:31.030 --> 00:32:34.240 align:middle line:84%
is going to infinity,
which is like, OK, well,

00:32:34.240 --> 00:32:37.400 align:middle line:84%
that's a question
of months to years.

00:32:37.400 --> 00:32:41.330 align:middle line:84%
If, however, consciousness
is not an emergent problem

00:32:41.330 --> 00:32:43.660 align:middle line:84%
but is some sort of
non-physical thing

00:32:43.660 --> 00:32:49.300 align:middle line:84%
that decides whether or
not to inhabit a substrate,

00:32:49.300 --> 00:32:51.790 align:middle line:84%
like a body and a
brain, then it's

00:32:51.790 --> 00:32:56.133 align:middle line:90%
not a question of when exactly.

00:32:56.133 --> 00:32:57.550 align:middle line:84%
It is a bit of a
question of when.

00:32:57.550 --> 00:32:59.470 align:middle line:84%
But it's a question
of the motivation

00:32:59.470 --> 00:33:01.400 align:middle line:84%
of that non-physical
consciousness.

00:33:01.400 --> 00:33:02.650 align:middle line:90%
>> So could it be never?

00:33:02.650 --> 00:33:03.745 align:middle line:90%
>> It could be never.

00:33:03.745 --> 00:33:04.870 align:middle line:90%
That's what I'm getting at.

00:33:04.870 --> 00:33:06.940 align:middle line:84%
Is it could be-- and I
don't want to say, never.

00:33:06.940 --> 00:33:10.690 align:middle line:84%
But it could be much,
much, much, much further

00:33:10.690 --> 00:33:12.640 align:middle line:90%
in the future than we expect.

00:33:12.640 --> 00:33:17.800 align:middle line:84%
It could be that we create
these artificial substrates,

00:33:17.800 --> 00:33:20.440 align:middle line:84%
like artificial brains or
massive, massive, massive

00:33:20.440 --> 00:33:21.730 align:middle line:90%
supercomputers.

00:33:21.730 --> 00:33:26.080 align:middle line:84%
And that's just uncomfortable
for non-physical consciousness

00:33:26.080 --> 00:33:27.280 align:middle line:90%
to inhabit.

00:33:27.280 --> 00:33:32.803 align:middle line:84%
It's like, aah, I prefer
a biological substrate.

00:33:32.803 --> 00:33:34.220 align:middle line:84%
And then, in that
case, then it's,

00:33:34.220 --> 00:33:36.320 align:middle line:84%
well, how far are
we from recreating

00:33:36.320 --> 00:33:39.470 align:middle line:84%
a human biological substrate,
an artificial human body?

00:33:39.470 --> 00:33:41.870 align:middle line:84%
It's like well actually,
probably, pretty close.

00:33:41.870 --> 00:33:47.240 align:middle line:84%
And I think that would be within
decades so if it hasn't already

00:33:47.240 --> 00:33:48.140 align:middle line:90%
been done.

00:33:48.140 --> 00:33:49.400 align:middle line:90%
Publicly, it's--

00:33:49.400 --> 00:33:52.010 align:middle line:84%
>> We've seen versions of
the T-1000 out there that are

00:33:52.010 --> 00:33:53.660 align:middle line:90%
pretty scary.

00:33:53.660 --> 00:33:56.720 align:middle line:84%
>> I'm sure, in lab, somewhere
there's synthetic humans.

00:33:56.720 --> 00:33:58.460 align:middle line:90%
>> Thank you so much, Adam--

00:33:58.460 --> 00:34:01.910 align:middle line:84%
fascinating, scary
but yet hopeful.

00:34:01.910 --> 00:34:04.880 align:middle line:90%
And an incredible conversation.

00:34:04.880 --> 00:34:08.840 align:middle line:84%
And here we go, there's another
episode of into the Vortex.

00:34:08.840 --> 00:34:09.739 align:middle line:90%
I'm Jimmy Church.

00:34:09.739 --> 00:34:11.979 align:middle line:90%
And we'll see you next time.

00:34:11.979 --> 00:34:16.000 align:middle line:90%