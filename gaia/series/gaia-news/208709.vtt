WEBVTT

00:00:00.000 --> 00:00:03.990 align:middle line:84%
>> Given the exponential growth
of artificial intelligence,

00:00:03.990 --> 00:00:06.930 align:middle line:84%
many are calling for
more rigorous regulation.

00:00:06.930 --> 00:00:09.450 align:middle line:84%
Can the potentially
disastrous consequences

00:00:09.450 --> 00:00:12.900 align:middle line:84%
be avoided by imbuing AI
with positive human values

00:00:12.900 --> 00:00:15.060 align:middle line:90%
such as compassion?

00:00:15.060 --> 00:00:17.400 align:middle line:84%
Thought leader Gregg
Braden shares the latest

00:00:17.400 --> 00:00:20.250 align:middle line:84%
on how this can be
done and why it's never

00:00:20.250 --> 00:00:22.200 align:middle line:90%
been more important to do so.

00:00:22.200 --> 00:00:28.350 align:middle line:10%
>> If we are at the
foundation of a new evolution,

00:00:28.350 --> 00:00:33.090 align:middle line:10%
perhaps a new life form that
we, in fact, are designing,

00:00:33.090 --> 00:00:36.815 align:middle line:10%
it's important to get it
right at the foundation.

00:00:36.815 --> 00:00:38.655 align:middle line:90%
>> This is Gaia News.

00:00:38.655 --> 00:00:47.600 align:middle line:90%


00:00:47.600 --> 00:00:51.170 align:middle line:10%
Gregg Braden is a former senior
computer systems designer,

00:00:51.170 --> 00:00:53.870 align:middle line:10%
best-selling author,
and leader in the fields

00:00:53.870 --> 00:00:56.095 align:middle line:10%
of science and spirituality.

00:00:56.095 --> 00:00:59.870 align:middle line:10%
>> The topic of compassion
in artificial intelligence,

00:00:59.870 --> 00:01:03.620 align:middle line:10%
while in many circles people
have never heard of it,

00:01:03.620 --> 00:01:07.070 align:middle line:10%
in the circles of science and
technology, it's a hot topic.

00:01:07.070 --> 00:01:08.600 align:middle line:10%
In one way or
another, this topic

00:01:08.600 --> 00:01:10.310 align:middle line:10%
is going to touch
each of our lives

00:01:10.310 --> 00:01:12.440 align:middle line:10%
and it's going to
happen faster than we

00:01:12.440 --> 00:01:13.700 align:middle line:10%
have been led to believe.

00:01:13.700 --> 00:01:16.310 align:middle line:10%
Humankind is at a
crossroad right now

00:01:16.310 --> 00:01:19.670 align:middle line:10%
for the first time in the
history of our species

00:01:19.670 --> 00:01:23.360 align:middle line:10%
where we have the
technology to support

00:01:23.360 --> 00:01:26.480 align:middle line:10%
the philosophy of the way
we think about ourselves

00:01:26.480 --> 00:01:30.050 align:middle line:10%
and our relationship
to the world around us,

00:01:30.050 --> 00:01:33.350 align:middle line:10%
to software, to robots to
artificial intelligence,

00:01:33.350 --> 00:01:38.330 align:middle line:10%
to machine intelligence,
the development of AI

00:01:38.330 --> 00:01:40.490 align:middle line:10%
is moving at an
exponential rate.

00:01:40.490 --> 00:01:43.430 align:middle line:10%
It's no longer linear
and it's not regulated.

00:01:43.430 --> 00:01:45.500 align:middle line:10%
We're talking about
AI that is going

00:01:45.500 --> 00:01:49.880 align:middle line:10%
to be running huge national
and international systems

00:01:49.880 --> 00:01:54.140 align:middle line:10%
of electricity, of power, of
energy, of water, of food,

00:01:54.140 --> 00:01:57.900 align:middle line:10%
of weapons systems that are
the reality of our lives today.

00:01:57.900 --> 00:02:01.520 align:middle line:10%
So if we're going to allow
artificial intelligence to play

00:02:01.520 --> 00:02:04.490 align:middle line:10%
a vital role in our lives,
we want that intelligence

00:02:04.490 --> 00:02:06.110 align:middle line:10%
to be more than intelligent.

00:02:06.110 --> 00:02:07.880 align:middle line:10%
We want it to be smart.

00:02:07.880 --> 00:02:10.400 align:middle line:10%
We want it to be
intuitive, we want

00:02:10.400 --> 00:02:13.700 align:middle line:10%
it to be compassionate as
it makes the decisions that

00:02:13.700 --> 00:02:16.271 align:middle line:10%
affect all of our lives.

00:02:16.271 --> 00:02:19.610 align:middle line:84%
>> So what exactly is
meant by compassionate AI?

00:02:19.610 --> 00:02:23.683 align:middle line:10%
>> First of all, if we're going
to imbue machine intelligence

00:02:23.683 --> 00:02:25.850 align:middle line:10%
with compassion, we have
to know what compassion is.

00:02:25.850 --> 00:02:31.460 align:middle line:84%
Compassion is where we
not only feel, empathize

00:02:31.460 --> 00:02:33.170 align:middle line:84%
with the suffering of
another but then we

00:02:33.170 --> 00:02:36.680 align:middle line:84%
choose to act in some way
to mitigate that suffering.

00:02:36.680 --> 00:02:38.240 align:middle line:84%
So in a nutshell,
this is what we're

00:02:38.240 --> 00:02:40.310 align:middle line:84%
talking about when
we say compassion

00:02:40.310 --> 00:02:42.350 align:middle line:84%
from the perspective
of programming

00:02:42.350 --> 00:02:45.260 align:middle line:90%
it into a machine intelligence.

00:02:45.260 --> 00:02:51.200 align:middle line:10%
If we are at the foundation
of a new evolution

00:02:51.200 --> 00:02:56.000 align:middle line:10%
perhaps a new life form that
we, in fact, are designing,

00:02:56.000 --> 00:02:59.840 align:middle line:10%
it's important to get it
right at the foundation.

00:02:59.840 --> 00:03:03.950 align:middle line:10%
Is it that we want to
imbue this new life

00:03:03.950 --> 00:03:08.975 align:middle line:10%
form with the cherished
values of our own experience?

00:03:08.975 --> 00:03:11.900 align:middle line:84%
>> Given that artificial
intelligence is designed

00:03:11.900 --> 00:03:15.860 align:middle line:84%
to accomplish a specific goal,
what role does compassionate

00:03:15.860 --> 00:03:19.480 align:middle line:84%
design play in the ethical
achievement of that goal?

00:03:19.480 --> 00:03:24.050 align:middle line:10%
>> The important thing is
for that intelligence to have

00:03:24.050 --> 00:03:28.140 align:middle line:10%
mitigating factors as it
is approaching that goal.

00:03:28.140 --> 00:03:31.670 align:middle line:10%
So it doesn't see humans as a
nuisance getting in the way.

00:03:31.670 --> 00:03:35.750 align:middle line:84%
In other words, when we go
to accomplish something,

00:03:35.750 --> 00:03:38.323 align:middle line:84%
we want to drive from
point A to point B.

00:03:38.323 --> 00:03:39.740 align:middle line:84%
So our goal is to
drive to point A

00:03:39.740 --> 00:03:42.020 align:middle line:84%
to point B. A machine
intelligence could

00:03:42.020 --> 00:03:42.980 align:middle line:90%
have that same goal.

00:03:42.980 --> 00:03:45.800 align:middle line:10%
For us, driving
point A to point B,

00:03:45.800 --> 00:03:49.520 align:middle line:10%
what if a little kid doesn't
understand traffic signs

00:03:49.520 --> 00:03:51.210 align:middle line:10%
and walks out in front of us?

00:03:51.210 --> 00:03:55.970 align:middle line:10%
We have the ability to
mitigate our actions based

00:03:55.970 --> 00:03:59.210 align:middle line:10%
upon that scenario, unless
the artificial intelligence

00:03:59.210 --> 00:04:04.320 align:middle line:10%
is imbued with similar abilities
we can have disastrous effects.

00:04:04.320 --> 00:04:07.700 align:middle line:84%
>> Braden believes that the
design of compassionate AI

00:04:07.700 --> 00:04:10.070 align:middle line:84%
needs to be modeled
on human behavior.

00:04:10.070 --> 00:04:14.480 align:middle line:10%
>> When we have compassion,
we are dynamically interacting

00:04:14.480 --> 00:04:15.570 align:middle line:10%
with our environment.

00:04:15.570 --> 00:04:17.390 align:middle line:10%
We're picking up subtle cues.

00:04:17.390 --> 00:04:19.970 align:middle line:84%
When we are with another
who is suffering,

00:04:19.970 --> 00:04:22.560 align:middle line:84%
we will hear inflections
in their voice.

00:04:22.560 --> 00:04:25.380 align:middle line:84%
We will hear frequency
changes in their voice.

00:04:25.380 --> 00:04:29.330 align:middle line:84%
We will sense changes in their
heart and their heart rate

00:04:29.330 --> 00:04:31.820 align:middle line:84%
variability through
electromagnetic fields.

00:04:31.820 --> 00:04:35.090 align:middle line:84%
We will sense the release
of photons in the body.

00:04:35.090 --> 00:04:37.040 align:middle line:10%
Now, science knows this.

00:04:37.040 --> 00:04:38.780 align:middle line:10%
They're only
beginning to embrace

00:04:38.780 --> 00:04:42.950 align:middle line:10%
what it means if we're going
to imbue machine intelligence

00:04:42.950 --> 00:04:44.420 align:middle line:10%
with true compassion.

00:04:44.420 --> 00:04:47.420 align:middle line:10%
Then these capabilities
that we have the ability

00:04:47.420 --> 00:04:50.630 align:middle line:10%
to pick up these subtle
cues within the context

00:04:50.630 --> 00:04:53.480 align:middle line:10%
of the moment and
put them together

00:04:53.480 --> 00:04:56.660 align:middle line:10%
to elicit a genuine
state of compassion

00:04:56.660 --> 00:05:00.450 align:middle line:10%
and the compassionate
response is what we're after.

00:05:00.450 --> 00:05:04.550 align:middle line:84%
>> While this compassionate AI
design is still in its infancy,

00:05:04.550 --> 00:05:07.160 align:middle line:84%
Braden has high
hopes for its future.

00:05:07.160 --> 00:05:10.610 align:middle line:10%
>> So to me, this is a
very exciting new frontier

00:05:10.610 --> 00:05:17.870 align:middle line:10%
because in our desire to
further the frontier of machine

00:05:17.870 --> 00:05:19.970 align:middle line:10%
intelligence,
synthetic intelligence,

00:05:19.970 --> 00:05:22.400 align:middle line:10%
or what is often called
artificial intelligence,

00:05:22.400 --> 00:05:26.180 align:middle line:10%
we must understand
ourselves on a level,

00:05:26.180 --> 00:05:28.610 align:middle line:10%
perhaps the deepest
level we ever have,

00:05:28.610 --> 00:05:31.730 align:middle line:10%
and maybe for the first time we
discover for ourselves what it

00:05:31.730 --> 00:05:34.040 align:middle line:10%
means to be truly human.

00:05:34.040 --> 00:05:38.600 align:middle line:10%
>> For a new perspective,
this is Gaia News.

00:05:38.600 --> 00:05:40.830 align:middle line:10%
For more information
on this topic,

00:05:40.830 --> 00:05:43.780 align:middle line:10%
check out this content on Gaia.

00:05:43.780 --> 00:05:45.000 align:middle line:90%