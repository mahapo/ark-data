[{"pageNumber":1,"pageContent":"Chaos: A Very Short Introduction"},{"pageNumber":2,"pageContent":"Very Short Introductions are for anyone wanting a stimulatingand accessible way in to a new subject. They are written by experts, and havebeen published in more than 25 languages worldwide.The series began in 1995, and now represents a wide variety of topicsin history, philosophy, religion, science, and the humanities. Over the nextfew years it will grow to a library of around 200 volumes – a Very ShortIntroduction to everything from ancient Egypt and Indian philosophy toconceptual art and cosmology.Very Short Introductions available now:ANARCHISMColin WardANCIENT EGYPTIan ShawANCIENT PHILOSOPHYJulia AnnasANCIENT WARFAREHarry SidebottomANGLICANISMMark ChapmanTHE ANGLO-SAXON AGEJohn BlairANIMAL RIGHTSDavid DeGraziaARCHAEOLOGYPaul BahnARCHITECTUREAndrew BallantyneARISTOTLEJonathan BarnesART HISTORYDana ArnoldART THEORY Cynthia FreelandTHE HISTORY OFASTRONOMY Michael HoskinAtheismJulian Baggini AugustineHenry ChadwickBARTHESJonathan CullerTHE BIBLEJohn RichesTHE BRAINMichael O’SheaBRITISH POLITICSAnthony WrightBuddhaMichael CarrithersBUDDHISMDamien KeownBUDDHIST ETHICSDamien KeownCAPITALISMJames FulcherTHE CELTSBarry Cunliffe CHAOS Leonard SmithCHOICE THEORYMichael AllinghamCHRISTIAN ARTBeth WilliamsonCHRISTIANITYLinda WoodheadCLASSICS Mary Beard andJohn HendersonCLAUSEWITZMichael HowardTHE COLD WARRobert McMahonCONSCIOUSNESSSusan BlackmoreCONTEMPORARY ARTJulian StallabrassContinental PhilosophySimon CritchleyCOSMOLOGYPeter ColesTHE CRUSADESChristopher TyermanCRYPTOGRAPHYFred Piper and Sean MurphyDADA AND SURREALISMDavid HopkinsDarwinJonathan HowardTHE DEAD SEA SCROLLSTimothy LimDemocracyBernard CrickDESCARTESTom SorellDESIGNJohn HeskettDINOSAURSDavid NormanDREAMINGJ. Allan HobsonDRUGSLeslie IversenTHE EARTHMartin RedfernECONOMICS Partha DasguptaEGYPTIAN MYTH Geraldine Pinch"},{"pageNumber":3,"pageContent":"EIGHTEENTH-CENTURYBRITAINPaul LangfordTHE ELEMENTSPhilip BallEMOTIONDylan EvansEMPIREStephen HoweENGELSTerrell CarverEthicsSimon BlackburnThe European UnionJohn PinderEVOLUTIONBrian and Deborah CharlesworthEXISTENTIALISM Thomas FlynnFASCISMKevin PassmoreFEMINISMMargaret WaltersTHE FIRST WORLD WARMichael HowardFOSSILSKeith ThomsonFOUCAULTGary GuttingTHE FRENCH REVOLUTIONWilliam DoyleFREE WILLThomas PinkFreudAnthony StorrFUNDAMENTALISMMalise RuthvenGalileoStillman DrakeGandhiBhikhu ParekhGLOBAL CATASTROPHESBill McGuireGLOBALIZATION Manfred StegerGLOBAL WARMING Mark MaslinHABERMASJames Gordon FinlaysonHEGELPeter SingerHEIDEGGERMichael InwoodHIEROGLYPHSPenelope WilsonHINDUISMKim KnottHISTORYJohn H. ArnoldHOBBESRichard TuckHUMAN EVOLUTIONBernard WoodHUMEA. J. AyerIDEOLOGYMichael FreedenIndian PhilosophySue HamiltonIntelligenceIan J. DearyINTERNATIONALMIGRATION Khalid KoserISLAMMalise RuthvenJOURNALISMIan HargreavesJUDAISMNorman SolomonJungAnthony StevensKAFKARitchie RobertsonKANTRoger ScrutonKIERKEGAARDPatrick GardinerTHE KORANMichael CookLINGUISTICSPeter MatthewsLITERARY THEORYJonathan CullerLOCKEJohn DunnLOGICGraham PriestMACHIAVELLIQuentin SkinnerTHE MARQUIS DE SADEJohn PhillipsMARXPeter SingerMATHEMATICSTimothy GowersMEDICAL ETHICSTo ny H o p eMEDIEVAL BRITAINJohn Gillingham andRalph A. GriffithsMODERN ARTDavid CottingtonMODERN IRELANDSenia Pasˇe t aMOLECULESPhilip BallMUSICNicholas CookMythRobert A. Segal NATIONALISMSteven GrosbyNEWTON Robert IliffeNIETZSCHEMichael TannerNINETEENTH-CENTURYBRITAINChristopher Harvie andH. C. G. MatthewNORTHERN IRELANDMarc MulhollandPARTICLE PHYSICSFrank ClosepaulE. P. SandersPhilosophyEdward CraigPHILOSOPHY OF LAWRaymond Wacks"},{"pageNumber":4,"pageContent":"PHILOSOPHY OF SCIENCESamir OkashaPHOTOGRAPHY Steve EdwardsPLATOJulia AnnasPOLITICSKenneth MinoguePOLITICAL PHILOSOPHYDavid MillerPOSTCOLONIALISMRobert YoungPOSTMODERNISMChristopher ButlerPOSTSTRUCTURALISMCatherine BelseyPREHISTORYChris GosdenPRESOCRATIC PHILOSOPHYCatherine OsbornePsychologyGillian Butler andFreda McManusPSYCHIATRY Tom BurnsQUANTUM THEORYJohn PolkinghorneTHE RENAISSANCE Jerry BrottonRENAISSANCE ARTGeraldine A. JohnsonROMAN BRITAIN Peter SalwayTHE ROMAN EMPIREChristopher KellyROUSSEAURobert WoklerRUSSELLA. C. GraylingRUSSIAN LITERATURECatriona KellyTHE RUSSIAN REVOLUTIONS. A. SmithSCHIZOPHRENIAChris Frith and Eve JohnstoneSCHOPENHAUERChristopher JanawaySHAKESPEAREGermaine GreerSIKHISM Eleanor NesbittSOCIAL AND CULTURALANTHROPOLOGYJohn Monaghan and Peter JustSOCIALISMMichael NewmanSOCIOLOGYSteve BruceSocratesC. C. W. TaylorTHE SPANISH CIVIL WARHelen GrahamSPINOZARoger ScrutonSTUART BRITAINJohn MorrillTERRORISMCharles TownshendTHEOLOGYDavid F. FordTHE HISTORY OF TIMELeofranc Holford-StrevensTRAGEDYAdrian PooleTHE TUDORSJohn GuyTWENTIETH-CENTURYBRITAINKenneth O. MorganTHE VIKINGSJulian D. RichardsWittgensteinA. C. GraylingWORLD MUSICPhilip BohlmanTHE WORLD TRADEORGANIZATIONAmrita NarlikarAvailable soon:AFRICAN HISTORYJohn Parker andRichard RathboneCHILD DEVELOPMENTRichard GriffinCITIZENSHIPRichard BellamyHIV/AIDSAlan WhitesideHUMAN RIGHTSAndrew ClaphamINTERNATIONAL RELATIONSPaul WilkinsonRACISMAli RattansiFor more information visit our web sitewww.oup.co.uk/general/vsi/"},{"pageNumber":5,"pageContent":"Leonard A. SmithCHAOSA Very Short Introduction1"},{"pageNumber":6,"pageContent":"3Great Clarendon Street, Oxford ox2 6dpOxford University Press is a department of the University of Oxford.It furthers the University’s objective of excellence in research, scholarship,and education by publishing worldwide inOxford New YorkAuckland Cape Town Dar es Salaam Hong Kong KarachiKuala Lumpur Madrid Melbourne Mexico City NairobiNew Delhi Shanghai Taipei TorontoWith offices inArgentina Austria Brazil Chile Czech Republic France GreeceGuatemala Hungary Italy Japan Poland Portugal SingaporeSouth Korea Switzerland Thailand Turkey Ukraine VietnamOxford is a registered trade mark of Oxford University Pressin the UK and in certain other countriesPublished in the United Statesby Oxford University Press Inc., New York© Leonard A. Smith 2007The moral rights of the author have been assertedDatabase right Oxford University Press (maker)First published as a Very Short Introduction 2007All rights reserved. No part of this publication may be reproduced,stored in a retrieval system, or transmitted, in any form or by any means,without the prior permission in writing of Oxford University Press,or as expressly permitted by law, or under terms agreed with the appropriatereprographics rights organizations. Enquiries concerning reproductionoutside the scope of the above should be sent to the Rights Department,Oxford University Press, at the address aboveYou must not circulate this book in any other binding or coverand you must impose this same condition on any acquirerBritish Library Cataloguing in Publication DataData availableLibrary of Congress Cataloging in Publication DataData availableTypeset by RefineCatch Ltd, Bungay, SuffolkPrinted in Great Britain byAshford Colour Press Ltd, Gosport, Hampshire978–0–19–285378–313579108642"},{"pageNumber":7,"pageContent":"To the memory of Dave Paul Debeer,A real physicist, a true friend."},{"pageNumber":8,"pageContent":"This page intentionally left blank"},{"pageNumber":9,"pageContent":"ContentsAcknowledgementsxiPrefacexiiList of illustrationsxv1The emergence of chaos12Exponential growth, nonlinearity, common sense223Chaos in context: determinism, randomness,and noise334Chaos in mathematical models585Fractals, strange attractors, and dimension(s)766Quantifying the dynamics of uncertainty877Real numbers, real observations, and computers1048Sorry, wrong number: statistics and chaos1129Predictability: does chaos constrain our forecasts?12310Applied chaos: can we see through our models?13211Philosophy in chaos154Glossary163"},{"pageNumber":10,"pageContent":"Further reading169Index173"},{"pageNumber":11,"pageContent":"AcknowledgementsThis book would not have been possible without my parents, ofcourse, but I owe a greater debt than most to their faith, doubt, andhope, and to the love and patience of a, b, and c. Professionally mygreatest debt is to Ed Spiegel, a father of chaos and my thesisProfessor, mentor, and friend. I also profited immensely fromhaving the chance to discuss some of these ideas with Jim Berger,Robert Bishop, David Broomhead, Neil Gordon, Julian Hunt,Kevin Judd, Joe Keller, Ed Lorenz, Bob May, Michael Mackey,Tim Palmer, Itamar Procaccia, Colin Sparrow, James Theiler,John Wheeler, and Christine Ziehmann. I am happy toacknowledge discussions with, and the support of, the Masterand Fellows of Pembroke College, Oxford. Lastly and largely, I’dlike to acknowledge my debt to my students, they know who theyare. I am never sure how to react upon overhearing an exchangelike: ‘Did you know she was Lenny’s student?’, ‘Oh, that explainsa lot.’ Sorry guys: blame Spiegel."},{"pageNumber":12,"pageContent":"PrefaceThe ‘chaos’ introduced in the following pages reflects phenomena inmathematics and the sciences, systems where (without cheating)small differences in the way things are now have huge consequencesin the way things will be in the future. It would be cheating, ofcourse, if things just happened randomly, or if everythingcontinually exploded forever. This book traces out the remarkablerichness that follows from three simple constraints, which we’ll callsensitivity, determinism, and recurrence. These constraints allowmathematical chaos: behaviour that looks random, but is notrandom. When allowed a bit of uncertainty, presumed to be theactive ingredient of forecasting, chaos has reignited a centuries-olddebate on the nature of the world.The book is self-contained, defining these terms as they areencountered. My aim is to show the what, where, and how of chaos;sidestepping any topics of ‘why’ which require an advancedmathematical background. Luckily, the description of chaos andforecasting lends itself to a visual, geometric understanding; ourexamination of chaos will take us to the coalface of predictabilitywithout equations, revealing open questions of active scientificresearch into the weather, climate, and other real-worldphenomena of interest.Recent popular interest in the science of chaos has evolved"},{"pageNumber":13,"pageContent":"differently than did the explosion of interest in science a centuryago when special relativity hit a popular nerve that was to throb fordecades. Why was the public reaction to science’s embrace ofmathematical chaos different? Perhaps one distinction is that mostof us already knew that, sometimes, very small differences can havehuge effects. The concept now called ‘chaos’ has its origins both inscience fiction and in science fact. Indeed, these ideas were wellgrounded in fiction before they were accepted as fact: perhaps thepublic were already well versed in the implications of chaos, whilethe scientists remained in denial? Great scientists andmathematicians had sufficient courage and insight to foresee thecoming of chaos, but until recently mainstream science required agood solution to be well behaved: fractal objects and chaotic curveswere considered not only deviant, but the sign of badly posedquestions. For a mathematician, few charges carry more shamethan the suggestion that one’s professional life has been spent on abadly posed question. Some scientists still dislike problems whoseresults are expected to be irreproducible even in theory. Thesolutions that chaos requires have only become widely acceptable inscientific circles recently, and the public enjoyed the ‘I told you so’glee usually claimed by the ‘experts’. This also suggests why chaos,while widely nurtured in mathematics and the sciences, took rootwithin applied sciences like meteorology and astronomy. Theapplied sciences are driven by a desire to understand and predictreality, a desire that overcame the niceties of whatever the formalmathematics of the day. This required rare individuals who couldspan the divide between our models of the world and the world as itis without convoluting the two; who could distinguish themathematics from the reality and thereby extend the mathematics.As in all Very Short Introductions, restrictions on space requireentire research programmes to be glossed over or omitted; Ipresent a few recurring themes in context, rather than a series ofshallow descriptions. My apologies to those whose work I haveomitted, and my thanks to Luciana O’Flaherty (my editor), WendyParker, and Lyn Grove for help in distinguishing between what"},{"pageNumber":14,"pageContent":"was most interesting to me and what I might make interestingto the reader.How to read this introductionWhile there is some mathematics in this book, there are noequations more complicated than X=2. Jargon is less easy todiscard. Words in bold italics you will have to come to grips with;these are terms that are central to chaos, brief definitions of thesewords can be found in the Glossary at the end of the book. Italics isused both for emphasis and to signal jargon needed for the nextpage or so, but which is unlikely to recur often throughout the book.Any questions that haunt you would be welcome online at http://cats.lse.ac.uk/forum/ on the discussion forum VSI Chaos. Moreinformation on these terms can be found rapidly at Wikipediahttp://www.wikipedia.org/ and http://cats.lse.ac.uk/preditcability-wiki/ , and in the Further reading."},{"pageNumber":15,"pageContent":"List of illustrations1The first weather mapever published in anewspaper, preparedby Galton in 18757© The Times/NI SyndicationLimited2 Galton’s original sketchof the Galton Board93The Times headlinefollowing the Burns’Day storm in 199013© The Times/NI SyndicationLimited 1990/John FrostNewspapers4 Modern weather mapshowing the Burns’ Daystorm and a two-day-ahead forecast145The Cheat with the Aceof Diamonds, c.1645,by Georges de la Tour19Louvre, Paris. © Photo12.com/Oronoz6 A graph comparingFibonacci numbers andexponential growth267A chaotic time seriesfrom the Full LogisticMap398 Six mathematicalmaps409 Points collapsing ontofour attractors of theLogistic Map4810The evolution ofuncertainty under theYule Map5211Period doublingbehaviour in theLogistic Map6112A variety of morecomplicated behavioursin the Logistic Map62"},{"pageNumber":16,"pageContent":"13Three-dimensionalbifurcation diagram andthe collapse towardattractors in theLogistic Map6314The Lorenz attractorand the Moore-Spiegelattractor6715The evolution ofuncertainty in theLorenz System6816The Hénon attractorand a two-dimensionalslice of theMoore-Spiegelattractor7017A variety of behavioursfrom the Hénon-HeiliesSystem7218The Fournier Universe,as illustrated byFournier7819Time series from thestochastic Middle ThirdsIFS Map and thedeterministic TriplingTent Map8220 A close look at theHénon attractor,showing fractalstructure8421Schematic diagramsshowing the action ofthe Baker’s Map and aBaker’s ApprenticeMap9822Predictable chaos asseen in four iterationsof the same mouseensemble under theBaker’s Map and aBaker’s ApprenticeMap10023Card trick revealing thelimitations of digitalcomputers10824Two views of data fromMachete’s electric circuit,suggestive of Takens’Theorem11825The Not A GaltonBoard12826An illustration of usinganalogues to make aforecast13427The state space of aclimate model136Crown Copyright28Richardson’s dream137© F. Schuiten"},{"pageNumber":17,"pageContent":"29Two-day-ahead ECMWFensemble forecasts of theBurns’ Day storm14030 Four ensemble forecastsof the Machete’s Moore-Spiegel Circuit150Figures 7, 8, 9, 11, 12, 13, 19, and 20 were produced with theassistance of Hailiang Du. Figures 24 and 30 were produced withthe assistance of Reason Machete. Figures 4 and 29 were producedwith the assistance of Martin Leutbecher with data kindly madeavailable by the European Centre for Medium-Range WeatherForecasting. Figure 27 is after M. Hume et al., The UKIP02Scientific Report, Tyndal Centre, University of East Anglia,Norwich, UK.The publisher and the author apologize for any errors or omissionsin the above list. If contacted they will be pleased to rectify these atthe earliest opportunity."},{"pageNumber":18,"pageContent":"This page intentionally left blank"},{"pageNumber":19,"pageContent":"Chapter 1The emergence of chaosEmbedded in the mud, glistening green and gold and black,was a butterfly, very beautiful and very dead.It fell to the floor, an exquisite thing, a small thingthat could upset balances and knock down a line ofsmall dominoes and then big dominoes and thengigantic dominoes, all down the years across Time.Ray Bradbury (1952)Three hallmarks of mathematical chaosThe ‘butterfly effect’ has become a popular slogan of chaos. But is itreally so surprising that minor details sometimes have majorimpacts? Sometimes the proverbial minor detail is taken to be thedifference between a world with some butterfly and an alternativeuniverse that is exactly like the first, except that the butterfly isabsent; as a result of this small difference, the worlds soon come todiffer dramatically from one another. The mathematical version ofthis concept is known as sensitive dependence. Chaotic systemsnot only exhibit sensitive dependence, but two other properties aswell: they are deterministic, and they are nonlinear. In thischapter, we’ll see what these words mean and how these conceptscame into science.Chaos is important, in part, because it helps us to cope with1"},{"pageNumber":20,"pageContent":"unstable systems by improving our ability to describe, tounderstand, perhaps even to forecast them. Indeed, one of themyths of chaos we will debunk is that chaos makes forecasting auseless task. In an alternative but equally popular butterfly story,there is one world where a butterfly flaps its wings and anotherworld where it does not. This small difference means a tornadoappears in only one of these two worlds, linking chaos touncertainty and prediction: in which world are we? Chaos is thename given to the mechanism which allows such rapid growth ofuncertainty in our mathematical models. The image of chaosamplifying uncertainty and confounding forecasts will be arecurring theme throughout this Introduction.Whispers of chaosWarnings of chaos are everywhere, even in the nursery. Thewarning that a kingdom could be lost for the want of a nail can betraced back to the 14th century; the following version of the familiarnursery rhyme was published in Poor Richard’s Almanack in 1758by Benjamin Franklin:For want of a nail the shoe was lost,For want of a shoe the horse was lost,and for want of a horse the rider was lost,being overtaken and slain by the enemy,all for the want of a horse-shoe nail.We do not seek to explain the seed of instability with chaos, butrather to describe the growth of uncertainty after the initial seed issown. In this case, explaining how it came to be that the rider waslost due to a missing nail, not the fact that the nail had gonemissing. In fact, of course, there either was a nail or there was not.But Poor Richard tells us that if the nail hadn’t been lost, then thekingdom wouldn’t have been lost either. We will often explore theproperties of chaotic systems by considering the impact of slightlydifferent situations.2Chaos"},{"pageNumber":21,"pageContent":"The study of chaos is common in applied sciences like astronomy,meteorology, population biology, and economics. Sciences makingaccurate observations of the world along with quantitativepredictions have provided the main players in the development ofchaos since the time of Isaac Newton. According to Newton’s Laws,the future of the solar system is completely determined by itscurrent state. The 19th-century scientist Pierre Laplace elevatedthis determinism to a key place in science. A world is deterministicif its current state completely defines its future. In 1820, Laplaceconjured up an entity now known as ‘Laplace’s demon’; in doing so,he linked determinism and the ability to predict in principle to thevery notion of success in science.We may regard the present state of the universe as the effect of itspast and the cause of its future. An intellect which at a certainmoment would know all forces that set nature in motion, and allpositions of all items of which nature is composed, if this intellectwere also vast enough to submit these data to analysis, it wouldembrace in a single formula the movements of the greatest bodies ofthe universe and those of the tiniest atom; for such an intellectnothing would be uncertain and the future just like the past wouldbe present before its eyes.Note that Laplace had the foresight to give his demon threeproperties: exact knowledge of the Laws of Nature (‘all the forces’),the ability to take a snapshot of the exact state of the universe (‘allthe positions’), and infinite computational resources (‘an intellectvast enough to submit these data to analysis’). For Laplace’sdemon, chaos poses no barrier to prediction. Throughout thisIntroduction, we will consider the impact of removing one or moreof these gifts.From the time of Newton until the close of the 19th century, mostscientists were also meteorologists. Chaos and meteorology areclosely linked by the meteorologists’ interest in the role uncertaintyplays in weather forecasts. Benjamin Franklin’s interest in3The emergence of chaos"},{"pageNumber":22,"pageContent":"meteorology extended far beyond his famous experiment of flyinga kite in a thunderstorm. He is credited with noting the generalmovement of the weather from west towards the east and testingthis theory by writing letters from Philadelphia to cities furthereast. Although the letters took longer to arrive than the weather,these are arguably early weather forecasts. Laplace himselfdiscovered the law describing the decrease of atmospheric pressurewith height. He also made fundamental contributions to the theoryof errors: when we make an observation, the measurement is neverexact in a mathematical sense, so there is always some uncertaintyas to the ‘True’ value. Scientists often say that any uncertainty in anobservation is due to noise, without really defining exactlywhat the noise is, other than that which obscures our vision ofwhatever we are trying to measure, be it the length of a table, thenumber of rabbits in a garden, or the midday temperature.Noise gives rise to observational uncertainty, chaos helps us tounderstand how small uncertainties can become largeuncertainties, once we have a model for the noise. Some of theinsights gleaned from chaos lie in clarifying the role(s) noiseplays in the dynamics of uncertainty in the quantitativesciences. Noise has become much more interesting, as the studyof chaos forces us to look again at what we might mean by theconcept of a ‘True’ value.Twenty years after Laplace’s book on probability theory appeared,Edgar Allan Poe provided an early reference to what we would nowcall chaos in the atmosphere. He noted that merely moving ourhands would affect the atmosphere all the way around the planet.Poe then went on to echo Laplace, stating that the mathematiciansof the Earth could compute the progress of this hand-waving‘impulse’, as it spread out and forever altered the state of theatmosphere. Of course, it is up to us whether or not we choose towave our hands: free will offers another source of seeds that chaosmight nurture.In 1831, between the publication of Laplace’s science and Poe’s4Chaos"},{"pageNumber":23,"pageContent":"fiction, Captain Robert Fitzroy took the young Charles Darwin onhis voyage of discovery. The observations made on this voyage ledDarwin to his theory of natural selection. Evolution and chaos havemore in common than one might think. First, when it comes tolanguage, both ‘evolution’ and ‘chaos’ are used simultaneously torefer both to phenomena to be explained and to the theories that aresupposed to do the explaining. This often leads to confusionbetween the description and the object described (as in ‘confusingthe map with the territory’). Throughout this Introduction we willsee that confusing our mathematical models with the reality theyaim to describe muddles the discussion of both. Second, lookingmore deeply, it may be that some ecosystems evolve as if they werechaotic systems, as it may well be the case that small differences inthe environment have immense impacts. And evolution hascontributed to the discussion of chaos as well. This chapter’sopening quote comes from Ray Bradbury’s ‘A Sound Like Thunder’,in which time-travelling big game hunters accidentally kill abutterfly, and find the future a different place when they return to it.The characters in the story imagine the impact of killing a mouse,its death cascading through generations of lost mice, foxes, andlions, and:all manner of insects, vultures, infinite billions of life forms arethrown into chaos and destruction . . . Step on a mouse and youleave your print, like a Grand Canyon, across Eternity. QueenElizabeth might never be born, Washington might not cross theDelaware, there might never be a United States at all. So be careful.Stay on the Path. Never step off!Needless to say, someone does step off the Path, crushing todeath a beautiful little green and black butterfly. We can onlyconsider these ‘what if’ experiments within the fictions ofmathematics or literature, since we have access to only onerealization of reality.The origins of the term ‘butterfly effect’ are appropriately shrouded5The emergence of chaos"},{"pageNumber":24,"pageContent":"in mystery. Bradbury’s 1952 story predates a series of scientificpapers on chaos published in the early 1960s. The meteorologist EdLorenz once invoked sea gulls’ wings as the agent of change,although the title of that seminar was not his own. And one of hisearly computer-generated pictures of a chaotic system doesresemble a butterfly. But whatever the incarnation of the ‘smalldifference’, whether it be a missing horse shoe nail, a butterfly, a seagull, or most recently, a mosquito ‘squished’ by Homer Simpson, theidea that small differences can have huge effects is not new.Although silent regarding the origin of the small difference, chaosprovides a description for its rapid amplification to kingdom-shattering proportions, and thus is closely tied to forecasting andpredictability.The first weather forecastsLike every ship’s captain of the time, Fitzroy had a deep interest inthe weather. He developed a barometer which was easier to useonboard ship, and it is hard to overestimate the value of abarometer to a captain lacking access to satellite images and radioreports. Major storms are associated with low atmosphericpressure; by providing a quantitative measurement of thepressure, and thus how fast it is changing, a barometer can givelife-saving information on what is likely to be over the horizon.Later in life, Fitzroy became the first head of what would becomethe UK Meteorological Office and exploited the newly deployedtelegraph to gather observations and issue summaries of thecurrent state of the weather across Britain. The telegraph allowedweather information to outrun the weather itself for the first time.Working with LeVerrier of France, who became famous for usingNewton’s Laws to discover two new planets, Fitzroy contributed tothe first international efforts at real-time weather forecasting.These forecasts were severely criticized by Darwin’s cousin,statistician Francis Galton, who himself published the firstweather chart in the London Times in 1875, reproduced inFigure 1.6Chaos"},{"pageNumber":25,"pageContent":"1. The first weather chart ever published in a newspaper. Prepared byFrancis Galton, it appeared in the London Times on 31 March 1875"},{"pageNumber":26,"pageContent":"If uncertainty due to errors of observation provides the seed thatchaos nurtures, then understanding such uncertainty can help usbetter cope with chaos. Like Laplace, Galton was interested in the‘theory of errors’ in the widest sense. To illustrate the ubiquitous‘bell-shaped curve’ which so often seems to reflect measurementerrors, Galton created the ‘quincunx’, which is now called a GaltonBoard; the most common version is shown on the left side of Figure2. By pouring lead shot into the quincunx, Galton simulated arandom system in which each piece of shot has a 50:50 chance ofgoing to either side of every ‘nail’ that it meets, giving rise to a bell-shaped distribution of lead. Note there is more here than the one-off flap of a butterfly wing: the paths of two nearby pieces of leadmay stay together or diverge at each level. We shall return to GaltonBoards in Chapter 9, but we will use random numbers from thebell-shaped curve as a model for noise many times before then. Thebell-shape can be seen at the bottom of the Galton Board on the leftof Figure 2, and we will find a smoother version towards the top ofFigure 10.The study of chaos yields new insight into why weather forecastsremain unreliable after almost two centuries. Is it due to ourmissing minor details in today’s weather which then have majorimpacts on tomorrow’s weather? Or is it because our methods,while better than Fitzroy’s, remain imperfect? Poe’s earlyatmospheric incarnation of the butterfly effect is complete with theidea that science could, if perfect, predict everything physical. Yetthe fact that sensitive dependence would make detailed forecasts ofthe weather difficult, and perhaps even limit the scope of physics,has been recognized within both science and fiction for some time.In 1874, the physicist James Clerk Maxwell noted that a sense ofproportion tended to accompany success in a science:This is only true when small variations in the initial circumstancesproduce only small variations in the final state of the system. In agreat many physical phenomena this condition is satisfied; but thereare other cases in which a small initial variation may produce a very8Chaos"},{"pageNumber":27,"pageContent":"great change in the final state of the system, as when thedisplacement of the ‘points’ causes a railway train to run intoanother instead of keeping its proper course.This example is again atypical of chaos in that it is ‘one-off’sensitivity, but it does serve to distinguish sensitivity anduncertainty: this sensitivity is no threat as long as there is nouncertainty in the position of the points, or in which train is onwhich track. Consider pouring a glass of water near a ridge in the2. Galton’s 1889 schematic drawings of what are now called ‘GaltonBoards’9The emergence of chaos"},{"pageNumber":28,"pageContent":"Rocky Mountains. On one side of this continental divide the waterfinds its way into the Colorado River and to the Pacific Ocean, onthe other side the Mississippi River and eventually the AtlanticOcean. Moving the glass one way or the other illustratessensitivity: a small change in the position of the glass means aparticular molecule of water ends up in a different ocean. Ouruncertainty in the position of the glass might restrict our ability topredict which ocean that molecule of water will end up in, but onlyif that uncertainty crosses the line of the continental divide. Ofcourse, if we were really trying to do this, we would have toquestion whether any such mathematical line actually dividedcontinents, as well as the other adventures the molecule of watermight have which could prevent it reaching the ocean. Usually,chaos involves much more than a single one-off ‘tripping point’; ittends to more closely resemble a water molecule that repeatedlyevaporates and falls in a region where there are continental dividesall over the place.Nonlinearity is defined by what it is not (it is not linear). This kindof definition invites confusion: how would one go about defining abiology of non-elephants? The basic idea to hold in mind now isthat a nonlinear system will show a disproportionate response: theimpact of adding a second straw to a camel’s back could be muchbigger (or much smaller) than the impact of the first straw. Linearsystems always respond proportionately. Nonlinear systems neednot, giving nonlinearity a critical role in the origin of sensitivedependence.The Burns’ Day stormBut Mousie, thou art no thy lane,In proving foresight may be vain:The best-laid schemes o mice an menGang aft agley,An lea’e us nought but grief an pain,For promis’d joy!10Chaos"},{"pageNumber":29,"pageContent":"Still thou art blest, compar’d wi me!The present only toucheth thee:But och! I backward cast my e’e,On prospects drear!An forward, tho I canna see,I guess an fear!Robert Burns, ‘To A Mouse’ (1785)Burns’ poem praises the mouse for its ability to live only in thepresent, not knowing the pain of unfulfilled expectations nor thedread of uncertainty in what is yet to pass. And Burns was writingin the 18th century, when mice and men laid their plans with littleassistance from computing machines. While foresight may be pain,meteorologists struggle to foresee tomorrow’s likely weather everyday. Sometimes it works. In 1990, on the anniversary of Burns’birth, a major storm ripped through northern Europe, including theBritish Isles, causing significant property damage and loss of life.The centre of the storm passed over Burns’ home town in Scotland,and it became known as the Burns’ Day storm. A weather chartreflecting the storm at noon on 25 January is shown in the toppanel of Figure 4 (page 14). Ninety-seven people died in northernEurope, about half of this number in Britain, making it the highestdeath toll of any storm in 40 years; about 3 million trees were blowndown, and total insurance costs reached £2 billion. Yet the Burns’Day storm has not joined the rogues’ gallery of famously failedforecasts: it was well forecast by the Met Office.In contrast, the Great Storm of 1987 is famous for a BBC televisionmeteorologist’s broadcast the night before, telling people not toworry about rumours from France that a hurricane was about tostrike England. Both storms, in fact, managed gusts of over100 miles per hour, and the Burns’ Day storm caused muchgreater loss of life; yet 20 years after the event, the Great Storm of1987 is much more often discussed, perhaps exactly because theBurns’ Day storm was well forecast. The story leading up to thisforecast beautifully illustrates a different way that chaos in our11The emergence of chaos"},{"pageNumber":30,"pageContent":"models can impact our lives without invoking alternate worlds,some with and some without butterflies.In the early morning of 24 January 1990, two ships in themid-Atlantic sent routine meteorological observations frompositions that happened to straddle the centre of what wouldbecome the Burns’ Day storm. The forecast models run with theseobservations give a fine forecast of the storm. Running the modelagain after the event showed that when these observations areomitted, the model predicts a weaker storm in the wrong place.Because the Burns’ Day storm struck during the day, the failure toprovide forewarning would have had a huge impact on loss of life,so here we have an example where a few observations, had theynot been made, would have changed the forecast and hence thecourse of human events. Of course, an ocean weather ship isharder to misplace than a horse shoe nail. There is more to thisstory, and to see its relevance we need to look into how weathermodels ‘work’.Operational weather forecasting is a remarkable phenomenon inand of itself. Every day, observations are taken in the most remotelocations possible, and then communicated and shared amongnational meteorological offices around the globe. Many differentnations use this data to run their computer models. Sometimes anobservation is subject to plain old mistakes, like putting thetemperature in the box for wind speed, or a typo, or a glitch intransition. To keep these mistakes from corrupting the forecast,incoming observations are subject to quality control: observationsthat disagree with what the model is expecting (given its lastforecast) can be rejected, especially if there are no independent,nearby observations to lend support to them. It is a well-laid plan.Of course, there are rarely any ‘nearby’ observations of any sort inthe middle of the Atlantic, and the ship observations showed thedevelopment of a storm that the model had not predicted would bethere, so the computer’s automatic quality control program simplyrejected these observations.12Chaos"},{"pageNumber":31,"pageContent":"3. Headline from The Times the day after the Burns’ Day storm"},{"pageNumber":32,"pageContent":"4. A modern weather chart reflecting the Burns’ Day storm as seenthrough a weather model (top) and a two-day-ahead forecast targetingthe same time showing a fairly pleasant day (bottom)"},{"pageNumber":33,"pageContent":"Luckily, the computer was overruled. An intervention forecasterwas on duty and realized that these observations were of greatvalue. His job was to intervene when the computer did somethingobviously silly, as computers are prone to do. In this case, he trickedthe computer into accepting the observations. Whether or not totake this action is a judgement call: there was no way to know at thetime which action would yield a better forecast. The computer was‘tricked’, the observation was used. The storm was forecast, andlives were saved.There are two take-home messages here: the first is that when ourmodels are chaotic then small changes in our observations can havelarge impacts on the quality of our foresight. An accountant lookingto reduce costs and computing the typical benefit of one particularobservation from any particular weather station is likely to vastlyunderestimate the value of a future report from one of thoseweather stations that falls at the right place at the right time, andsimilarly the value of the intervention forecaster, who often has todo nothing, literally. The second is that the Burns’ Day forecastillustrates something a bit different from the butterfly effect.Mathematical models allow us to worry about what the real futurewill bring not by considering possible worlds, of which there may beonly one, but by contrasting different simulations of our model, ofwhich there can be as many as we can afford. As Burns mightappreciate, science gives us new ways to guess and new things tofear. The butterfly effect contrasts different worlds: one world withthe nail and another world without that nail. The Burns effectplaces the focus firmly on us and our attempts to make rationaldecisions in the real world given only collections of differentsimulations under various imperfect models. The failure todistinguish between reality and our models, between observationsand mathematics, arguably between an empirical fact and scientificfiction, is the root of much confusion regarding chaos both by thepublic and among scientists. It was research into nonlinearity andchaos that clarified yet again how import this distinction remains.In Chapter 10, we will return to take a deeper look at how today’s15The emergence of chaos"},{"pageNumber":34,"pageContent":"weather forecasters would have used insights from theirunderstanding of chaos when making a forecast for this event.We have now touched on the three properties found in chaoticmathematical systems: chaotic systems are nonlinear, they aredeterministic, and they are unstable in that they display sensitivityto initial condition. In the chapters that follow we will constrainthem further, but our real interests lie not only in the mathematicsof chaos, but also in what it can tell us about the real world.Chaos and the real world: predictability and a21st-century demonThere is no more greater an error in science, than to believe that justbecause some mathematical calculation has been completed, someaspect of Nature is certain.Alfred North Whitehead (1953)What implications does chaos hold for our everyday lives? Chaosimpacts the ways and means of weather forecasting, which affect usdirectly through the weather, and indirectly through economicconsequences both of the weather and of the forecasts themselves.Chaos also plays a role in questions of climate change and ourability to foresee the strength and impacts of global warming. Whilethere are many other things that we forecast, weather and climatecan be used to represent short-range forecasting and long-rangemodelling, respectively. ‘When is the next solar eclipse?’ would be aweather-like question in astronomy, while ‘Is the solar systemstable?’ would be a climate-like question. In finance, when to buy100 shares of a given stock is a weather-like question, while aclimate-like question might address whether to invest in the stockmarket or real estate.Chaos has also had a major impact on the sciences, forcing a closere-examination of what scientists mean by the words ‘error’ and‘uncertainty’ and how these meanings change when applied to our16Chaos"},{"pageNumber":35,"pageContent":"world and our models. As Whitehead noted, it is dangerous tointerpret our mathematical models as if they somehow governedthe real world. Arguably, the most interesting impacts of chaosare not really new, but the mathematical developments of the last50 years have cast many old questions into a new light. Forinstance, what impact would uncertainty have on a 21st-centuryincarnation of Laplace’s demon which could not escapeobservational noise?Consider an intelligence that knew all the laws of nature preciselyand had good, but imperfect, observations of an isolated chaoticsystem over an arbitrarily long time. Such an agent – even ifsufficiently vast to subject all this data to computationally exactanalysis – could not determine the current state of the system andthus the present, as well as the future, would remain uncertain inher eyes. While our agent could not predict the future exactly, thefuture would hold no real surprises for her, as she could see whatcould and what could not happen, and would know the probabilityof any future event: the predictability of the world she could see.Uncertainty of the present will translate into well-quantifieduncertainty in the future, if her model is perfect.In his 1927 Gifford Lectures, Sir Arthur Eddington went to theheart of the problem of chaos: some things are trivial to predict,especially if they have to do with mathematics itself, while otherthings seem predictable, sometimes:A total eclipse of the sun, visible in Cornwall is prophesied for11 August 1999 . . . I might venture to predict that 2+2 will beequal to 4 even in 1999 . . . The prediction of the weather this timenext year . . . is not likely to ever become practicable . . . We shouldrequire extremely detailed knowledge of present conditions, sincea small local deviation can exert an ever-expanding influence.We must examine the state of the sun . . . be forewarned of volcaniceruptions, . . . , a coal strike . . . , a lighted match idly thrownaway ...17The emergence of chaos"},{"pageNumber":36,"pageContent":"Our best models of the solar system are chaotic, and our bestmodels of the weather appear to be chaotic: yet why was Eddingtonconfident in 1928 that the 1999 solar eclipse would occur? Andequally confident that no weather forecast a year in advance wouldever be accurate? In Chapter 10 we will see how modern weatherforecasting techniques designed to better cope with chaos helpedme to see that solar eclipse.When paradigms collide: chaos and controversyOne of the things that has made working in chaos interesting overthe last 20 years has been the friction generated when differentways of looking at the world converge on the same set ofobservations. Chaos has given rise to a certain amount ofcontroversy. The studies that gave birth to chaos haverevolutionized not only the way professional weather forecastersforecast but even what a forecast consists of. These new ideas oftenrun counter to traditional statistical modelling methods, and stillproduce both heat and light on how best to model the real world.This battle is broken into skirmishes by the nature of the field andour level of understanding in the particular system of which aquestion is asked, be it the population of voles in Scandinavia,a mathematical calculation to quantify chaos, the number ofspots on the Sun’s surface, the price of oil delivered next month,tomorrow’s maximum temperature, or the date of the last ever solareclipse.The skirmishes are interesting, but chaos offers deeper insightseven when both sides are fighting for traditional advantage, say, the‘best’ model. Here studies of chaos have redefined the high ground:today we are forced to reconsider new definitions for whatconstitutes the best model, or even a ‘good’ model. Arguably, wemust give up the idea of approaching Truth, or at least define awholly new way of measuring our distance from it. The study ofchaos motivates us to establish utility without any hope of achievingperfection, and to give up many obvious home truths of forecasting,18Chaos"},{"pageNumber":37,"pageContent":"like the naı ̈ve idea that a good forecast consists of a prediction thatis close to the target. This did not appear naı ̈ve before weunderstood the implications of chaos.La Tour’s realistic vision of science in the real worldTo close this chapter, we illustrate how chaos can force us toreconsider what constitutes a good model, and revise our beliefs asto what is ultimately responsible for our forecast failures. Thisimpact is felt by scientists and mathematicians alike, but thereconsideration will vary depending on the individual’s point ofview and the empirical system under study. The situation is nicelypersonified in Figure 5, a French baroque painting by Georges de laTour showing a card game from the 17th century. La Tour wasarguably a realist with a sense of humour. He was fond of fortunetelling and games of chance, especially those in which chanceplayed a somewhat lesser role than the participants happened tobelieve. In theory, chaos can play exactly this role. We will interpret5.The Cheat with the Ace of Diamonds, by Georges de la Tour, paintedabout 164519The emergence of chaos"},{"pageNumber":38,"pageContent":"this painting to show a mathematician, a physicist, a statistician,and a philosopher engaged in an exercise of skill, dexterity, insight,and computational prowess; this is arguably a description for doingscience, but the task at hand here is a game of poker. Exactly who iswho in the painting will remain open, as we will return to thesepersonifications of natural science throughout the book. Theinsights chaos yields vary with the perspective of the viewer, but afew observations are in order.The impeccably groomed young man on the right is engaged incareful calculations, no doubt a probability forecast of some nature;he is currently in possession of a handsome collection of gold coinson the table. The dealer plays a critical role, without her there is nogame to be played; she provides the very language within which wecommunicate, yet she seems to be in nonverbal communicationwith the handmaiden. The role of the handmaiden is less clear; sheis perhaps tangential, but then again the provision of wine willinfluence the game, and she herself may feature as a distraction.The roguish character in ramshackle dress with bows untied isclearly concerned with the real world, not mere appearances insome model of it; his left hand is extracting one of several aces ofdiamonds from his belt, which he is about to introduce into thegame. What then do the ‘probabilities’ calculated by the young mancount for, if, in fact, he is not playing the game his mathematicalmodel describes? And how deep is the insight of our rogue? Hisglance is directed to us, suggesting that he knows we can see hisactions, perhaps even that he realizes that he is in a painting?The story of chaos is important because it enables us to see theworld from the perspective of each of these players. Are we merelydeveloping the mathematical language with which the game isplayed? Are we risking economic ruin by over-interpreting somepotentially useful model while losing sight of the fact that it, like allmodels, is imperfect? Are we only observing the big picture, notentering the game directly but sometimes providing an interestingdistraction? Or are we manipulating those things we can change,20Chaos"},{"pageNumber":39,"pageContent":"acknowledging the risks of model inadequacy, and perhaps even ourown limitations, due to being within the system? To answer thesequestions we must first examine several of the many jargons ofscience in order to be able to see how chaos emerged from the noiseof traditional linear statistics to vie for roles both in understandingand in predicting complicated real-world systems. Before thenonlinear dynamics of chaos were widely recognized within science,these questions fell primarily in the domain of the philosophers;today they reach out via our mathematical models to physicalscientists and working forecasters, changing the statistics ofdecision support and even impacting politicians and policy makers.21The emergence of chaos"},{"pageNumber":40,"pageContent":"Chapter 2Exponential growth,nonlinearity, common senseOne of the most pervasive myths about chaotic systems is that theyare impossible to predict. To expose the fallacy of this myth, wemust understand how uncertainty in a forecast grows as we predictfurther and further into the future. In this chapter we investigatethe origin and meaning of exponential growth, since on average asmall uncertainty will grow exponentially fast in a chaotic system.There is a sense in which this phenomenon really does imply a‘faster’ growth of uncertainty than that found in our traditionalideas of how error and uncertainty grow as we forecast further intothe future. Nevertheless, chaos can be easy to predict, sometimes.Chess, rice, and Leonardo’s rabbits:exponential growthAn oft-told story about the origin of the game of chess illustratesnicely the speed of exponential growth. The story goes that a king ofancient Persia was so pleased when first presented with the gamethat he wanted to reward the game’s creator, Sissa Ben Dahir. Achess board has 64 squares arranged in an 8 by 8 pattern; for hisreward, Ben Dahir requested what seemed a quite modest sumof rice determined using the new chess board: one grain of ricewas to be put on the first square of the board, two to be put onthe second, four for the third, eight for the fourth, and so on,doubling the number on each square until the 64th was reached. A22"},{"pageNumber":41,"pageContent":"mathematician will often call any rule for generating one numberfrom another one a mathematical map, so we’ll refer to this simplerule (‘double the current value to generate the next value’) as theRice Map.Before working out just how much rice Ben Dahir has asked for, letus consider the case of linear growth where we have one grain onthe first square, two on the second square, three on the third, and soon until we need 64 for the last square. In this case we have a totalof 64+63+62+...+3+2+1, or around 1,000 grains. Just forcomparison, a 1 kilogram bag of rice contains a few tens ofthousands of grains.The Rice Map requires one grain for the first square, then two forthe second, four for the third, then 8, 16, 32, 64, and 128 for the lastsquare of the first row. On the third square of the second row, wepass 1,000 and before the end of the second row there is a squarewhich exhausts our bag of rice. To fill the next square alone willrequire another entire bag, the following square two bags, and soon. Some square in the third row will require a volume of ricecomparable to a small house, and we will have enough rice to fill theRoyal Albert Hall well before the end of the fifth row. Finally, the64th square alone will require billions and billions, or to be exact,263 (=9, 223, 372, 036, 854, 775, 808) grains, for a total of18,446,744,073,709,551,615 grains. That is a non-trivial quantity ofrice! It is something like the entire world’s rice production over twomillennia. Exponential growth quickly grows out of all proportion.By comparing the amount of rice on a given square in the case oflinear growth with the amount of rice on the same square in thecase of exponential growth, we quickly see that exponential is muchfaster than linear growth: on the fourth square we already havetwice as many grains in the exponential case as in the linear case(8 in the first, only 4 in the second), and by the eighth square, at theend of the first row, the exponential case has 16 times more!Soon thereafter we have the astronomical numbers.23Exponential growth, nonlinearity, common sense"},{"pageNumber":42,"pageContent":"Of course, we hid the values of some parameters in the exampleabove: we could have made the linear growth faster by addingnot one additional grain for each square, but instead, say,1,000 additional grains. This parameter, the number ofadditional grains, defines the constant of proportionality betweenthe number of the square and the number of grains on thatsquare, and gives us the slope of the linear relationship betweenthem. There is also a parameter in the exponential case: oneach step we increased the number of grains by a factor of two,but it could have been a factor of three, or a factor of one and ahalf.One of the surprising things about exponential growth is thatwhatever the values of these parameters, there will come a time atwhich exponential growth surpasses any linear growth, and willsoon thereafter dwarf linear growth, no matter how fast the lineargrowth is. Our ultimate interest is not in rice on a chess board, butin the dynamics of uncertainty in time. Not just the growth of apopulation, but the growth of our uncertainty in a forecast of thefuture size of that population. In the forecasting context, there willcome a time at which an exponentially growing uncertainty which isvery small today will surpass a linearly growing uncertainty which istoday much larger. And the same thing happens when contrastingexponential growth with growth proportional to the square of time,or to the cube of time, or to time raised to any power (in symbols:steady exponential growth will eventually surpass the growthproportional to t2 or t3 or tn for any value of n.). It is for this reasonamong others that exponential growth is mathematicallydistinguished, and taken to provide a benchmark for definingchaos. It has also contributed to the widespread but fundamentallymistaken impression that chaotic systems are hopelesslyunpredictable. Ben Dahir’s chess board illustrates that there is adeep sense in which exponential growth is faster than linear growth.To place this in the context of forecasting, we move forward a fewhundred years in time and a few hundred miles northwest, fromPersia to Italy.24Chaos"},{"pageNumber":43,"pageContent":"At the beginning of the 13th century, Leonardo of Pisa posed aquestion of population dynamics: given a newborn pair of rabbits ina large, lush, walled garden, how many pairs of rabbits will we havein one year if their nature is for each mature pair to breed andproduce a new pair every month, and newborn rabbits mature intheir second month? In the first month we have one juvenile pair. Inthe second month this pair matures and breeds to produce a newpair in the third month. So in the third month, we have one maturepair and one newborn pair. In the fourth month we once again haveone new born pair from the original pair of rabbits and now twomature pairs for a total of three pairs. In the fifth month, two newpairs are born (one from each mature pair), and we have threemature pairs for a total of five pairs. And so on.So what does this ‘population dynamic’ look like? In the first monthwe have one immature pair, in the second month we have onemature pair, in the third month we have one mature pair and a newimmature pair, in the fourth month we have two mature pairs andone immature pair, in the fifth month we have three mature pairsand two immature.If we count up all the pairs each month, the numbers are 1, 1, 2, 3, 5,8, 13, 21 . . . . Leonardo noted that the next number in the series isalways the sum of the previous two numbers (1+1=2, 2+1=3,3+2=5, . . . ) which makes sense, as the previous number is thenumber we had last month (in our model all rabbits survive nomatter how many there are), and the penultimate number is thenumber of mature pairs (and thus the number of new pairs arrivingthis month).Now it gets a bit tedious to write ‘and in the sixth month we have12 pairs of rabbits’, so scientists often use a short-hand X for thenumber of pairs of rabbits and X6 to denote the number of pairs inmonth six. And since the series 1, 1, 2, 3, 5, 8, . . . reflects how thepopulation of rabbits evolves in time, this series and others like itare called time series. The Rabbit Map is defined by the rule:25Exponential growth, nonlinearity, common sense"},{"pageNumber":44,"pageContent":"Add the previous value of X to the current value of X, and takethe sum as the new value of X.The numbers in the series 1, 1, 2, 3, 5, 8, 13, 21, 34 . . . arecalled Fibonacci numbers (Fibonacci was a nickname ofLeonardo of Pisa), and they arise again and again in nature: in thestructure of sunflowers, pine cones, and pineapples. They are ofinterest here because they illustrate exponential growth in time,almost. The crosses in Figure 6 are Fibonacci’s points – therabbit population as a function of time – while the solid linereflects two raised to the power λt, or in symbols 2λt , where t isthe time in months and λ is our first exponent. Exponents whichmultiply time in the superscript are a useful way of quantifyinguniform exponential growth. In this case, λ is equal to thelogarithm of a number called the golden mean, a very specialnumber which is discussed in the Very Short Introduction toMathematics.6. The series of crosses showing the number of pairs of rabbits eachmonth (Fibonacci numbers); the smooth curve they lie near is therelated exponential growth26Chaos"},{"pageNumber":45,"pageContent":"The first thing to notice about Figure 6 is that the points lie close tothe curve. The exponential curve is special in mathematics becauseit reflects a function whose increase is proportional to its currentvalue. The larger it gets, the faster it grows. It makes sense thatsomething like this function would describe the dynamics ofLeonardo’s rabbit population since the number of rabbits nextmonth is more or less proportional to the number of rabbits thismonth. The second thing to notice about the figure is that the pointsdo not lie on the curve. The curve is a good model for Fibonacci’sRabbit Map, but it is not perfect: at the end of each month thenumber of rabbits is always a whole number and, while the curvemay be close to the correct whole number, it is not exactly equal toit. As the months go by and the population grows, the curve getscloser and closer to each Fibonacci number, but it never reachesthem. This concept of getting closer and closer but never quitearriving is one that will come up again and again in thisbook.So how can Leonardo’s rabbits help us to get a feel for the growth offorecast uncertainty? Like all observations, counting the numberof rabbits in a garden is subject to error; as we saw in Chapter 1,observational uncertainties are said to be caused by noise. Imaginethat Leonardo failed to notice a pair of mature rabbits also in thegarden in the first month; in that case, the number of pairsactually in the garden would have been 2, 3, 5, 8, 13, . . . The error inthe original forecast (1, 1, 2, 3, 5, 8 . . . ) would be the differencebetween the Truth and that forecast, namely: 1, 2, 3, 5 . . . (again, theFibonacci series). In month 12, this error has reached a verynoticeable 146 pairs of rabbits! A small error in the initial numberof rabbits results in a very large error in the forecast. In fact, theerror is growing exponentially in time. This has many implications.Consider the impact of the exponential error growth on theuncertainty of our forecasts. Let us again contrast linear growth andexponential growth. Let’s assume that, for a price, we can reducethe uncertainty in the initial observation that we use in generating27Exponential growth, nonlinearity, common sense"},{"pageNumber":46,"pageContent":"our forecast. If the error growth is linear, and we reduce ourinitial uncertainty by a factor of ten, then we can forecast thesystem ten times longer before our uncertainty exceeds the samethreshold. If we reduce the initial uncertainty by a factor of 1,000,then we can get forecasts of the same quality 1,000 times longer.This is an advantage of linear models. Or, more accurately, this isan apparent advantage of studying only linear systems. Bycontrast, if the model is nonlinear and the uncertainty growsexponentially, then we may reduce our initial uncertainty by afactor of ten yet only be able to forecast twice as long with thesame accuracy. In that case, assuming the exponential growth inuncertainty is uniform in time, reducing the uncertainty by afactor of 1,000 will only increase our forecast range at the sameaccuracy by a factor of eight. Now reducing the uncertainty in ameasurement is rarely free (we have to hire someone else to countthe rabbits a second time), and large reductions of uncertaintycan be expensive, so when uncertainty grows exponentially fast,the cost sky-rockets. Attempting to achieve our forecast goals byreducing uncertainty in initial conditions can be tremendouslyexpensive.Luckily, there is an alternative that allows us to accept the simplefact that we can never be certain that any observation has not beencorrupted by noise. In the case of rabbits or grains of rice, it seemsthere really is a fact of the matter, a whole number that reflects thecorrect answer. If we reduce the uncertainty in this initial conditionto zero then we can predict without error. But can we ever really becertain of the initial condition? Might there not be another bunnyhiding in the noise? While our best guess is that there is one pair inthe garden, there might be two, or three, or more (or perhaps zero).When we are uncertain of the initial condition, we can examine thediversity of forecasts under our model by making an ensemble offorecasts: one forecast started from each initial condition we thinkplausible. So one member of the ensemble will start with X equal toone, another ensemble member will start with X equals two, and soon. How should we divide our limited resources between computing28Chaos"},{"pageNumber":47,"pageContent":"more ensemble members and making better observations of thecurrent number of rabbits in the garden?In the Rabbit Map, differences between the forecasts of differentmembers of the ensemble will grow exponentially fast, but with anensemble forecast we can see just how different they are and usethis as a measure of our uncertainty in the number of rabbits weexpect at any given time. In addition, if we carefully count thenumber of rabbits after a few months, we can all but rule out someof the individual ensemble members. Each of these ensemblemembers was started from some estimate of the number of rabbitsthat were in the garden originally, so ruling an ensemble memberout in effect gives us more information about the original number ofrabbits. Of course, this information need only prove accurate if ourmodel is literally perfect, meaning, in this case, that our Rabbit Mapcaptures the reproductive behaviour and longevity of our rabbitsexactly. But if our model is perfect, then we can use futureobservations to learn about the past; this process is called noisereduction. If it turns out that our model is not perfect, then we mayend up with incoherent results.But what if we were measuring something that is not a wholenumber, like temperature, or the position of a planet? And istemperature in an imperfect weather model exactly the same thingas temperature in the real world? It was these questions thatinitially interested our philosopher in chaos. First, we shouldconsider the more pressing question of why rabbits have not takenover the world in the 9,000 months since 1202?Stretching, folding, and the growth of uncertaintyThe study of chaos lends credence to the meteorological maxim thatno forecast is complete without a useful estimate of forecastuncertainty: if we know our initial condition is uncertain then weare not only interested in the prediction per se, but equally inlearning what the likely forecast error will be. Forecast error for any29Exponential growth, nonlinearity, common sense"},{"pageNumber":48,"pageContent":"Exponential growth: an example fromMiss Nagel’s third grade classA few months ago, I received an email written by an oldfriend of mine from elementary school. It contained anotheremail that had originated from a third grader in NorthCarolina whose class was studying geography. It requestedthat everyone who read the email send a reply to the schoolstating where they lived, and the class would locate that placeon a school globe. It also requested that each reader pass onthe email to ten friends.I did not forward the message to anyone, but I did write anemail to Miss Nagel’s class stating that I was in Oxford,England. I also suggested that they tell their mathematicsteacher about their experiment and use it as an example toillustrate exponential growth: if they sent the message to tenpeople, and the next day each of them sent it to ten morepeople, that would be 100 on day three, 1,000 on day four,and more emails than there are email addresses within aweek or so. In a real system, exponential growth cannot goon forever: eventually we run out of rice, or garden space, ornew email addresses. It is often the resources that limitgrowth: even a lush garden provides only a finite amountof rabbit food. There are limits to growth which boundpopulations, if not our models of populations.I never found out whether Miss Nagel’s class learned theirlesson in exponential growth. The only answer I everreceived was an automated reply stating that the school’semail in-box had exceeded its quota and had been closed.30Chaos"},{"pageNumber":49,"pageContent":"real system should not grow without limit; even if we start with asmall error like one grain or one rabbit, the forecast error will notgrow arbitrarily large (unless we have a very naı ̈ve forecaster), butwill saturate near some limiting value, as would the populationitself. Our mathematician has a way to avoid ludicrously largeforecast errors (other than naı ̈veté), namely by making the initialuncertainty infinitesimally small – smaller than any number youcan think of, yet greater than zero. Such an uncertainty will stayinfinitesimally small for all time, even if it grows exponentially fast.Physical factors, like the total amount of rabbit food in the gardenor the amount of disk space on an email system, limit growth inpractice. The limits are intuitive even if we do not know exactlywhat causes them: I think I have lost my keys in the car park; ofcourse they might be several miles from there, but it is exceedinglyunlikely that they are farther away than the moon. I do not need tounderstand or believe the laws of gravity to appreciate this.Similarly, weather forecasters are rarely more than 100 degrees off,even for a forecast one year in advance! Even inadequate modelscan usually be constrained so that their forecast errors are bounded.Whenever our model goes into never-never land (suggesting valueswhere no data have ever gone before), then something is likely togive, unless something in our model has already broken. Often, asour uncertainty grows too large, it starts to fold back on itself.Imagine kneading dough, or a toffee machine continuouslystretching and folding toffee. An imaginary line of toffee connectingtwo very nearby grains of sugar will grow longer and longer as thesetwo grains separate under the action of the machine, but before itbecomes bigger than the machine itself, this line will be folded backinto itself, forming a horrible tangle. The distance between thegrains of sugar will stop growing, even as the string of toffeeconnecting them continues to grow longer and longer, becoming amore and more complicated tangle. The toffee machine gives us away to envision limits to the growth of prediction error wheneverour model is perfect. In this case, the error is the growing distance31Exponential growth, nonlinearity, common sense"},{"pageNumber":50,"pageContent":"between the True state and our best guess of that state: anyexponential growth of error would correspond only to the rapidinitial growth of the string of toffee. But if our forecasts are notgoing to zoom away towards infinity (the toffee must stay in themachine, only a finite number of rabbits will fit in the garden, andthe like), then eventually the line connecting Truth and our forecastwill be folded over on itself. There is simply nowhere else for it togrow into. In many ways, identifying the movement of a grain ofsugar in the toffee machine with the evolution of the state of achaotic system in three dimensions is a useful way to visualizechaotic motion.We want to require a sense of containment for chaos, since it ishardly surprising that it is difficult to predict things that are flyingapart to infinity, but we do not want to impose so strict a conditionas requiring a forecast to never exceed some limited value, nomatter how big that value might be. As a compromise, we requirethe system to come back to the vicinity of its current state at somepoint in the future, and to do so again and again. It can take as longas it wants to come back, and we can define coming back to meanreturning closer to the current point than we have ever seen itreturn before. If this happens, then the trajectory is said to berecurrent. The toffee again provides an analogy: if the motion waschaotic and we wait long enough, our two grains of sugar will againcome back close together, and each will pass close to where it was atthe beginning of the experiment, assuming no one turns off themachine in the meantime.32Chaos"},{"pageNumber":51,"pageContent":"Chapter 3Chaos in context:determinism, randomness,and noiseAll linear systems resemble one another, each nonlinear system isnonlinear in its own way.After Tolstoy’s Anna KareninaDynamical systemsChaos is a property of dynamical systems. And a dynamical systemis nothing more than a source of changing observations: Fibonacci’simaginary garden with its rabbits, the Earth’s atmosphere asreflected by a thermometer at London’s Heathrow airport, theeconomy as observed through the price of IBM stock, a computerprogram simulating the orbit of the moon and printing out thedate and location of each future solar eclipse.There are at least three different kinds of dynamical systems. Chaosis most easily defined in mathematical dynamical systems. Thesesystems consist of a rule: you put a number in and you get a newnumber out, which you put back in, to get yet a newer number out,which you put back in. And so on. This process is called iteration.The number of rabbits each month in Fibonacci’s imaginary gardenis a perfect example of a time series from this kind of system. Asecond type of dynamical system is found in the empirical world ofthe physicist, the biologist, or the stock market trader. Here, oursequence of observations consists of noisy measurements of reality,33"},{"pageNumber":52,"pageContent":"which are fundamentally different from the noise-free numbers ofthe Rabbit Map. In these physical dynamical systems – the Earth’satmosphere and Scandinavia’s vole population, for example –numbers represent the state, whereas in the Rabbit Map they werethe state. To avoid needless confusion, it is useful to distinguish athird case when a digital computer performs the arithmeticspecified by a mathematical dynamical system; we will call this acomputer simulation – computer programs that produce TVweather forecasts are a common example. It is important toremember that these are different kinds of systems and that each isa different beast: our best equations for the weather differ from ourbest computer models based on those equations, and both of thesesystems differ from the real thing the Earth’s atmosphere itself.Confusingly, the numbers from each of our three types of systemsare called time series, and we must constantly struggle to keep inmind the distinction between what these are time series of: anumber of imaginary rabbits, the True temperature at the airport (ifsuch a thing exists), a measurement representing that temperature,and a computer simulation of that temperature.The extent to which these differences are important depends onwhat we aim to do. Like la Tour’s card players, scientists,mathematicians, statisticians, and philosophers each have differenttalents and aims. The physicist may aim to describe theobservations with a mathematical model, perhaps testing themodel by using it to predict future observations. Our physicist iswilling to sacrifice mathematical tractability for physical relevance.Mathematicians like to prove things that are true for a wide rangeof systems, but they value proof so highly that they often do notcare how widely they must restrict that range to have it; oneshould almost always be wary whenever a mathematician isheard to say ‘almost every’. Our physicist must be careful not toforget this and confuse mathematical utility with physicalrelevance; physical intuitions should not be biased by the propertiesof ‘well-understood’ systems designed only for their mathematicaltractability.34Chaos"},{"pageNumber":53,"pageContent":"Our statistician is interested in describing interesting statisticsfrom the time series of real observations and in studying theproperties of dynamical systems that generate time series whichlook like the observations, always taking care to make as fewassumptions as possible. Finally, our philosopher questions therelationships among the underlying physical system that we claimgenerated the observations, the observations themselves, and themathematical models or statistical techniques that we created toanalyse them. For example, she is interested in what we can knowabout the relationship between the temperature we measure andthe true temperature (if such a thing exists), and in whether thelimits on our knowledge are merely practical difficulties we mightresolve or limits in principle that we can never overcome.Mathematical dynamical systems and attractorsWe commonly find four different types of behaviour in time series.They can (i) grind to a halt and more or less repeat the same fixednumber over and over again, (ii) bounce around in a closed loop likea broken record, periodically repeating the same pattern: exactlythe same series of numbers over and over, (iii) move in a loop thathas more than one period and so does not quite repeat exactly butcomes close, like the moment of high tide drifting through the timeof day, or (iv) forever jump about wildly, or perhaps even calmly,displaying no obvious pattern. The fourth type looks random, yetlooks can be deceiving. Chaos can look random but it is not random.In fact, as we have learned to see better, chaos often does not evenlook all that random to us anymore. In the next few pages we willintroduce several more maps, though perhaps without the rice orrabbits. We need these maps in order to generate interestingartefacts for our tour in search of the various types of behaviour justnoted. Some of these maps were generated by mathematicians forthis very purpose, although our physicist might argue, with reason,that a given map was derived by simplifying physical laws. In truth,the maps are simple enough to have each come about in severaldifferent ways.35Chaos in context: determinism, randomness, and noise"},{"pageNumber":54,"pageContent":"Before we can produce a time series by iterating a map, we needsome number to start with. This first number is called an initialcondition, an initial state that we define, discover, or arrange forour system to be. As in Chapter 2, we adopt the symbol X as short-hand for a state of our system. The collection of all possible states Xis called the state space. For Fibonacci’s imaginary rabbits, thiswould be the set of all whole numbers. Suppose our time series isfrom a model of the average number of insects per square mile atmid-summer each year. In that case, X is just a number and thestate space, being the collection of all possible states, is then a line.It sometimes takes more than one number to define the state, and ifso X will have more than one component. In predator-prey models,for instance, the populations of both are required and X has twocomponents: it is a vector. When X is a vector containing both thenumber of voles (prey) and the number of weasels (predators) onthe first of January each year, then the state space will be a two-dimensional surface – a plane – that contains all pairs of numbers.If X has three components (say, voles, weasels, and annualsnowfall), then the state space is a three-dimensional spacecontaining all triplets of numbers. Of course, there is no reason tostop at three components; although the pictures become morechallenging to draw in higher dimensions, modern weather modelshave over 10,000,000 components. For a mathematical system,X can even be a continuous field, like the height of the surfaceof the ocean or the temperature at every point on the surface ofthe Earth. However, our observations of physical systems willnever be more complicated than a vector, and since we will onlymeasure a finite number of things, our observations will always befinite-dimensional vectors. For the time being, we will consider thecase in which X is a simple number, such as one-half.Recalling that a mathematical map is just a rule that transforms oneset of values into the next set of values, you can define theQuadrupling Map by the rule:Multiply X by four to form the new value of X.36Chaos"},{"pageNumber":55,"pageContent":"Given an initial condition, like X equals one-half, this mathematicaldynamical system produces a time series of values of X, in this case½ × 4=2, 2 × 4=8, 8 × 4=32 . . . and the time series is 0.5, 2, 8, 32,128, 512, 2048 . . . And so on. This series just gets bigger andbigger and, dynamically speaking, that is not so interesting. If atime series of X grows without limit like this one does, we call itunbounded. In order to get a dynamical system where X is bounded,we’ll take a second example, the Quartering Map:Take X divided by four as the new XStarting at X=½ yields the time series 1/8, 1/32, 1/128, . . . . At firstsight, this is not very exciting since X rapidly shrinks towards zero.But in fact, the Quartering Map has been carefully designed toillustrate special mathematical properties. The origin – the stateX=0 – is a fixed point: if we start there we will never leave, sincezero divided by four is again zero. The origin is also our firstattractor; under the Quartering Map the origin is the inevitable ifunreachable destination: if we start with some other value of X, wenever actually make it to the attractor, although we get close as thenumber of iterations increases without limit. How close? Arbitrarilyclose. As close as you like. Infinitesimally close, meaning closerthan any number you can name. Name a number, any number, andwe can work out how many iterations are required after which Xwill remain closer to zero than that number. Getting arbitrarilyclose to an attractor as time goes on while never quite reaching it isa common feature of many time series from nonlinear systems. Thependulum provides a physical analogue: each swing will be smallerthan the last, an effect we blame on air resistance and friction. Theanalogue of the attractor in this case is the motionless pendulumhanging straight down. We will have more to say about attractorsafter we have added a few more dynamical systems to ourmenagerie.In the Full Logistic Map, time series from almost every X bouncesaround irregularly between zero and one forever:37Chaos in context: determinism, randomness, and noise"},{"pageNumber":56,"pageContent":"Subtract X2 from X, multiply the difference by four and take theresult as the new X.If we multiply components of state variables by other components,things become nonlinear. What is the time series in this case if weagain start with X equals one-half ? Starting with ½, X minus X2 is¼, times four is one, so our new value is one. Continuing with Xnow equal to one, we have X minus X2 is zero. But four times zero isalways zero, so we’ll get zeros forever. And our time series is 0.5, 1,0, 0, 0 . . . This does not blow up, but it is hardly exciting; recall thewarning about ‘almost every’.The order of the numbers in a time series is important, whether theseries reflects monthly values of Fibanocci’s rabbits or iterations ofthe Full Logistic Map. Using the short-hand suggested in Chapter 2,we will write X5 for the fifth new value of X, and X0 for the initialstate (or observation), and in general Xi for the ith value. Whetherwe are iterating the map or taking observations, i is always aninteger and is often called ‘time’.In the Full Logistic Map with X0 is equal to 0.5, X1 is equal to 1, X2is 0, X3 is 0, X4 is 0, and Xi will be zero for all i greater than four aswell. So the origin is again a fixed point. But under the Full LogisticMap small values of X grow (you can check this with a handcalculator), X=0 is unstable and so the origin is not an attractor.A time series started near the origin is in fact unlikely to take one ofthe first three options noted at the opening of this section, but tobounce about chaotically forever.Figure 7 shows a time series starting near X0 equals 0.876; itrepresents a chaotic time series from the Full Logistic Map. Butlook at it closely: does it really look completely unpredictable? Itlooks like small values of X are followed by small values of X, andthat there is a tendency for the time series to linger whenever it isnear three-quarters. Our physicist would look at this series andexpect it to be predictable at least sometimes, while, after a few38Chaos"},{"pageNumber":57,"pageContent":"calculations, our statistician might even declare it random.Although we can see this structure, the most common statisticaltests cannot.A menagerie of mapsThe rule that defines a map can be stated either in words, or as anequation, or in a graph. Each panel of Figure 8 defines the rulegraphically. To use the graph, find the current value of X on thehorizontal axis, and then move directly upward until you hit thecurve; the value of this point on the curve on the vertical axis isthe new value of X. The Full Logistic Map is shown graphically inFigure 8 (b), while the Quarter Map is in panel (a).An easy way of using the graph to see if a fixed point is unstable is tolook at the slope of the map at the fixed point: if the slope is steeperthan 45 degrees (either up or down); then the fixed point is7. A chaotic time series from the Full Logistic Map starting nearX0 equals 0.876. Note the series is visibly predictable whenever X is nearzero and three-quarters39Chaos in context: determinism, randomness, and noise"},{"pageNumber":58,"pageContent":"8. Graphical presentation of the (a) Quarter Map, (b) Full Logistic Map, (c) Shift Map, (d) Tent Map, (e) Tripling Tent Map,and (f) the Moran-Ricker Map"},{"pageNumber":60,"pageContent":"unstable. In the Quartering Map the slope is less than oneeverywhere, while for the Full Logistic Map the slope near theorigin is greater than one. Here small but non-zero values of X growwith each iteration but only as long as they stay sufficiently small(the slope near ½ is zero). As we will see below, for almost everyinitial condition between zero and one, the time series displays truemathematical chaos. The Full Logistic Map is pretty simple; chaosis pretty common.To see if a mathematical system is deterministic merely requireschecking carefully whether carrying out the rule requires a randomnumber. If not, then the dynamical system is deterministic: everytime we put the same value of X in, we get the same new value of Xout. If the rule requires (really requires) a random number, then thesystem is random, also called stochastic. With a stochastic system,even if we iterate exactly the same initial condition we expect thedetails of the next value of X and thus the time series to be different.Looking back at their definitions, we see that the three mapsdefined above are each deterministic; their future time series iscompletely determined by the initial condition, hence the name‘deterministic system’. Our philosopher would point out that justknowing X is not enough, we also need to know the mathematicalsystem and we have to have the power to do exact calculations withit. These were the three gifts Laplace ensured his demon possessed200 years ago.Our first stochastic dynamical system is the AC Map:Divide X by four, then subtract ½ and add a random number R toget the new X.The AC Map is a stochastic system since applying the rule requiresaccess to a supply of random numbers. In fact, the rule above isincomplete, since it does not specify how to get R. To complete thedefinition we must add something like: for R on each iteration, picka number between zero and one in a manner that each number isequally likely to be chosen, which implies that R will be uniformly42Chaos"},{"pageNumber":61,"pageContent":"distributed between zero and one and that the probability of thenext value of R falling in an interval of values is proportional to thewidth of that interval.What rule do we use to pick R? It could not be a deterministic rule,since then R would not be random. Arguably, there is no finite rulefor generating values of R. This has nothing to do with needinguniform numbers between zero and one. We’d have the sameproblem if we wanted to generate random numbers whichmimicked Galton’s ‘bell-shape’ distribution. We will have to rely onour statistician to somehow get us the random numbers we need;hereafter we’ll just state whether they have a uniform distributionor the bell-shaped distribution.In the AC Map, each value of R is used within the map, but there isanother class of random maps – called Iterated Function Systems,or IFS for short – which appear to use the value of R not in aformula but to make a decision as to what to do. One example is theMiddle Thirds IFS Map, which will come in handy later when wetry to work out the properties of maps from the time series that theygenerate. The Middle Thirds IFS Map is:Take a random number R from a uniform distribution between zeroand one.If R is less than a half, take X/3 as the new XOtherwise take 1 – X/3 as the new X.So now we have a few mathematical systems, and we can easilytell if they are deterministic or stochastic. What about computersimulations? Digital computer simulations are alwaysdeterministic. And as we shall see in Chapter 7, the time seriesfrom a digital computer is either on an endless loop of valuesrepeating itself periodically, over and over again, or it is on itsway towards such a loop. This first part of a time series in whichno value is repeated, the trajectory is evolving towards a periodicloop but has not reached it, is called a transient. Inmathematical circles, this word is something of an insult, since43Chaos in context: determinism, randomness, and noise"},{"pageNumber":62,"pageContent":"mathematicians prefer to work with long-lived things, not meretransients. While mathematicians avoid transients, physicalscientists may never see anything else and, as it turns out, digitalcomputers cannot maintain them. The digital computers thathave proven critical in advancing our understanding of chaoscannot, ironically, display true mathematical chaos themselves.Neither can a digital computer generate random numbers. Theso-called random number generators on digital computers andhand calculators are, in fact, only pseudo-random numbergenerators; one of the earliest of these generators was even basedon the Full Logistic Map! The difference between mathematicalchaos and computer simulations, like that between randomnumbers and pseudo-random numbers, exemplifies thedifference between our mathematical systems and our computersimulations.The maps in Figure 8 are not there by chance. Mathematiciansoften construct systems in such a way that it will be relatively simplefor them to illustrate some mathematical point or allow theapplication of some specific manipulation – a word they sometimesuse to obscure technical sleight of hand. The really complicatedmaps – including the ones used to guide spacecraft and the onescalled ‘climate models’, and the even bigger ones used in numericalweather prediction – are clearly constructed by physicists, notmathematicians. But they all work the same way: a value of X goesin and a new value X comes out. The mechanism is exactly the sameas in the simple maps defined above, even if X might have over10,000,000 components.Parameters and model structureThe rules that define the maps above each involve numbers otherthan the state, numbers like four and one-half. These numbers arecalled parameters. While X changes with time, parameters remainfixed. It is sometimes useful to contrast the properties of time seriesgenerated using different parameter values. So instead of44Chaos"},{"pageNumber":63,"pageContent":"defining the map with a particular parameter value, like 4, mapsare usually defined using a symbol for the parameter, say α. Wecan then contrast the behaviour of the map at α equals 4 withthat at α=2, or α=3.569945, for example. Greek symbols areoften used to clearly distinguish parameters from state variables.Rewriting the Full Logistic Map with a parameter yields one ofthe most famous systems of nonlinear dynamics: the LogisticMap:Subtract X2 from X, then multiply by α and take the result as thenew X.In physical models, parameters are used to represent things likethe temperature at which water boils, or the mass of the Earth,or the speed of light, or even the speed with which ice ‘falls’ in theupper atmosphere. Statisticians often dismiss the distinctionbetween the parameter and the state, while physicists tend togive parameters special status. Applied mathematicians, as itturns out, often force parameters towards the infinitely large orthe infinitesimally small; it is easier, for example, to study the flowof air over an infinitely long wing. Once again, these different pointsof view each make sense in context. Do we require an exact solutionto an approximate question, or an approximate answer to aparticular question? In nonlinear systems, these can be verydifferent things.AttractorsRecall the Quartering Map, noting that after one iteration everypoint between zero and one will be between zero and one-quarter.Since all the points between zero and one-quarter are also betweenzero and one, none of these points can ever escape to values greaterthan one or less than zero. Dynamical systems in which, on average,line segments (or in higher dimensions, areas or volumes) shrinkare called dissipative. Whenever a dissipative map translates avolume of state space completely inside itself, we know immediatelythat an attractor exists without knowing what it looks like.45Chaos in context: determinism, randomness, and noise"},{"pageNumber":64,"pageContent":"Whenever α is less than four we can prove that the Logistic Maphas an attractor by looking at what happens to all the pointsbetween zero and one. The largest new value of X we can getis the iteration of X equals one-half. (Can you see this inFigure 8?) This largest value is α/4, and as long as α is less thanfour this largest value is less than one. That means every pointbetween zero and one iterates to a point between zero and α/4and is confined there forever. So the system must have anattractor. For small values of α the point X equals zero is theattractor, just like in the Quartering Map. But if α is greaterthan one, then any value of X near zero will move away and theattractor is elsewhere. This is an example of a non-constructiveproof: we can prove that an attractor exists but, frustratingly,the proof does not tell us how to find it nor give any hint of itsproperties!Multiple time series of the Logistic Map for each of four differentvalues of α are shown in Figure 9. In each panel, we start with512 points taken at random between zero and one. At eachstep we move the entire ensemble of points forward in time.In the first step we see that all remain greater than zero, yetmove away from X equals one never to return: we have anattractor. In (a) we see them all collapsing onto the period oneloop; in (b) onto one of the two points in the period two loop;in (c) onto one of the four points of the period four loop. In (d),we can see that they are collapsing, but it is not clear what theperiod is. To make the dynamics more plainly visible, onemember of our ensemble is chosen at random in the middleof the graph, and the points on its trajectory are joined by a linefrom that point forward. The period one loop (a) appears as astraight line, while (b) and (c) show the trajectories alternatingbetween two or four points, respectively. While (d) first looks likea period four loop as well, but a closer look shows that there aremany more than four options, and that while there is regularity inthe order in which the bands of points are visited, no simpleperiodicity is visible.46Chaos"},{"pageNumber":65,"pageContent":"To get a different picture of the same phenomena, we canexamine many different initial conditions and different valuesfor α at the same time, as shown in Figure 13 (page 63). In thisthree-dimensional view, the initial states can be seen randomlyscattered on the back left of the box. At each iteration, they moveout towards you and the points collapse towards the pattern shownin the previous two figures. The iterated initial random states areshown after 0, 2, 8, 32, 128, and 512 iterations; it takes some timefor the transients to die away, but the familiar patterns can be seenemerging as the states reach the front of the box.Tuning model parameters and structural stabilityWe can see now that a dynamical system has three components: themathematical rule that defines how to get the next value, theparameter values, and the current state. We can, of course, changeany of these things and see what happens, but it is useful todistinguish what type of change we are making. Similarly, we mayhave insight into the uncertainty in one of these components, and itis in our interest to avoid accounting for uncertainty in onecomponent by falsely attributing it to another.Our physicist may be looking for the ‘True’ model, or only just auseful one. In practice there is an art of ‘tuning’ parameter values.And while nonlinearity requires us to reconsider how we find ‘goodparameter values’, chaos will force us to re-evaluate what we meanby ‘good’. A very small difference in the value of a parameter whichhas an unnoticeable impact on the quality of a short-term forecastcan alter the shape of an attractor beyond recognition. Systems inwhich this happens are called structurally unstable. Weatherforecasters need not worry about this, but climate modellers must;as Lorenz noted in the 1960s.A great deal of confusion has arisen from the failure todistinguish between uncertainty in the current state, uncertaintyin the value of a parameter, and uncertainty regarding themodel structure itself. Technically, chaos is a property of a47Chaos in context: determinism, randomness, and noise"},{"pageNumber":66,"pageContent":"9. Each frame shows the evolution of 512 points, initially spread atrandom between zero and one, as they move forward under the LogisticMap. Each panel shows one of four different values of α, showing thecollapse towards (a) a fixed point, (b) a period two loop, (c) a period fourloop, and (d) chaos. The solid line starting at time 32 shows thetrajectory of one point, in order to make the path on each attractorvisible"},{"pageNumber":68,"pageContent":"dynamical system with fixed equations (structure) and specifiedparameter values, so the uncertainty that chaos acts on is onlythe uncertainty in the initial state. In practice, these distinctionsbecome blurred and the situation is much more interesting, andconfused.Statistical models of Sun spotsChaos is only found in deterministic systems. But to understand itsimpact on science we need to view it against the background oftraditional stochastic models developed over the past century.Whenever we see something repetitive in nature, periodic motionis one of the first hypotheses to be deployed. It can make youfamous: Halley’s comet, and the Wolf Sun spot number. In theend, the name often sticks even when we realize that thephenomenon is not really periodic. Wolf guessed that the Sunwent through a cycle of about 11 years at a time when he had lessthan 20 years’ data. Periodicity remains a useful concept eventhough it is impossible to prove a physical system is periodicregardless of how much data we take. So are the concepts ofdeterminism and chaos.The solar record showed correlations with weather, with economicactivity, with human behaviour; even 100 years ago the 11-yearcycle could be ‘seen’ in tree rings. How could we model the Sunspots cycle? Models of a frictionless pendulum are perfectlyperiodic, while the solar cycle is not. In the 1920s, the Scottishstatistician Udny Yule discovered a new model structure, realizinghow to introduce randomness into the model and get morerealistic-looking time series behaviour. He likened the observedtime series of Sun spots to those from the model of a dampedpendulum, a pendulum with friction which would have a freeperiod of about 11 years. If this model pendulum were ‘left alonein a quiet room’, the resulting time series would slowly damp downto nothing. In order to motivate his introduction of randomnumbers to keep the mathematical model going, Yule extended the50Chaos"},{"pageNumber":69,"pageContent":"analogy with a physical pendulum: ‘Unfortunately, boys with peashooters get into the room, and pelt the pendulum from all sides atrandom.’ The resulting models became a mainstay in thestatistician’s arsenal. A linear, stochastic mainstay. We will definethe Yule Map:Ta k e α times X plus a random value R to be the new value of Xwhere R is randomly drawn from the standard bell-shapeddistribution.So how does this stochastic model differ from a chaotic model?There are two differences that immediately jump out at themathematician: the first is that Yule’s model is stochastic – therule requires a random number generator, while a chaotic modelof the Sun spots would be deterministic by definition. The secondis that Yule’s model is linear. This implies more than simply thatwe do not multiply components of the state together in thedefinition of the map; it also implies that one can combinesolutions of the system and get other acceptable solutions, aproperty called superposition. This very useful property is notpresent in nonlinear systems.Yule developed a model similar to the Yule Map that behaved morelike the time series of real Sun spots. Cycles in Yule’s improvedmodel differ slightly from one cycle to the next due to the randomeffects, the details of the pea shooters. In a chaotic model the stateof the Sun differs from one cycle to the next. What aboutpredictability? In any chaotic model, almost all nearby initialstates will eventually diverge, while in each of Yule’s models even faraway initial states would converge, if both experienced the sameforcing from the pea shooters. This is an interesting and ratherfundamental difference: similar states diverge under deterministicdynamics whereas they converge under linear stochastic dynamics.That does not necessarily make Yule’s model easier to forecast, sincewe never know the details of the future random forcing, but itchanges the way that uncertainty evolves in the system, as shown in51Chaos in context: determinism, randomness, and noise"},{"pageNumber":70,"pageContent":"Figure 10. Here an initially small uncertainty, or even aninitially zero uncertainty, at the bottom grows wider and movesto the left with each iteration. Note that the uncertainty in thestate seems to be approaching a bell-shaped distribution, andhas more or less stabilized by the time it reaches the top of thegraph. Once the uncertainty saturates in a static state, then allpredictability is lost; this final distribution is called the ‘climate’of the model.10. The evolution of uncertainty under the stochastic Yule Map.Starting as a point at the bottom of the graph, the uncertainty spreads tothe left as we move forward in time (upwards) and approaches aconstant bell-shaped distribution52Chaos"},{"pageNumber":71,"pageContent":"Physical dynamical systemsThere is no way of proving the correctness of the position of‘determinism’ or ‘indeterminism’. Only if science were complete ordemonstrably impossible could we decide such questions.E. Mach (1905)There is more to the world than mathematical models. Just aboutanything we want to measure in the real world, or even just thinkabout observing, can be taken to have come from a physicaldynamical system. It could be the position of the planets in the solarsystem, or the surface of a cup of coffee on a vibrating table, or thepopulation of fish in a lake, or the number of grouse on an estate, ora coin being flipped.The time series we want to observe now is the state of the physicalsystem: say, the position of our nine planets relative to the Sun, thenumber of fish or grouse. As a short-hand, we will again denote thestate of the system as X, while trying to remember that there is afundamental difference between a model-state and the True state, ifsuch a thing exists. It is unclear how these concepts stand inrelation to each other; as we shall see in Chapter 11, somephilosophers have argued that the discovery of chaos implies thereal world must have special mathematical properties. Otherphilosophers, perhaps sometimes the same ones, have argued thatthe discovery of chaos implies mathematics does not describe theworld. Such are philosophers.In any event, we never have access to the True state of a physicalsystem, even if one exists. What we do have are observations,which we will call ‘S’ to distinguish them from the state of thesystem, X. What is the difference between X and S? The unsunghero of science: noise. Noise is the glue that bonds theexperimentalists with the theorists on those occasions when theymeet. Noise is also the grease that allows theories to slide easilyover awkward facts.53Chaos in context: determinism, randomness, and noise"},{"pageNumber":72,"pageContent":"In the happy situation where we know the mathematical modelwhich generated the observations and we also know of a noisemodel for whatever generated whatever noise there was, then weare in the Perfect Model Scenario, or PMS. It is useful todistinguish a strong version of PMS where we know the parametervalues exactly, from a weak version where we know only themathematical forms and must estimate parameter values from theobservations. As long as we are in either version of PMS, the noise isdefined by the distance between X and S, and it makes sense tospeak of noise as causing our uncertainty in the state, since we knowa True state exists even if we do not know its value. Not much of thispicture survives when we leave PMS. Even within PMS, noise takeson a new prominence once we acknowledge that the world is notlinear.What about the concepts of deterministic and random, or evenperiodic? These refer to properties of our models; we can applythem to the real world only via (today’s) best model. Are there reallyrandom physical dynamical systems? Despite the everyday use ofcoin flips and dice as sources of ‘randomness’, the typical answer inclassical physics is: no, there is no randomness at all. With acomplete set of laws it may (or may not) be too difficult for us tocalculate the outcomes of coin flips, rolling dice, or spinning aroulette: but that is a problem only in practice, not in principle:Laplace’s demon would have no difficulty with such predictions.Quantum mechanics, however, is different. Within the traditionalquantum mechanical theory, the half-life of a uranium atom is asnatural and real a quantity as the mass of the uranium atom. Thefact that classical coin tosses or roulette are not best modelled asrandom is irrelevant, given the quantum mechanical claim forrandomness and objective probabilities. Claims for – or against –the existence of objective probabilities require interpreting physicalsystems in terms of our models of those systems. As always. Somefuture theory may revoke this randomness in favour ofdeterminism, but we are on the scene only for a vanishinglysmall interval. It is relatively safe to say that some of our best54Chaos"},{"pageNumber":73,"pageContent":"models of reality will still admit random elements as you read thesewords.Observations and noiseOver the last few decades, a huge number of scientific papers havebeen written about using a time series to distinguish deterministicsystems from stochastic systems. This avalanche was initiated in thephysics literature, and then spread into geophysics, economics,medicine, sociology, and beyond. Most of these papers wereinspired by a beautiful theorem proven by the Dutchmathematician Floris Takens in 1983, to which we will return inChapter 8. Why were all these papers written, given that we have asimple rule for determining if a mathematical system isdeterministic or stochastic? Why not just look at the rules of thesystem and see if it requires a random number generator? It iscommon to confuse the games mathematicians play withconstraints placed on the work of the natural (and other) scientists.Real mathematicians like to play intellectual games, like pretendingto forget the rules and then guessing if the system is deterministicor stochastic from looking only at the time series of the states of thesystem. Could they clearly identify any deterministic system giventhe time series from the infinitely remote past to the infinitelydistant future? For fixed points and even periodic loops, this gameis not challenging enough; to make it more interesting, consider avariation in which we do not know the exact states, but have accessonly to noisy observations, S, of each state X. The origin S iscommonly, if somewhat misleadingly, thought of as being related tothe addition of a random number to each true X. In that case, thisobservational noise does not affect the future states of the system,only our observations of each state; it is a very different role fromthat played by the random numbers R in the stochastic systems, likethe Yule Map where the value of R did impact the future since itchanged the next value of X. To maintain this distinction, randominfluences that do influence X are called dynamic noise.55Chaos in context: determinism, randomness, and noise"},{"pageNumber":74,"pageContent":"As noted above, mathematicians can work within the Perfect ModelScenario (PMS). They start off knowing that the model whichgenerated the time series has a certain kind of structure, andsometimes they assume they know the structure (weak PMS),sometimes even the values of the parameters as well (strong PMS).They generate a time series of X, and from this a time series of S.They then pretend to forget the values of X and see if they can workout what they were, or they pretend to forget the mathematicalsystem and see if, given only S, they can identify the system alongwith its parameter values, or determine if the system is chaotic, orforecast the next value of X.At this point, it should be pretty easy to see where their game isgoing: our mathematicians are trying to simulate the situation thatnatural scientists can never escape from. The physicists, earthscientists, economists, and other scientists do not know the rule, thefull Laws of Nature, relevant to the physical systems of scientificstudy. And scientific observations are not perfect; they may beinvariably uncertain due to observational noise, but that is not theend of the story. It is a capital mistake to confuse real observationswith those of these mathematical games.The natural scientist is forced to play a different game. Whileattempting to answer the same questions, the scientist is given onlya time series of observations, S, some information regarding thestatistics of the observational noise, and the hope that somemathematical map exists. Physicists can never be sure if such astructure exists or not; they cannot even be certain if the modelstate variable X really has any physical meaning. If X is the numberof rabbits in a real garden, it is hard to imagine that X does notexist, it is just some whole number. But what about model variableslike wind speed or temperature? Are there real numbers thatcorrespond to those components of our state vector? And if not,where between rabbits and wind speed does the correspondencebreak down?56Chaos"},{"pageNumber":75,"pageContent":"Our philosopher is very interested in such questions, and we allshould be. LeVerrier, the Frenchman who worked with Fitzroy toset up the first weather warning system, died famous for discoveringtwo planets. He used Newton’s Laws to predict the location ofNeptune based on ‘irregularities’ in the observed time series ofUranus’s orbit, and that planet was duly observed. He also analysed‘irregularities’ in the orbit of Mercury, and again told observerswhere to find another new planet. And they did: the new planet,named Vulcan, was very near the Sun and difficult to see, but it wasobserved for decades. We now know that there is no planet Vulcan;LeVerrier was misled because Mercury’s orbit is poorly described byNewton’s Laws (although it is rather better described by Einstein’s).How frequently do we blame the mismatch between our modelsand our data on noise when the root cause is in fact modelinadequacy? Most really interesting science is done at the edges,whether the scientists realize it or not. We are never sure if today’slaws apply there or not. Modern-day climate science is a goodexample of hard work being done at the edge of our understanding.The study of chaos has clarified the importance of distinguishingtwo different issues: one being the effects of uncertainty in the stateor the parameters, the other being the inadequacy of ourmathematics itself. Mathematicians working within PMS can makeprogress by pretending that they are not, while scientists whopretend – or believe – that they are working within PMS when theyare not can wreak havoc, especially if their models are naı ̈vely takenas a basis for decision making. The simple fact is that we cannotapply the standards of mathematical proof to physical systems, butonly to our mathematical models of physical systems. It isimpossible to prove that a physical system is chaotic, or to prove it isperiodic. Our physicist and mathematician must not forget thatthey sometimes use the same words to mean rather different things;when they do, they often run into some difficulty and considerableacrimony. Mach’s comment above (page 53) suggests that this is nota new issue.57Chaos in context: determinism, randomness, and noise"},{"pageNumber":76,"pageContent":"Chapter 4Chaos in mathematicalmodelsWe would all be better off if more people realised that simple nonlinearsystems do not necessarily possess simple dynamical properties.Lord May (1976)This chapter consists of a very short survey of chaotic mathematicalmodels from zoology to astronomy. Like any cultural invasion, thearrival of nonlinear deterministic models with sensitive dependencewas sometimes embraced, and sometimes not. It has been mostuniformly welcomed in physics where, as we shall see, theexperimental verification of its prophecies has been nothing short ofastounding. In other fields, including population biology, the veryrelevance of chaos is still questioned. Yet it was populationbiologists who proposed some of the first chaotic models a decadebefore the models of astronomers and meteorologists came on thescene. Renewed interest in this work was stimulated in 1976 by aninfluential and accessible review article in the journal Nature. Webegin with the basic insights noted in that article.The darling bugs of MayIn 1976, Lord May provided a high-profile review of chaoticdynamics in Nature that surveyed the main features ofdeterministic nonlinear systems. Noting that many interestingquestions remained unresolved, he argued that this new perspective58"},{"pageNumber":77,"pageContent":"provided not just theoretical but practical and pedagogical value aswell, and that it suggested everything from new metaphors fordescribing systems to new quantities to observe and new parametervalues to estimate. Some of the simplest population dynamics arethose of breeding populations when one generation does notoverlap with the next. Insects that have one generation per year, forexample, might be described by discrete time maps. In this case Xiwould represent the population, or population density, in the ithyear, so our time series would have one value per year, and the mapis the rule that determines the size of next year’s population giventhis year’s. A parameter α represents the density of resources. In the1950s, Moran and Ricker independently suggested the map shownin Figure 8(f ) (page 40). Looking at this graph, we can see thatwhen the current value of X is small, the next value of X is larger:small populations grow. Yet if X gets too big, then the next value ofX is small, and when the current value is very large, the next value isvery small: large populations exhaust the resources available to eachindividual, and so successful reproduction is reduced.Irregularly fluctuating populations have long been observed, andresearchers have long argued over their origin. Time series ofCanadian lynx and both Scandinavian and Japanese voles are, alongwith the Sun spot series, some of the most analysed data sets in allof statistics. The idea that very simple nonlinear models can displaysuch irregular fluctuations suggested a new potential mechanismfor real population fluctuations, a mechanism that was in conflictwith the idea that ‘natural’ populations should maintain either asteady level or a regular periodic cycle. The idea that these random-looking fluctuations need not be induced by some outside force likethe weather, but could be inherent to the natural populationdynamics, had the potential to radically alter attempts tounderstand and manage populations. While noting that ‘replacing apopulation’s interactions with its biological and physicalenvironment by passive parameters may do great violence to thereality’, May provided a survey of interesting behaviours in theLogistic Map. The article ends with ‘an evangelical plea for the59Chaos in mathematical models"},{"pageNumber":78,"pageContent":"introduction of these difference equations into elementarymathematics courses, so that students’ intuition may be enriched byseeing the wild things that simple nonlinear equations can do’. Thatwas three decades ago.We will consider a few of these wild things below, but note that themathematicians’ focus on the Logistic Map is not meant to suggestthat this map itself in any sense ‘governs’ the various physical andbiological systems. One thing that distinguishes nonlineardynamics from traditional analysis is that the former tends to focusmore on the behaviour of systems rather than on the details of anyone initial state under particular equations with specific parametervalues: a focus on geometry rather than statistics. Similar dynamicscan be more important than ‘good’ statistics. And it turns out thatthe Logistic Map and the Moran-Ricker Map are very similar in thisway, even though they look very different in Figure 8(f ) (page 40).The details may well matter, of course; the enduring role of theLogistic Map itself may be pedagogical, helping to exorcize thehistorical belief that complicated dynamics requires either verycomplicated models or randomness.Universality: prophesying routes to chaosThe Logistic Map gives rise to amazingly rich varieties of behaviour.The famous bifurcation diagram of Figure 11 summarizes thebehaviour of the map at many different values of its parameter inone figure. The horizontal axis is α and the dots in any vertical sliceindicate states which fall near the attractor for that value of α. Hereα reflects some parameter of the system: if X is the number of fish inthe lake, then α is the amount of food in the lake; if X is the timebetween drips of the faucet, then α is the rate of water leakingthrough the tap; if X is the motion of rolls in fluid convection, thenα is the heat delivered to the bottom of the pan. In models of verydifferent things, the behaviour is the same. For small α (on the left)we have a fixed point attractor. The location of the fixed pointincreases as α increases, until α reaches a value of one, where the60Chaos"},{"pageNumber":79,"pageContent":"fixed point vanishes and we observe iterations which alternatebetween two points: a period two loop. As α continues to increase,we get a period four loop, then period eight, then 16, then 32. Andso on. Bifurcating over, and over again.Since the period of the loop always increases by a factor of two, theseare called period doubling bifurcations. While the old loops are nolonger seen, they do not cease to exist. They are still there, but havebecome unstable. This is what happened to the origin in the LogisticMap when α is greater than one: X only stays at zero if it is exactlyequal to zero, while small non-zero values grow at each iteration.Similarly, points near an unstable periodic loop move away from it,and so we no longer see them clearly when iterating the map.There is a regularity hidden in Figure 11. Take any three consecutivevalues of α at which the period doubles, subtract the first from thesecond, and then divide that number by the difference between thesecond and the third. The result leads to the Feigenbaum number,~4.6692016091. Mitch Feigenbaum discovered these relationships,working with a hand calculator in Los Alamos in the late 1970s, and11. Period doubling behaviour in the Logistic Map as α increases from2.8 to ~3.5; the first three doublings are marked61Chaos in mathematical models"},{"pageNumber":80,"pageContent":"the ratio is now known by his name. Others also found itindependently; having the insight to do this calculation wasstunning in each case.Since the Feigenbaum number is greater than one, values of α atwhich bifurcations occur get closer and closer together, and we havean infinite number of birfurcations before reaching a value of α near3.5699456718. Figure 12 indicates what happens for larger valuesof α. This sea of points is largely chaotic. But note the windows ofperiodic behaviour, for instance the period three window where αtakes on the value of one plus the square root of eight (that is, about3.828). This is a stable period three loop; can you identify windowscorresponding to period five? Seven?Figure 13 puts the figures of the Logistic Map in context. Randomlychosen values for α and X0 form a cloud of points on the t equalszero slice of this three-dimensional figure. Iterating the LogisticMap forward from these values, the transients fall away, and theattractors at each value of α slowly come into view, so that after 512iterations the last time slice resembles Figure 12.12. A variety of behaviours in the Logistic Map as α increases from aperiod four loop at α=3.5 to chaos at α=4. Note the replicated perioddoubling cascades at the right side of each periodic window62Chaos"},{"pageNumber":81,"pageContent":"13. Three-dimensional diagram showing the collapse of initially random values of X0 and α at the left rear side of the boxfalling toward their various attractors as the number of iterations increases. Note the similarity of the points near the rightforward side with those in Figures 11 and 12"},{"pageNumber":82,"pageContent":"It would be asking too much to expect something as simple as theLogistic Map to tell us anything about the behaviour of liquidhelium. But it does. Not only does the onset of complicatedbehaviour show a qualitative indication of period doubling, theactual quantitative values of the Feigenbaum numbers computedfrom many experiments agree remarkably well with thosecomputed from the Logistic Map. Many physical systems seem todisplay this ‘period doubling route to chaos’: hydrodynamics (water,mercury, and liquid helium), lasers, electronics (diodes,transistors), and chemical reactions (BZ reaction). One can oftenestimate the Feigenbaum number to two-digits’ accuracy inexperiments. This is one of the most astounding results reported inthis Introduction to chaos: how could it be that simple calculationswith the Logistic Map can give us information that is relevant to allthese physical systems?The mathematician’s fascination with this diagram arises not onlyfrom its beauty but also from the fact that we would get a similarpicture for the Moran-Ricker Map and many other systems that atfirst instance appear quite different from the Logistic Map. Atechnical argument shows that the period doubling is common in‘one-hump’ maps where the hump looks like a parabola. In a veryreal and relevant sense, almost all nonlinear maps look like this veryclose to their maximum value, so properties like period doublingare called ‘universal’, although not all maps have them. Moreimpressive than these mathematical facts is the empirical fact that awide variety of physical systems display unexpected behaviour that,as far as we can see, reflects this mathematical structure. Is this notthen a strong argument for the mathematics to govern, not merelydescribe, Nature? To address this question, we might considerwhether the Feigenbaum number is more akin to a constant ofgeometry, like π, or a physical constant like the speed of light, c. Thegeometry of disks, cans, and balls is well described using π, but πhardly governs the relationship between real lengths, area, andvolumes in the same way that the values of physical constantsgovern the nature of things within our laws of nature.64Chaos"},{"pageNumber":83,"pageContent":"The origin of the mathematical term ‘chaos’In 1964 the Russian mathematician A. N. Sharkovski proved aremarkable theorem about the behaviours of many ‘one-hump’maps: namely that discovering a periodic loop indicated that others,potentially lots of others, existed. Discovering that a period 16 loopexisted for a particular value of the parameter implied there wereloops of period eight and of four and of two and of one at that value;while finding a loop of period three meant that there was a loop ofevery possible period! It is another non-constructive proof; it doesnot tell us where those loops are, but nevertheless it is a pretty neatresult. Eleven years after Sharkovski, Li and Yorke published theirenormously influential paper with the wonderful title ‘Period ThreeImplies Chaos’. The name ‘chaos’ stuck.Higher-dimensional mathematical systemsMost of our model states so far have consisted of just onecomponent. The vole and weasel model is an exception, since thestate consisted of two numbers: one reflecting the population ofvoles, the other the population of weasels. In this case, the state is avector. Mathematicians call the number of components in the statethe dimension of the system, since plotting the state vectors wouldrequire a state space of that dimension.As we move to higher dimensions, the systems are often not mapsbut flows: a map is a function that takes one value of X and returnsthe next value of X, while a flow provides the velocity of X for anypoint in the state space. Think of a parsnip floating under thesurface of the sea; it is carried along by the current and will traceout the flow of the sea. The three-dimensional path of the parsnip inthe sea is analogous to a path traced out by X in the state space, andboth are sometimes called trajectories. If instead of a parsnip, wefollow the path of an infinitesimal parcel of the fluid itself, we oftenfind these paths to be recurrent with sensitive dependence. Theequations are deterministic and these fluid parcels are said to65Chaos in mathematical models"},{"pageNumber":84,"pageContent":"display ‘Lagrangian chaos’. Laboratory experiments with fluidsoften display beautiful patterns which reflect the chaotic dynamicsobserved in our models of fluid flow. Without examining thedifferential equations that define these velocity fields, we will nexttouch several classic chaotic systems.Dissipative chaosIn 1963, Ed Lorenz published what became a classic paper on thepredictability of chaotic systems. He considered a vastly simplifiedset of three equations based on the dynamics of a fluid near theonset of convection which is now called the Lorenz System. One canpicture the three components of the state in terms of convectiverolls in a layer of fluid between two flat plates when the lower plateis heated. When there is no convection, the fluid is motionless andthe temperature in the fluid decreases uniformly from the warmerplate at the bottom to the cooler plate at the top. The state X of theLorenz model consisted of three values {x,y,z}, where x reflected thespeed of the rotating fluid, y quantified the temperature differencebetween rising and sinking fluid, and z measured the deviationfrom the linear temperature profile. An attractor from this system isshown in Figure 14; by chance, it looks something like a butterfly.The different shading on the attractor indicates variations in thetime it takes an infinitesimal uncertainty to double. We return todiscuss the meaning of these shades in Chapter 6, but note thevariations with location.The evolution of uncertainty in the Lorenz system is shown inFigure 15; this looks a bit more complicated than the correspondingfigure for the Yule Map in Figure 10 (page 52). Figure 15 shows thekind of forecast our 21st-century demon could make for this system:an initial small uncertainty at the bottom of the panel grows wider,then narrower, then wider, then narrower . . . eventually splittinginto two parts and beginning to fade away. But depending on thedecisions we are trying to make, there may still be usefulinformation in this pattern even at the time reflected at the top of66Chaos"},{"pageNumber":85,"pageContent":"14. Three-dimensional plots of (above) the Lorenz attractor and(below) the Moore-Spiegel attractor. The shading indicates variationsin uncertainty doubling time at each point"},{"pageNumber":86,"pageContent":"15. The probability forecast our 21st-century demon would make forthe 1963 Lorenz System. Contrast the way uncertainty evolves in thischaotic system with the relatively simple growth of uncertainty underthe Yule Map shown in Figure 10 on page 52"},{"pageNumber":87,"pageContent":"the panel. On this occasion the uncertainty has not stabilized by thetime it reaches the top of the graph.In 1965, mathematical astronomers Moore and Spiegel considereda simple model of a parcel of gas in the atmosphere of a star. Thestate space is again three-dimensional, and the three components ofX are simply the height, velocity, and acceleration of the parcel. Thedynamics are interesting because we have two competing forces: athermal force that tends to destabilize the parcel and a magneticforce that tends to bring it back to its starting point, much like aspring would. As the parcel rises, it finds itself at a differenttemperature than the surrounding fluid and this feeds back on itsvelocity and its temperature, but at the same time the star’smagnetic field acts as a spring to pull the parcel back towards itsoriginal location. Motion caused by two competing forces oftengives rise to chaos. The Moore-Spiegel attractor is also shown inFigure 16.Chaos experiments have always pushed computers to their limits,and sometimes slightly beyond those limits. In the 1970s, theastronomer Michael Hénon wanted to make a detailed study ofchaotic attractors. For a given amount of computer power thereis a direct trade-off between the complexity of the system andthe duration of the time series one can afford to compute.Hénon wanted a system with properties similar to Lorenz’s1963 system that would be cheaper to iterate on his computer.This was a two-dimensional system, where the state X consistedof the pair of values {x,y}. The Hénon Map is defined by therules:The new value of x i+1 is equal to one minus yi plus α times xi2;the new value of y i+1 is equal to β times xi.Panel (b) of Figure 16 shows the attractor when α is 1.4 and β is 0.3;panel (a) shows a slice of the Moore-Spiegel attractor made bycombining snapshots of the system whenever z was zero and69Chaos in mathematical models"},{"pageNumber":88,"pageContent":"16. Two-dimensional plots of (a) a slice of the Moore-Spiegelattractor at z=0; and (b) the Hénon attractor where α is 1.4 and β is0.3. Note the similar structure with many leaves in each case"},{"pageNumber":89,"pageContent":"growing. This type of figure is called a Poincaré section andillustrates how slices of a flow are much like maps.Delay equations, epidemics, and medicaldiagnosticsAnother interesting family of models are delay equations. Here boththe current state and some state in the past (the ‘delayed state’) playa direct role in the dynamics. These models are common forbiological systems, and can provide insight into oscillatory diseaseslike leukaemia. In the blood supply, the number of cells availabletomorrow depends upon the number available today, and also thenumber of new cells that mature today; the delay comes from thegap in time between when these new cells are requested and whenthey mature: the number of cells maturing today depends on thenumber of blood cells at some point in the past. There are manyother diseases with this kind of oscillatory dynamics, and the studyof chaos in delay equations is extremely interesting and productive.We leave the discussion of mathematical models for a paragraph tonote that medical research is another area where insights from ourmathematical models are deployed for use in real systems. Researchby Mike Mackey at McGill University and others on delay equationshas even led to a cure for at least one oscillatory disease. The studyof nonlinear dynamics has also led to insights in the evolution ofdiseases that oscillate in a population, not an individual; our modelscan be contrasted with reality in the study of measles, where onecan profitably consider the dynamics in time and in space. Theanalysis of chaotic time series has also led to the development ofinsightful ways to view complicated medical time series, includingthose from the brain (EEG) and heart (ECG). This is not to suggestthat these medical phenomena of the real word are chaotic, or evenbest described with chaotic models; methods of analysis developedfor chaos may prove of value in practice regardless of the nature ofthe underlying dynamics of the real systems that generate thesignals analysed.71Chaos in mathematical models"},{"pageNumber":90,"pageContent":"Hamiltonian chaosIf volumes in state space do not shrink in time there can be noattractors. In 1964, Hénon and Heiles published a paper showingchaotic dynamics in a four-dimensional model of the motion of astar within a galaxy. Systems in which volumes in state space do notshrink, including those of Newtonian celestial mechanics commonlyused to predict eclipses, and which trace the future of the solarsystem and spacecraft within it, are called Hamiltonian. Figure 17is a slice from the Hénon-Heiles system, which is Hamiltonian.Note the intricate interweaving of empty islands in a sea of chaotictrajectories. Initial states started within these islands may fall ontoalmost closed loops (tori); alternatively they may follow chaotictrajectories confined within an island chain. In both cases, the orderin which the islands in the chain are visited is predictable, althoughexactly where on each island might be unpredictable; in any case,things are only unpredictable on small length scales.17. A two-dimensional slice of the Hénon-Heiles attractor. Note thesimultaneous loops, and a chaotic sea with many (empty) islands72Chaos"},{"pageNumber":91,"pageContent":"Exploiting the insights of chaosIn the three-year period between 1963 and 1965, threeindependent papers appeared (by Lorenz, by Moore and Spiegel,and by Hénon and Heiles), each using digital computers tointroduce what would be called ‘chaotic dynamics’. In Japan, chaoshad been observed in analogue computer experiments byYoshisuke Ueda, and Russian mathematicians were advancingupon a groundwork laid down by over a century of internationalmathematics. Almost 50 years later, we are still finding new waysto exploit these insights.What limits the predictability of future solar eclipses? Is ituncertainty in our knowledge of the planetary orbits due tothe limited accuracy of our current measurements? Or futurevariations in the length of the day which alters the point on thesurface of the Earth under the eclipse? Or the failure ofNewton’s equations due to effects (better) described by generalrelativity? We can see that the Moon is slowly moving awayfrom the Earth, and assuming that this continues, it willeventually appear too small to block the entire Sun. In thatcase, there will be a last total eclipse of the Sun. Can weforecast when that event will occur and, weather permitting,where we should be on the surface of the Earth in order tosee it? We do not know the answer to that question. Nor do weknow, for certain, if the solar system is stable. Newton was wellaware of the difficulties nonlinearities posed for determiningthe ultimate stability of only three celestial bodies, andsuggested that insuring the stability of the solar system was atask for God. By understanding the kinds of chaotic orbitsthat Hamiltonian systems admit, we have learned many thingsabout the ultimate stability of the solar system. Our best guess,currently, is that our solar system is stable, probably. Insightslike these come from understanding the geometry in state spacerather than attempting detailed calculations based uponobservations.73Chaos in mathematical models"},{"pageNumber":92,"pageContent":"Can we safely draw insights from mathematical behaviour oflow-dimensional systems? They suggest new phenomena to lookfor in experiments, like periodic doubling, or suggest newconstants to estimate in Nature, like the Feigenbaum number.These simple systems also provide test beds for our forecastmethods; this is a bit more dangerous. Are the phenomena oflow-dimensional chaotic systems the same phenomena that weobserve in more complicated models? Are they so common thatthey occur even in simple low-dimensional systems like Lorenz1963 or the Moore-Spiegel system? Or are these phenomenadue to the simplicity of these examples: do they occur only insimple mathematical systems? The same even in or only inquestion applies to techniques developed to forecast or controlchaotic systems, which are tested in low-dimensional systems:do these things happen even in or only in low-dimensionalsystems? The most robust answer so far is that difficultieswe identify in low-dimensional systems rarely go away inhigher-dimensional systems, while successful solutions tothese difficulties which work in low-dimensional systemsoften fail to work in higher-dimensional systems. Recognizingthe danger of generalizing from three-dimensional systems,Lorenz moved on to a 28-dimensional system about 50 years ago;he is still creating new systems today, some in two dimensions andothers in 200 dimensions.Chaos and nonlinearity impact many fields; perhaps the deepestinsight to be drawn here is that complicated-looking solutions aresometimes acceptable and need not be due to external dynamicnoise. This does not imply that, in any particular case, they are notdue to external noise, nor does it lessen the practical value ofstochastic statistical modelling, which has almost a century ofexperience and statistical good practice behind it. It does suggestthe value in developing tests for which methods to use in a givenapplication, and consistency tests for all modelling approached.Our models should be as uninhibited as possible, but not more so.The lasting impact of these simple systems may be in their74Chaos"},{"pageNumber":93,"pageContent":"pedagogical value; young people can be exposed to the richbehaviours of these simple systems early in their education. Byrequiring internal consistency, mathematics constrains our flightsof fancy in drawing metaphors, not so much as to bring them in linewith physical reality, but often opening new doors.75Chaos in mathematical models"},{"pageNumber":94,"pageContent":"Chapter 5Fractals, strange attractors,and dimension(s)Big fleas have little fleasupon their backs to bite’em.And little fleas have lesser fleas,and so ad infinitum.A. de Morgan (1872)No introduction to chaos would be complete without touching uponfractals. This is neither because chaos implies fractals nor becausefractals require chaos, but simply because in dissipative chaos realmathematical fractals appear as if from nowhere. It is just asimportant to distinguish mathematical fractals from physicalfractals as it is to distinguish what we mean by chaos inmathematical systems from what we mean by chaos in physicalsystems. Despite decades of discussion, there is no single generallyaccepted definition of a fractal in either case, although you canusually recognize one when you see it. The notion is bound up inself-similarity: as we zoom in on the boundary of clouds, countries,or coastlines, we see patterns similar to those seen at the larger-length scales again and again. The same thing happens with the setof points in Figure 18. Here the set is composed of five clusters ofpoints; if we enlarge any one of these clusters, we find theenlargement looks similar to the entire set itself. If this similarity isexact – if the zoom is equivalent to the original set – then the set iscalled strictly self-similar. If only statistical properties of interest76"},{"pageNumber":95,"pageContent":"are repeated, then the set is called statistically self-similar.Deciding exactly what counts as a ‘statistical property of interest’opens one of the discussions that has prevented agreement on ageneral definition. Disentangling these interesting details deservesits own Very Short Introduction to Fractals; we will contentourselves with some examples.In the late 18th century, fractals were widely discussed bymathematicians including Georg Cantor, although the famousMiddle Thirds set that bears his name was first found by an Oxfordmathematician named Henry Smith. Fractal entities were oftendisavowed by their mathematical parents as monstrous curves inthe 100 years that followed, just as L. F. Richardson was beginningto quantify the fractal nature of various physical fractals. Bothphysical and mathematical fractals were more warmly embraced byastronomers, meteorologists, and social scientists. One of the firstfractals to bridge the divide – and blur the distinction – between amathematical space and real-world space appeared about 100 yearsago in an attempt to resolve Olbers’ paradox.A fractal solution to Olbers’ paradoxIn 1823, the German astronomer Heinrich Olbers encapsulated acenturies-old concern of astronomers in the concise question: ‘Whyis the night sky dark?’ If the universe were infinitely large and moreor less uniformly filled with stars, then there would be a balancebetween the number of stars at a given distance and the light we getfrom each one of them. This delicate balance implies that the nightsky should be uniformly bright; it would even be difficult to see theSun against a similarly bright day-time sky. But the night sky isdark. That is Olbers’ paradox. Johannes Kepler used this as anargument for a finite number of stars in 1610. Edgar Allan Poe wasthe first to suggest an argument still in vogue today: that the nightsky was dark because there had not been enough time for light fromfar-away stars to reach the Earth, yet. Writing in 1907, Fournierd’Albe proposed an elegant alternative, suggesting that the77Fractals, strange attractors, and dimension(s)"},{"pageNumber":96,"pageContent":"distribution of matter in the universe was uniform but in a fractalmanner. Fournier illustrated his proposal with the figurereproduced in Figure 18. This set is called the Fournier Universe. Itis strictly self-similar: blowing up one of the small cubes by a factorof 5 yields an exact duplicate of the original set. Each small cubecontains the totality of the whole.The Fournier Universe illustrates a way out of Olbers’ paradox: theline Fournier placed in Figure 18 indicates one of many directionsin which no other ‘star’ will ever be found. Fournier did not stop18. The Fournier Universe, showing the self-similar structure, aspublished by Fournier himself in 190778Chaos"},{"pageNumber":97,"pageContent":"at the infinitely large, but also suggested that this cascadeactually extended to the infinitely small; he interpreted atoms asmicro-verses, which were in turn made of yet smaller particles, andsuggested macro-verses in which our galaxies would play the role ofatoms. In this way, he proposed one of the few physical fractals withno inner cut-off and no outer cut-off: a cascade that went from theinfinitely large to the infinitesimally small in a manner reminiscentof the last frames of the film Men in Black.Fractals in physicsBig whorls have little whirls,which feed on their velocity.And little whirls have lesser whirls,and so on to viscosity.L. F. RichardsonClouds, mountains, and coastlines are common examples ofnatural fractals; statistically self-similar objects that exist in realspace. Interest in generating fractal irregularity is not new:Newton himself recorded an early recipe, noting that when beeris poured into milk and ‘the mixture let stand till dry, the surfaceof the curdled substance will appear as rugged and mountainousas the earth at any place’. Unlike Newton’s curdled substance, thefractals of chaos are mathematical objects found in state spaces;they are true fractals as opposed to their physical counterparts.What is the difference? Well, for one thing, a physical fractal onlydisplays the properties of a fractal at certain length scales and notat others. Consider the edge of a cloud: as you look more andmore closely, going to smaller and smaller length scales, you’llreach a point at which the boundary is no more; the cloudvanishes into the helter-skelter rush of molecules and there is noboundary to measure. Similarly, a cloud is not self-similar onlength scales comparable with the size of the Earth. For physicalfractals, fractal concepts break down as we look too closely; thesephysical cut-offs make it easy to identify old Hollywood special79Fractals, strange attractors, and dimension(s)"},{"pageNumber":98,"pageContent":"effects using model ships in wave tanks: we can sense the cut-offis at the wrong length scale relative to the ‘ships’. Today, filmmakers in Hollywood and in Wellington have learned enoughmathematics to generate computer counterfeits that hide the cut-off better. The Japanese artist Hokusai respected this cut-off inhis famous ‘Great Wave’ print of the 1830s. Physicists have alsoknown this for some time: de Morgan’s poem allowed its cascadeof fleas to continue ad infinitum, while the cascade whorls inL. F. Richardson’s version face a limit due to viscosity, the termfor friction within fluids. Richardson was expert in the theoryand observation of turbulence. He once threw parsnips off oneend of Cape Cod canal at regular intervals, using the time of theirarrival at a bridge on the other end of the canal to quantify howthe fluid dispersed as it moved downstream. He also computed(by hand!) the first numerical weather forecast, during the FirstWorld War.A Quaker, who left the Met Office in the First World War tobecome an ambulance driver in France, Richardson later becameinterested in measuring the length of the border between nationsin order to test his theory that this influenced the likelihood oftheir going to war. He identified an odd effect when measuring thesame border on different maps: the border between Spain andPortugal was much longer when measured on the map of Portugalthan it was when measured on the map of Spain! Measuringcoastlines of island nations like Britain, he found that the length ofthe coastline increased as the callipers he walked along the coast tomeasure it decreased, and also noted an unexpected relationshipbetween the area of an island and its perimeter as both vary whenmeasured on different scales. Richardson demonstrated that thesevariations with length scale followed a very regular pattern whichcould be summarized by a single number for a particularboundary: an exponent that related the length of a curve to thelength scale used to measure it. Following fundamental work byMandelbrot, this number is called the fractal dimension of theboundary.80Chaos"},{"pageNumber":99,"pageContent":"Richardson developed a variety of methods to estimate the fractaldimension of physical fractals. The area-perimeter methodquantifies how the area and perimeter both change under higherand higher resolution. For one particular object, such as a singlecloud, this relationship also yields the fractal dimension of itsborder. When we look at many different clouds at the sameresolution, as in a photograph from space, a similar relationshipbetween areas and perimeters emerges; we do not understand whythis alternative area-perimeter relation seems to hold for collectionsof different-sized clouds, given that clouds are famous for not alllooking the same.Fractals in state spaceWe next construct a rather artificial mathematical systemdesigned to dispel one of the most resilient and misleadingmyths of chaos: that detecting upon a fractal set in statespace indicates deterministic dynamics. The Tripling TentMap is:If X is less than a half then take 3X as the new value of X,Otherwise take 3 minus 3X as the new value of X.Almost every initial state between zero and one flies far away fromthe origin; we will ignore these and focus on the infinite number ofinitial conditions which remain forever between zero and one. (Weignore the apparent paradox due to the loose use of ‘infinity’ here,but note Newton’s warning that ‘the principle that all infinities areequal is a precarious one’.)The Tripling Tent Map is chaotic: it is clearly deterministic, thetrajectories of interest are recurrent, and the separation betweeninfinitesimally close points increases by a factor of three on eachiteration, which implies sensitive dependence. A time series fromthe Tripling Tent Map, along with one from the stochastic MiddleThirds IFS Map, are shown in Figure 19. Visually, we see hints that81Fractals, strange attractors, and dimension(s)"},{"pageNumber":100,"pageContent":"19. A time series from (a) the stochastic Middle Thirds IFS Map and (b) the deterministic Tripling Tent Map. The lowerinsets show a summary of all the points visited: approximations to the Middle Thirds Cantor set in each case"},{"pageNumber":101,"pageContent":"the chaotic map is easier to forecast: small values of X are alwaysfollowed by small values of X The two small insets at the bottom ofFigure 19 each show a set of points visited by a long trajectory fromone of the systems, they look very similar and in fact both reflectpoints from the Middle Thirds Cantor set. The two dynamicalsystems each visit the same fractal set, so we can never distinguishthe deterministic system from the stochastic system if we only lookat the dimension of the set of points each system visits; but is it anysurprise that to understand the dynamics we have to examine howthe system moves about, not only where it has been? This simplecounter-example slays the myth noted above; while chaotic systemsmay often move on fractal sets, detecting a finite dimensional setindicates neither determinism nor chaotic dynamics.Finding fractals in carefully crafted mathematical maps is not sosurprising, as mathematicians are clever enough to design mapswhich create fractals. One of the neatest things about dissipativechaos is that fractals appear without the benefit of intelligentdesign. The Hénon Map is the classic example. Mathematicallyspeaking, it represents an entire class of interesting models; there isnothing particularly ‘fractal-looking’ in its definition, as there is inthe Middle Thirds IFS Map. Figure 20 shows a series of zooms fromwhere, as if by magic, self-similar structures spring out. Surely thisis one of the most amazing things about nonlinear dynamicalsystems. There is no hint of artificial design in the Hénon Map, andfractal structure appears commonplace in the attractors ofdissipative chaotic systems. It is not required for chaos, nor viceversa, but it is common.Like all magic, we can understand how the trick works, at least afterthe fact: we have chosen to zoom in about a fixed point of theHénon Map, and looking at the properties of the map very, veryclose to this point reveals how much to zoom in order to make itsself-similarity so striking. The details of the repeated structure, athick line and two thinner lines, depend on what happens far awayfrom this point. But if Hénon is really chaotic and the computer83Fractals, strange attractors, and dimension(s)"},{"pageNumber":102,"pageContent":"trajectory used to make these pictures is realistic, then we have afractal attractor naturally.The traditional theory of turbulence in state space reflectedRichardson’s poem: it was thought that more and more periodicmodes would be excited and tracing the linear sum of all thoseoscillations would require a very high-dimensional state space. Somost physicists were expecting the attractors of turbulence to behigh-dimensional doughnuts, or mathematically speaking, tori.In the early 1970s, David Ruelle and Floris Takens were lookingfor alternatives to smooth high-dimensional tori and ran intolower-dimensional fractal attractors; they found the fractalattractors ‘strange’. Today, the word ‘strange’ is used to describethe geometry of the attractor, specifically the fact that it is a fractal,while the word ‘chaos’ is used to describe the dynamics of thesystem. It is a useful distinction. The precise origin of the phrase‘strange attractor’ has been lost, but the term has proven an20. A series of zooms into the unstable fixed point of the Hénon Map,which is marked with a ‘+’ on each zoom. The same pattern repeats overand over, until we start running out of data points84Chaos"},{"pageNumber":103,"pageContent":"inspiring and appropriate label for these objects of mathematicalphysics. Since Hamiltonian systems have no attractors at all, theyhave no strange attractors. Nevertheless, chaotic time series fromHamiltonian systems often develop intricate patterns with starkinhomogeneity and hints of self-similarity called strangeaccumulators which persist for as long as we run our computers.Their ultimate fate remains unknown.Fractal dimensionsCounting the number of components in the state vector tells us thedimension of the state space. But how would we estimate thedimension of a set of points if those points do not define aboundary; the points that form a strange attractor, for example?One approach reminiscent of the area-perimeter relation is tocompletely cover the set with boxes of a given size, and see how thenumber of boxes required increases as the size of the individualboxes gets smaller. Another approach considers how the number ofpoints changes, on average, as you look inside a ball centred on arandom point and decrease the radius of the ball. To avoidcomplications that arise near the edge of an attractor, ourmathematician will consider only balls with a vanishingly smallradius, r. We find familiar-looking results: near a random point on aline the number of points is proportional to r1 , about a point in aplane it is proportional to πr2 , and about a point from the set whichdefines a solid cube, it is proportional to 4/3 πr3 . In each case, theexponent of r reflects the dimension of the set: one if the set forms aline, two if a plane, three if a solid.This method can be applied to fractal sets, although fractals tend tohave holes, called lacunae, on all scales. While dealing with theselogarithmic wrinkles is non-trivial, we can compute the dimensionof strictly self-similar sets exactly, and immediately notice that thedimension of a fractal is often not a whole number. For the FournierUniverse, the dimension is ~0.7325 (it equals log 5/log 9) whilethe Middle Thirds Cantor set has dimension ~0.6309 (it equals85Fractals, strange attractors, and dimension(s)"},{"pageNumber":104,"pageContent":"log 2/log 3); in each case, the dimension is a fraction bigger thanzero yet less than one. Mandelbrot took the ‘fract’ in ‘fraction’ as theroot of the word ‘fractal’.What is the dimension of the Hénon attractor? Our best estimate is~1.26, but while we know there is an attractor, we do not know forcertain whether or not, in the long run, this attractor is merely along periodic loop. In maps, every periodic loop consists of only afinite number of points and so has dimension zero. To see this, justconsider balls with a radius r smaller than the closest pair of pointson the loop; the number of points in each ball is constant (and equalto one), which we can write as proportional to r0 , and so each hasdimension zero. In Chapter 7, we shall see why it is hard to provewhat happens in the long run using a computer simulation. First,we will take a closer look at the challenges to quantifying thedynamics of uncertainty even when we know the mathematicalsystem perfectly. For real-world systems, we only have noisyobservations, and the problem is harder still.86Chaos"},{"pageNumber":105,"pageContent":"Chapter 6Quantifying the dynamicsof uncertaintyChaos exposes our prejudices when we examine the dynamics ofuncertainty. Despite the hype regarding unpredictability, we shallsee that the quantities used to establish chaos place no restrictionwhatsoever on the accuracy of today’s forecast: chaos does notimply that prediction is hopeless. We can see why the link betweenchaos and predictability has been so badly overstated by looking atthe history of the statistics used to measure uncertainty. Additionalstatistics are available today.Once scientists touch on uncertainty and predictability, they arehonour-bound to clarify the relevance of their forecasts and thestatistics used to quantify their uncertainty. The older man lookingout of la Tour’s painting may have provided the younger man withaccurate tables of probabilities for every hand from a deck of52 cards, but he knows those probabilities do not reflect the gamebeing played. Likewise, our 21st-century demon can quantify thedynamics of uncertainty quite accurately, given her perfect model,but we know we do not have a perfect model. Given only a collectionof imperfect models, how might we relate the diversity of theirbehaviours to our uncertainty about the future state of the realworld?87"},{"pageNumber":106,"pageContent":"The decay of certainty: information withoutcorrelationWhen it comes to predicting what a system will do next, data on therecent state of the system often provide more information thandata on some long past state of the system. In the 1920s, Yulewanted to quantify the extent to which data on this year’s Sun spotsprovide more information about the number of spots that willappear next year than ten-year-old data do. Such a statistic wouldalso allow him to quantitatively compare properties of the originaldata with those of time series generated by models. He inventedwhat is now called the auto-correlation function (or ACF), whichmeasures the linear correlation between states k iterations apart.When k is zero the ACF is one, since any number is perfectlycorrelated with itself. If the time series reflects a periodic cycle, theACF decreases from one as k increases, and then returns to equalone whenever k is an exact multiple of the period. Given data from alinear stochastic system the ACF is of great value, but as we willsoon see, it is of less use when faced with observations from anonlinear system. Nevertheless, some statisticians went so far as todefine determinism as linear correlation; many are still reeling fromthis misstep. It is well known that correlation does not implycausation; the study of chaos has made it clear that causation doesnot imply (linear) correlation either. The correlation betweenconsecutive states of the Full Logistic Map is zero despite the factthat the next state is completely determined by the current state. Infact, its ACF is zero for every separation in time. How then are we todetect relationships in nonlinear systems, much less quantifypredictability, if a mainstay of a century of statistical analysis isblind to such visible relationships? To answer this question, we firstintroduce base two.Bits and pieces of informationComputers tend to record numbers in binary notation: rather thanuse the ten symbols (0,1,2,3,4,5,6,7,8, and 9) we learn in school,88Chaos"},{"pageNumber":107,"pageContent":"they use only the first two (0 and 1). Instead of 1000, 100 and 10representing 103 , 102 and 101, in binary these symbols represent 23,22 and 21 that is, eight, four, and two. The symbol 11 in base tworepresents 21 +20, i.e. three, while 0.10 represents 2—1 (one-half )and 0.001 represents 2—3 (one-eighth). Hence the joke that thereare ten kinds of mathematicians in the world: those whounderstand binary notation and those who do not. Just asmultiplying by ten (10) is easy in base ten, multiplying by two (10)is easy in base two: just shift all the bits to the left, so that1.0100101011 becomes 10.100101011, that is where the Shift Mapgets its name. Similarly dividing by two: its just a shift to the right.A computer usually uses a fixed number of bits for each number,and does not waste valuable memory space storing the ‘decimal’point. This makes dividing a bit curious: On a computer, dividing001010010101100 by two yields 000101001010110; but thendividing 001010010101101 by two yields the same result!Multiplying 000101001010110 by two yields 00101001010110Q,where Q is a new bit the computer has to make up. So it is for everyshift left: a new bit is required in the empty place on the far right. Individing by two, a zero correctly appears in the empty place on thefar left, but any bits that are shifted out the right side this windoware lost forever into the bit bucket. This introduces an annoyingfeature: if we take a number and divide by two, and then multiplyby two, we may not get back to the original number we started with.The discussion thus far leads to differing visions of the growth anddecay of uncertainty – or creation of information – in our variouskinds of mathematical dynamical systems: random systems, chaoticmathematical systems and computerized versions of chaoticmathematical systems. The evolution of the state of a system isoften visualized as a tape passing through a black-box. Whathappens inside the box depends on what kind of dynamical systemwe are watching. As the tape exits the box we see the bitswritten on it; the question of whether the tape is blank when itenters the back of the box, or if it already has the bits written on it,89Quantifying the dynamics of uncertainty"},{"pageNumber":108,"pageContent":"leads to spirited discussions in ivory tower coffee rooms. What arethe options? If the dynamics are random, then the tape comes intothe box blank and leaves with a randomly determined bit stampedon it. In this case, any pattern we believe we see in the bits as thetape ticks constantly forward is a mirage. If the dynamical systemis deterministic, the bits are already printed on the tape (and unlikeus, Laplace’s demon is in a position to already see all of them);we cannot see them clearly until they pass through the box, but theyare already there. Creating all those bits of information issomething like a miracle either way, and it seems to come down topersonal preference whether you prefer one big miracle or a regularstream of small ones: in a deterministic system the picturecorresponds to creating an infinite number of bits all at once:the irrational number which is the initial state; in the randomsystem, it looks as if new bits are created as at each iteration. Inpractice, it certainly seems that we do have some control overhow accurately we measure something, suggesting that the tapeis pre-printed.There is nothing in the definition of a chaotic system that preventsthe tape from running backwards for a while. When this happens,prediction gets simple for a while, since we have seen the tape backup, we already know the next bits that will come out when it runsforward again. When we try to cast this image into the form of acomputational system, we run into difficulty. The tape cannot reallybe blank before it comes into the box: the computer has to ‘make up’those new bits with some deterministic rule when it left-shifts, sothey are effectively already printed on the tape before it enters thebox. More interesting is what happens in a region where the tapebacks up, since the computer cannot ‘remember’ any bits it loses ona right-shift. For constant slope maps we are always shifting left oralways right, the tape never backs up. The computer simulation isstill a deterministic system, although the variety of tapes it canproduce is much less rich than the tapes of the deterministicmathematical map it is simulating. If the map being simulated hasregions of shrinking uncertainty, then there is a transient period90Chaos"},{"pageNumber":109,"pageContent":"during which the tape backs up, the computer cannot know whichbits were written on it; when the tape runs forward again thecomputer uses its internal rule to make up new bits and we may finda 0 and a 1 overprinted on the tape as it comes out of the box asecond time! We discuss other weird things that happen incomputer simulations of chaotic mathematical systems inChapter 7.Statistics for predicting predictabilityOne of the insights of chaos is to focus on information content. Inlinear systems variance reflects information content. Informationcontent is more subtle in nonlinear systems, where size is not theonly indicator of importance. How else might we measureinformation? Consider the points on a circle on the X,Y plane with aradius equal to one, and pick an angle at random. Knowing thevalue of X tells us a great deal about the value of Y – it tells us that Yis one of two values. Likewise, if we do not know all of the bitsneeded to completely represent X, the more bits of X we learn, themore bits of Y we know. Although we will never be able to decidebetween two alternative locations of Y, our uncertainty regardingthe two possible locations shrinks as we measure X more and moreaccurately. Not surprisingly, X and Y have a linear correlation ofzero in this case. Other statistical measures have been developed toquantify just how much knowing one value tells you about theother. Mutual Information, for instance, reflects how many bits of Yyou learn, on average, when you learn another bit of X. For thecircle, if you know the first five bits of X, you know four of the firstfive bits of Y; if you know 20 bits of X, you know 19 of Y; and if youknow all the bits of X, you know all but one of the bits of Y. Withoutthat missing bit, we can’t tell which of two possible values of Y is theactual value of Y. And unfortunately, from the linear-thinking pointof view, the bit you are missing is the value of the ‘largest’ bit in Y.Nevertheless, it is more than a bit misleading to interpret the factthat the correlation is zero to mean you learn nothing about Y uponlearning the value of X.91Quantifying the dynamics of uncertainty"},{"pageNumber":110,"pageContent":"What does Mutual Information tell us about the dynamics of theLogistic map? Mutual Information will reflect the fact that knowingone value of X exactly gives us complete information on futurevalues of X. While given a finite precision measurement of X,Mutual Information reflects how much we know, on average, abouta future measurement of X. In the presence of observational noisewe would tend to know less about future values of X the further theyfall in the future since the corresponding bits of the current valueof X will be obscured by the noise. So Mutual Information tendsto decay as the separation in time increases, while the linearcorrelation coefficient is zero for all separations (except zero).Mutual Information is one useful tool; the development ofcustom-made statistics to use in particular applications is a growthindustry within nonlinear dynamics. It is important to know exactlywhat these new statistics are telling us, and it is equally importantto accept that there is more to say than traditional statistics cantell us.Our model of the noise gives us an idea of our current uncertainty,so one measure of predictability would be the time we expect thatuncertainty to double. We must avoid the trap of linear thinkingthat suggests the quadrupling time will be twice the doubling timein a non-linear system. Since we do not know which time will beof interest (the doubling-time, tripling-time, quadrupling time,or . . . ), we will simply refer to the q-tupling time near a particularinitial condition. The distribution of these q-tupling times isrelevant to predictability: they directly reflect the time we expectour uncertainty in each particular forecast to go through a giventhreshold of interest to us. The average uncertainty doubling timegives the same information averaged over forecasts from this model.It is convenient to have a single number, but this average may notapply to any initial state at all.The average uncertainty doubling time is a useful statistic ofpredictability. But the definition of mathematical chaos is not madein relation to doubling (or any q-tupling) time statistic, but rather in92Chaos"},{"pageNumber":111,"pageContent":"relation to Lyapunov exponents which we define below. This isone reason that chaos and predictability are not as closely related asthey are commonly thought to be. The average doubling time gives amore practical indication of predictability than the leadingLyapunov exponent, but it lacks a major impractical advantagewhich mathematicians value highly and which, as we shall see,Lyapunov exponents do possess.Chaos is defined in the long run. Uniform exponential growth ofuncertainty is found only in the simplest chaotic systems. Indeed,uniform growth is rare amongst chaotic systems which usuallydisplay only effective-exponential growth, or equivalentlyexponential-on-average growth. The average is taken in the limit ofan infinite number of iterations. The number we use to quantify thisgrowth is call the Lyapunov Exponent. If the growth is a pureexponential, not just exponential-on-average, then we can quantifyit as two raised to the power λ t, where t is time and λ is theLyapunov exponent. The Lyapunov exponent has units of bits periteration, and a positive exponent indicates the number of bits ouruncertainty has grown on average after each iteration. A system hasas many Lyapunov exponents as there are directions in its statespace, which is the same as the number of components that makeup the state. For convenience they are listed in decreasing order,and the first Lyapunov exponent, the largest one, is often calledthe leading Lyapunov exponent. In the sixties, the Russianmathematician Osceledec established that Lyapunov exponentsexisted for a wide variety of systems and proved that in manysystems almost all initial conditions would share the sameLyapunov exponents. While Lyapunov exponents are defined byfollowing the nonlinear trajectory of a system in state space, theyonly reflect the growth of uncertainty infinitesimally close to thatnonlinear reference trajectory, and as long as our uncertainty isinfinitesimal it can hardly damage our forecasts.In as much as computing Lyapunov exponents requires averagingover infinite durations and restricts attention to infinitesimal93Quantifying the dynamics of uncertainty"},{"pageNumber":112,"pageContent":"uncertainties, adopting these exponents in the technical definitionof mathematical chaos places this burden on identifying a system aschaotic. The advantage here is that these same properties make theLyapunov exponent a robust reflection of the underlying dynamicalsystem; we can take the state space and stretch it, fold it, twist it,and apply any smooth deformation, and the Lyapunov exponentsdo not change. Mathematicians prize that kind of consistency, andso Lyapunov exponents define whether or not a system has sensitivedependence. If the leading Lyapunov exponent is positive, then wehave exponential-on-average growth of infinitesimal uncertainties,and a positive Lyapunov exponent is taken to be a necessarycondition for chaos. Nevertheless, the same properties that giveLyapunov exponents their robustness make them rather difficult tomeasure in mathematical systems, and perhaps impossible tomeasure in physical dynamical systems. Ideally that should help usremain clear on the difference between mathematical maps andphysical systems.While there is no alternative with the mathematically appealingrobustness of Lyapunov exponents, there are more relevantquantities for quantifying predictability. Knowing the average timeit took a train to travel from Oxford to central London last week ismore likely to provide insight into how long it will take today, thanwould dividing the distance between Oxford and London by theaverage speed of all trains which ever ran in England. Lyapunovexponents give us an average speed, while doubling times give usaverage times. By their very nature, Lyapunov exponents are farremoved from any particular forecast.Look at the menagerie of maps in Figure 8 (page 40): how would wecalculate their Lyapunov exponents or doubling times? We wish toquantify the stretching (or shrinking) that goes on near a referencetrajectory, but if our map is nonlinear then the amount of stretchingwill depend on how far we are from the reference trajectory.Requiring the uncertainty to remain infinitesimally close to thetrajectory circumvents this potential difficulty. For one-dimensional94Chaos"},{"pageNumber":113,"pageContent":"systems we can then legitimately look at the slope of the map ateach point. We are interested in how uncertainty magnifies withtime. To combine magnifications we have to multiply the individualmagnifications together. If my credit card bill doubles one day andthen triples the next, the total increase is six times what I startedwith, not five. This means that to compute the averagemagnification per iteration we must take a geometric average.Suppose the uncertainty increases by a factor of three in the firstiteration, then by two, then by four, then by one third, and then byfour: over all that is a factor of 32 over these five iterations: so onaverage the increase is by a factor of two per iteration, since the fifthroot of 32 is two, that is: 2 × 2 × 2 × 2 × 2=32. We are not interestedin the arithmetic average: 32 divided by 5 is 6.4 and our uncertaintynever grew that much on any one day. Also note that although theaverage growth is by a factor of two per day, the actual factors were3, 2, 4, 1–3, and 4: the growth was not uniform and on one day theuncertainty actually shrunk: if we can bet on the quality of ourforecasts in a chaotic system and if we can bet different amounts ondifferent days, then there may be times where we are much moreconfident in the future. Another myth bites the dust: chaos does notimply prediction is hopeless. In fact, if you can bet against someonewho firmly believes that predicting chaos is uniformly hopeless, youare in a position to educate them.The fact that some of the simplest cases (and most commonexamples) of chaos have constant slopes has lead to theovergeneralization that chaos is uniformly unpredictable. Lookingback at the six chaotic systems in Figure 8 (page 40), we notice thatin four of them (Shift Map, Tent Map, Quarter Map, and TriplingTent Map), the magnitude of the slope is always the same. Onthe other hand, in the Logistic Map and the Moran-Ricker Map, theslope varies a great deal for different values of X. Since a slope withabsolute value less than one indicates shrinking uncertainty, theLogistic Map shows strong growth of uncertainty at values of Xnear zero or near one, and shrinking of uncertainty for values of Xnear one-half! Likewise, the Moran-Ricker Map shows strong95Quantifying the dynamics of uncertainty"},{"pageNumber":114,"pageContent":"growth of uncertainty near zero and at values near one, where themagnitude of the slope is also large, but shrinking at intermediateand high values of X, where the slope is near zero.How might we determine an average that extends into the infinitefuture? Like many mathematical difficulties, the easiest way to solvethis one is to cheat. One reason that the Shift Map and the TentMap are so popular in nonlinear dynamics is that while thetrajectories are chaotic, the magnification of uncertainty is the sameat each state. For the Shift Map, every infinitesimal uncertaintyincreases by a factor of two on each iteration. So the apparentlyintractable task of taking an average as time goes to infinitybecomes trivial: if the uncertainty grows by a factor of two on everyiteration then it grows by a factor of two on average, and the ShiftMap has a Lyapunov exponent of one bit per iteration. Computingthe Lyapunov exponent of the Tent Map is almost as easy: themagnification is either a factor of two or a factor of minus two,depending on which half of the ‘tent’ we are in. The minus sign doesnot effect the size of magnification: it merely indicates that theorientation has flipped from left to right, and we can safely ignorethis. Again we have one bit per iteration. The same trick works forthe Tripling Tent Map, but it has a larger slope of three, and aLyapunov exponent of ~1.58 bits per iteration (the exact value islog2(3) ). Why do we keep taking logarithms instead of just talkingabout ‘magnifying factors’ (Lyapunov numbers)? And why base2 logarithms? This is a personal choice, usually justified by itsconnection to binary arithmetic, its use in computers, a preferencefor saying ‘one bit per iteration’ over saying ‘about 0.693147 nats periteration’, and the fact that multiplying by two is relatively easy forhumans.The graph of the Full Logistic Map reveals a parabola, so themagnification at different states varies, and our trick of taking theaverage of a constant appears to fail. How might we take the limitinto the infinite future? Our physicist would simply fire up acomputer and compute finite-time Lyapunov exponents for many96Chaos"},{"pageNumber":115,"pageContent":"different states. Specifically, he would compute the geometricaverage magnification over two iterations for different values of X,and then the distribution corresponding to three iterations, thenfour iterations, . . . . And so on. If this distribution convergestowards a single value, then he might be willing to count this as anestimate of the Lyapunov exponent, as long as the computer is notrun so long as to be unreliable. As it turns out, this distributionconverges faster than the Law of Large Numbers would suggest.Our physicist is happy with this estimated value, which turns out tobe near one bit per iteration.Our mathematician, of course, would not dream of making such anextrapolation. She sees no analogy between a finite number ofdigital computations, each of which is inexact, and an exactcalculation extended into the infinite future. From her point ofview, the value of the Lyapunov exponent at most values of αremains unknown, even today. But the Full Logistic Map is special,and demonstrates the second trick of mathematicians: substitutingsin θ for X in the rule that defines the Full Logistic Map, and usingsome identities from trigonometry, she can show that the FullLogistic Map is the Shift Map. Since the Lyapunov exponents donot change under this kind of mathematical manipulation, she canprove that the Lyapunov exponent really is equal to one bit periteration, and explain the violation of the Law of Large Numbers ina footnote.Lyapunov exponents in higher dimensionsIf the model state has more than one component, then uncertaintyin one of its components can contribute to future uncertainty inother components. This brings in a whole new set of mathematicalissues, since the order in which you multiply things togetherbecomes important. We will initially avoid these complications byconsidering examples where the uncertainty in differentcomponents do not mix, but we must be careful not to forget thatthese are very special cases!97Quantifying the dynamics of uncertainty"},{"pageNumber":116,"pageContent":"The state space of the Baker’s Map has two components, x and y, asshown in Figure 21. It maps a two-dimensional square back intoitself exactly with the rule:If x is less than one-half:Multiply x by 2 to get the new value of x and divide y by 2 to get thenew y.Otherwise:Multiply x by 2 and subtract one to get the new value of x anddivide y by 2 and add one half to get the new y.In the Baker’s Map, any uncertainty in the horizontal (x)component of our state will double on each iteration, while those invertical (y) are cut in half. Since it is true on every step it is also trueon average. The average uncertainty doubling time is one iterationand the Baker’s Map has one Lyapunov exponent equal to one bitper iteration, and one exponent equal to minus one bit per iteration.21. Schematic showing how points in the square evolve forward underone iteration of (left) Baker’s Map and (right) a Baker’s ApprenticeMap98Chaos"},{"pageNumber":117,"pageContent":"The positive Lyapunov exponent corresponds to growinguncertainty, while the negative one corresponds to shrinkinguncertainty. For every state, there is a direction associated witheach of these exponents; in this very special case these directionsare the same for all states and thus they never mix uncertaintiesin x with uncertainties in y. The Baker’s Map itself was carefullycrafted to avoid the difficulties caused by uncertainty in onecomponent contributing to uncertainty in another component.In almost all two-dimensional maps, of course, such uncertaintiesdo mix, so usually we cannot compute any positive Lyapunovexponents at all!We can see why one might think predicting chaos is hopeless fromthe left panels of Figure 22, which show the evolution of a mouse-shaped ensemble over several iterations of the map. But rememberthat this map is a very special case: our hypothetical baker is veryskilled in kneading, and can uniformly stretch the dough by a factorof two in the horizontal so that it shrinks by a factor of two in thevertical, before returning the lot back into the unit square. It isuseful to contrast the Baker’s Map with various members of thefamily of Baker’s Apprentice Maps. Our hypothetical apprenticesare each less uniform, stretching a small portion of the dough on theright side of the square a great deal, while hardly stretching themajority of the dough to the left at all, as shown in Figure 21.Luckily, all members of the Apprentice family are skilled enoughnot to mix the uncertainty in one component into another, so wecan compute doubling times and Lyapunov exponents of anymember.As it turns out, every Apprentice Map has a leading Lyapunovexponent greater than the Baker’s Map. So if we adopt the leadingLyapunov exponent as our measure of chaos, then the ApprenticeMaps are each ‘more chaotic’ than the Baker’s Map. This conclusionmight cause some unease, when considered in light of Figure 22,which shows, side by side, the evolution of an ensemble of pointsunder the Baker’s Map and also under Apprentice number four. The99Quantifying the dynamics of uncertainty"},{"pageNumber":118,"pageContent":"22. A mouse-like ensemble of initial states (top) and four frames,showing in parallel the evolution of this ensemble under both theBaker’s Map (left) and the fourth Baker’s Apprentice Map (right)"},{"pageNumber":119,"pageContent":"average doubling time of an Apprentice Map can be much greaterthan the Baker’s Map, even though its Lyapunov exponent is alsogreater than that of the Baker’s Map. This is true for an entirefamily of Apprentice Maps, and we can find an Apprentice Mapwith an average doubling time larger than any number one cares toname. Perhaps we should reconsider the connection between chaosand predictability?Positive Lyapunov exponents with shrinkinguncertaintiesAs long as our uncertainty is smaller than the smallest number wecan think of, it can hardly pose any practical limit on our forecasts,and as soon as that uncertainty grows to be measurable, then itsevolution need no longer be reflected by Lyapunov exponents inany way whatsoever. Even in the infinitesimal case, the Baker’sApprentice Maps show that Lyapunov exponents are misleadingindicators of predictability, since the amount the uncertainty growscan vary with the state the system is in. And it gets better: in theclassic system of Lorenz 1963 we can prove that there are regions ofthe state space in which all uncertainties decrease for a while. Givena choice as to when to bet on a forecast, betting when entering sucha region will improve your odds of winning. Predicting chaoticsystems is far from hopeless, betting against someone who naı ̈velybelieves it is hopeless might even prove profitable.We end this discussion of Lyapunov exponents with one more wordof caution. While a direction in which uncertainty neither growsnor shrinks implies a zero Lyapunov exponent the converse is nottrue: a Lyapunov exponent of zero does not imply a direction of nogrowth! Remember the discussion of the exponential thataccompanied Fibonacci’s rabbits: even growth as fast as the squareof time is slower than exponential and will result in a zero Lyapunovexponent. This is one reason why mathematicians are so pedanticabout really taking limits all the way out to the infinite future: if weconsider a long but finite period of time, then any magnification at101Quantifying the dynamics of uncertainty"},{"pageNumber":120,"pageContent":"all would suggest a positive Lyapunov exponent – exponential,linear or even slower than linear growth will yield a magnificationgreater than one over any finite period, and the logarithm of anynumber greater than one will be positive. Computing the statisticsof chaos will prove tricky.Understanding the dynamics of relevantuncertaintiesAs we noted above, an infinitesimal uncertainty cannot cause usmuch difficulty in forecasting; once it becomes measurable, thedetails of its exact size and where the state is in the state space comeinto play. To date, mathematicians have found no elegant methodfor tracking these small but noticeable uncertainties, which are, ofcourse, most relevant to real-world forecasting. The best we can dois to take a sample of initial states, called an ensemble, make thisensemble consistent both with the dynamics of our model and thenoise in our observations, and then see how the ensemble dispersesin the future. For our 21st-century demon that is enough: given herperfect model of the system and of the noise, her noisy observationsof previous states reaching into the distant past, and her access toinfinite computer power, her ensemble will accurately reflect theprobability of future events. If a quarter of her ensemble membersindicate rain tomorrow, then there really is a 25% chance of raintomorrow, given the noisy observations available to her. Decreasingthe noise increases her ability to determine what is more likely tohappen. Chaos is no real barrier to her. She is uncertain of thepresent, but can accurately map that uncertainty into the future:who could ask for anything more? Our models, however, are notperfect and our computational resources are limited: in Chapter 9we contrast the inadequacy with which we must deal with theuncertainty which she can accommodate.The nonlinear zoo contains more than mere chaos. It need not bethe case that the smaller the uncertainty, the more tame itsbehaviour. There are worse things than chaos: it could be the case102Chaos"},{"pageNumber":121,"pageContent":"that the smaller the uncertainty, the faster it grows, leading to anexplosion of infinitesimal uncertainties to finite proportions afteronly a finite period. This is not as outlandish as it might sound: itremains an open question whether or not the basic equations offluid dynamics display this worse-than-chaos behaviour – one ofthose few mathematical questions with a one million dollar rewardattached to it!103Quantifying the dynamics of uncertainty"},{"pageNumber":122,"pageContent":"Chapter 7Real numbers, realobservations, and computersThe mathematician very carefully defines irrational numbers. Thephysicist never meets any such numbers . . . The mathematicianshudders at uncertainty and tries to ignore experimental errors.Leon Brillouin (1964)In this chapter we examine the relation between the numbers in ourmathematical models, the numbers we observe when takingmeasurements in the world, and the numbers used inside a digitalcomputer. The study of chaos has helped to clarify the importanceof distinguishing these three sorts of number. What do we mean bydifferent kinds of number?Whole numbers are integers; measurements of things like ‘thenumber of rabbits in my garden’ come naturally as integers, andcomputers can do perfect mathematics with integers as long as theydo not get too big. But what about things like ‘the length of thistable’, or ‘the temperature at Heathrow Airport’? It seems theseneed not be integers, and it is natural to think of them as beingrepresented by real numbers, numbers which can have an infinitelylong string of digits to the right of the decimal point or bits to theright of the binary point. The debate over whether or not these realnumbers exist in the real world dates back into antiquity. One thingthat is clear is that when we ‘take data’ we only ‘keep’ integer values.If we measure ‘the length of this table’ and write it down as 1.370104"},{"pageNumber":123,"pageContent":"the measurement does not appear to be an integer at first sight, butwe can transform it into an integer by multiplying by 1000; anytimewe are only able to measure a quantity like length or temperature tofinite precision – which is always the case in practice – ourmeasurement can be represented using an integer. And in fact ourmeasurements are almost always recorded in this way today, sincewe tend to record and manipulate them using digital computers,which always store numbers as integers. This suggests somethingof a disconnect between our physical notion of length and ourmeasurements of length, and there is a similar break between ourmathematical models, which consider real numbers, and theircomputerized counterparts, which only allow integers.Of course a real physicist would never say that the length of thetable was 1.370; she would say something like the length was 1.370± 0.005, with the aim of quantifying her uncertainty due to noise.Implicit in this is a model of the noise. Random numbers from thebell-shaped curve is without doubt the most common noise model.One learns to include things like ‘± 0.005’ in order to pass scienceclasses in school; it is usually seen as an annoyance but what does itreally mean? What is it that our measurements are measuring? Isthere a precise number that corresponds to the True length of thetable or the True temperature at the airport, but just obscured bynoise and truncated when we record it? Or is it a fiction, and thebelief that there should be some precise number just a creation ofour science? The study of chaos has clarified the role of uncertaintyand noise in evaluating our theories by suggesting new ways to see ifsuch True values might exist. For the moment we will assume theTruth is out there and that we just cannot see it clearly.Nothing really mattersSo what is an observation exactly? Remember our first time series,which consisted of monthly numbers of rabbits in Fibonacci’smythical garden. In that case, we knew the total number of rabbitsin the garden. But in most studies of population dynamics we do not105Real numbers, real observations, and computers"},{"pageNumber":124,"pageContent":"have such complete information. Suppose for instance that we arestudying a population of voles in Finland. We put out traps, checkthem each day, release the captives, and keep a daily time series ofthe number of voles captured. This number is somehow related tothe number of voles per square kilometre in Finland, but howexactly? Suppose we observe zero voles in our trap today. What doesthis ‘zero’ mean? That there are no voles in this forest? That thereare no voles in Scandinavia? That voles are extinct? Zero in our trapcould mean any or none of these things and thus illustrates twodistinct kinds of uncertainty we must cope with when relating ourmeasurements to our models. The first is simple observationalnoise: an example would be to miscount the number of voles in thetrap, or to find the trap full, leaving open the possibility that morevoles might have been counted on that day if a larger trap had beenused. The second is called representation error: our modelsconsider the population density per square kilometre, but we aremeasuring the number of voles in a trap, so our measurement doesnot represent the variable our models use. Is this a shortcoming ofthe model or the measurement?If we put the wrong number into our model we can expect to get thewrong number out: garbage in, garbage out. But it seems that ourmodels are asking for one kind of number, while our observationsare offering a noisy version of another kind of number. In the case ofweather forecasting where our target variables – temperature,pressure, humidity – are thought to be real numbers, we cannotexpect our observations to reflect the true values exactly. Thissuggests that we might look for models with dynamics which areconsistent with our observations, rather than taking ourobservations and our model states to be more-or-less the samething and trying to measure the distance between some future stateof our model and the corresponding target observation. The goal offorecasting linear systems is to minimize this distance: the forecasterror. When forecasting nonlinear systems it becomes important todistinguish the various things bound up in this quantity, includinguncertainties in observation, truncation in measurement, and the106Chaos"},{"pageNumber":125,"pageContent":"difference between our mathematical models, our computersimulations of them, and whatever it was that actually generatedthe data. We first consider what happens when we try to putdynamics into a digital computer.Computers and chaosRecall that our three requirements for mathematical chaos weredeterminism, sensitive dependence, and recurrence. Computermodels are deterministic to a fault. Sensitive dependence reflectsthe dynamics of infinitesimals, but on any given digital computerthere is a limit to how close two numbers can be, beyond which thecomputer sees no difference at all and will treat them as if they werethe same number. No infinitesimals, no mathematical chaos. Asecond reason that computers cannot display chaos arises from thefact there is only a finite amount of memory in any digitalcomputer: each computer has a limited number of bits and thusonly a limited number of different internal states, so eventually thecomputer must return to a state it has already been in, after which,being deterministic, the computer will simply run in circles,repeating its previous behaviour over and over forever. This fatecannot be avoided, unless some human or other external forceinterferes with the natural dynamic of the digital computer itself. Asimple card trick illustrates the point nicely.What does this imply for computer simulations of the LogisticMap? In the mathematical version of the map, the time series fromiterating almost any X between zero and one will never contain thesame value of X twice, no matter how many iterations we consider.As the number of iterations increases, the smallest value of Xobserved so far will slowly get closer and closer to zero, neveractually reaching zero. For the computer simulation of the LogisticMap there are only about 260 (about a million million million)different values of X between zero and one, so the time series fromthe computer must eventually include two values of X which areexactly the same, becoming stuck in an endless loop. After this107Real numbers, real observations, and computers"},{"pageNumber":126,"pageContent":"happens, the smallest value of X will never decrease again, and anycomputation along this loop, whether it be the average value of X orthe Lyapunov exponent of the map, will reflect the characteristics ofthe particular loop, not the mathematical map. The computertrajectory has become digitally periodic, regardless of what themathematical system would have done. And so it is for all digitalcomputers. Computers cannot do chaos.There may be more than one digitally periodic loop: shuffle a deckof cards and place some of them in a large circle so that the first card23. Two ways to deal the computers-can’t-do-chaos card trick, if thedeck of cards is large enough a time will come when everyone will findthemselves on the same card even when they are placed on a line as inthe upper panel108Chaos"},{"pageNumber":127,"pageContent":"Card tricks and computer programsAsk a friend to pick a secret number between, say, 1 and 8,and then deal out a deck of cards as shown in Figure 23.Counting a face card as a ten and an ace as a one, ask yourfriend to count out her secret number and take the numberof the card she lands on as her new number. If her numberwas one, she would land on the six of spades, and with thenew number six, she would move forward to the four ofclubs; if her original number was three, she would have hitthe three of diamonds, then the ace of hearts, and so on. Tryit yourself using Figure 23 and stop when you hit the jack ofhearts. How did I know you would hit the jack of hearts? Forthe same reason that computers cannot display chaos.Everyone hits the jack of hearts.What does this have to do with computers? A digital com-puter is a finite state machine: there are only a limited num-ber of bits inside it which define its current state. Encoded inthe current state of the machine is the rule that determineswhich state comes next. In the card game there were tenpossible values at each location. If players on two differentcards move forward to land on the same card, they remainidentical from then on; unless one takes great care, nearbystates in a computer will collapse in the same manner. Amodern computer has many more options, but only a finitenumber, so eventually it will hit a configuration (an internalstate) it has hit before, and after that happens it will cycle inthe same loop forever. The card trick works in an analogousway: everyone starts off with their own initial number,updating and moving forward. But once two of these pathsconverge onto the same card, they stay together forever. For109Real numbers, real observations, and computers"},{"pageNumber":128,"pageContent":"follows the last card dealt. Determining which loop each card endsup in yields a list of all the loops. Which is larger: the number ofcards that are actually on loops or those on transients? Shuffle thecards and repeat the experiment to see how the number of loopsand their lengths change with the number of cards dealt. In thesame way, artificially changing the number of bits a computer usesfor each value of X turns it into a mathematical microscope forexamining the digitally fine structure of the map, using thethe particular cards on the table, everyone will hit the jack ofhearts; no one will hit the ace of spades unless they startthere. To see this, try starting with each value. If you pickone, you land on the six, then the four, then the jack; whilepicking two hits the five, the four, and the jack; picking threelands on the three, the ace, the four, and the jack; pickingfour, the two, the ace, the four, and the jack; picking five, thesix and the jack; picking six, the ace, the four, the jack; pick-ing seven, the four and the jack; picking 8, the ace, the two,and the jack. All values lead to the jack. Place the cards in acircle and we have a finite state machine where every startingpoint must lead to a periodic loop, but there may be morethan one loop.By projecting the cards on a screen, you can use this demon-stration with a large audience. Take a number yourself, anddeal out cards until you think everyone has converged. Thenask people to raise their hands if they are on, in this case, thejack of hearts. There is a wonderful look of surprise on thefaces of the audience when they realize that they are all onthe same card. They will converge faster if you restrict thedeck to cards with small values. If you are willing to stack thedeck to get more rapid convergence, what order would youplace the cards?110Chaos"},{"pageNumber":129,"pageContent":"computer dynamics to examine the length scales where there wouldbe far too many boxes to count them all.Shadows of realityReality is that which, when you stop believing in it, doesn’t go away.P. K. DickOur philosopher and our physicist find these results disturbing. Ifour computers cannot reflect our mathematical models, how mightwe decide if our mathematical models reflect reality? If ourcomputers cannot realize a mathematical system as simple as theLogistic Map, how can we evaluate the theory behind our muchmore complicated weather and climate models? Or contrast ourmathematical models with reality? The issue of model inadequacyis deeper than that of uncertainty in the initial condition.One test of model inadequacy is to take the observations we alreadyhave and ask if our model can generate a time series that stays closeto these observations. If the model were perfect there would be atleast one initial state that shadowed any length of observations wemight take, where by shadowing we mean that the difference(s)between the model time series and the observed time series isconsistent with our model for the noise. This gives our model for thenoise a much higher status than it has ever had in the past. Can westill expect shadows when our models are not perfect? No, not inthe long run, if our model is chaotic: we can prove that noshadowing trajectory exists. Noise will not go away, even when westop believing in it. In imperfect chaotic models, we cannot get thenoise to allow a coherent account of the difference between ourmodels and the observations. Model error and observational noiseare inextricably mixed together. And if observations, model states,and real numbers really are different kinds of number – like applesand orangutans – what did we think we were doing when we triedto subtract one from another? To pursue that question, we mustfirst learn more about the statistics of chaos.111Real numbers, real observations, and computers"},{"pageNumber":130,"pageContent":"Chapter 8Sorry, wrong number:statistics and chaosI have no data yet, and it is a capital mistake to theorise before onehas data.(Holmes to Watson in A Scandal in Bohemia, A. C. Doyle)Chaos poses new challenges to statistical estimation, but these needto be seen in the context of the challenges statisticians have beendealing with for centuries. When analysing time series from ourmodels themselves, there is much to be gleaned from statisticalinsight and basic rules of statistical good practice. But our physicistfaces an ‘apples and oranges’ problem when contrasting chaoticmodels with observations of the real world, and this casts the role ofstatistics in a less familiar context. The study of chaotic systems hasclarified just how murky the situation is. There is evendisagreement as to how to estimate the current state of a systemgiven from noisy observations, which threatens to stop us frommaking a forecast before we even get started. Progress here wouldyield fruit on issues as disparate as our ability to foreseetomorrow’s weather and our ability to influence climate change50 years from now.112"},{"pageNumber":131,"pageContent":"The statistics of limits and the limits of statisticsConsider estimating some particular statistic, say the averageheight of all human beings. There may be some disagreementover the definition of the population of ‘all human beings’ (thosealive on 1 January 2000? those alive today? all those who have everlived? . . . ), but that need not distract us yet. Given the height ofevery member of this population a well-defined value exists, we justdo not know what its value is. The average height taken over asample of human beings is called the sample-average. Allstatisticians will agree on this value, even if they disagree aboutthe relationship of this number to the desired average over theentire population. (Well, almost all statisticians will agree.) Thesame cannot be said for sample-Lyapunov exponents. It is not clearthat sample-exponents of chaos can be uniquely defined in anysensible way.There are several reasons for this. First, computing the statistics ofchaos, like fractal dimensions and Lyapunov exponents, requirestaking limits to vanishingly small lengths and over infinitely longdurations. These limits can never be taken based on observations.Second, the study of chaos has provided new ways of makingmodels from data without specifying exactly how to build them. Thefact that different statisticians with the same data set may arrive atrather different sample-statistics makes the statistics of chaosrather different from the sample-mean.Chaos changes what counts as ‘good’Many models contain ‘free’ parameters, meaning parameterswhich, unlike the speed of light or the freezing point of water,we do not already know with good accuracy. What then is thebest value to give the parameter in our model? And if the purposeof the model is to make forecasts, why would we use a valuefrom the lab or from some fundamental theory, if some otherparameter value provided better forecasts? Modelling chaoticSorry, wrong number: statistics and chaos113"},{"pageNumber":132,"pageContent":"systems has even forced us to re-evaluate, arguably to redefine,‘better’.In the weak version of the Perfect Model Scenario, our model hasthe same mathematical structure as the system which generated thedata, but we do not know the True parameter values. Say we knowthat the data was generated by the Logistic Map, without knowingthe value of α. In this case, there is a pretty well-defined ‘best’: theparameter value that generated the data. Given a perfect noisemodel for the observational uncertainty, how do we extract the bestparameter values for use tomorrow given noisy observations fromthe past?If the model is linear, then several centuries of experience andtheory suggests the best parameters are those whose predictions fallclosest to their targets. We have to be careful not to over-tune ourmodel if we want to use it on new observations, but this issue iswell known to our statistician. As long as the model is linear andthe observational noise is from the bell-shaped distribution, then wehave the intuitively appealing aim of minimizing the distancebetween the forecast and the target. Distance is defined in the usualleast squares sense: based on adding up the squares of thedifferences in each component of the state. As the data set grows,the parameter values we estimate will get closer and closer to thosethat generated the data – assuming of course that our linear modelreally did generate the data. And if our model is nonlinear?In the nonlinear case our centuries of intuition prove a distraction ifnot an impediment. The least squares approach can even steer usaway from the correct parameter values. It is hard to understate thenegative impact that failure to react to this simple fact has had onscientific modelling. There have been many warnings that thingsmight go wrong, but given the lack of any clear and present danger– and their ease of use – such methods were regularly (mis)appliedin nonlinear systems. Predicting chaos has made this danger clear:suppose we have noisy observations from the Logistic Map withChaos114"},{"pageNumber":133,"pageContent":"(unknown to us) α=4, even with an infinite data set, the leastsquares approach yields a value for α which is too small. This is nota question of too little data or too little computer power: methodsdeveloped for linear systems give the wrong answer when applied tononlinear questions. The mainstay of statistics simply does not holdwhen estimating the parameters of nonlinear models. This is asituation where ignoring the mathematical details and hoping forthe best leads to disaster in practice: the mathematical justificationfor least squares assumes bell-shaped distributions for theuncertainty both on the initial state and on the forecasts. In linearmodels, a bell-shaped distribution for the uncertainty in the initialcondition results in a bell-shaped distribution for the uncertainty inthe forecasts. In nonlinear models this is not the case.This effect is almost as important as it is neglected. Even today, welack a coherent, deployable rule for parameter estimation innonlinear models. It was the study of chaos that made this factpainfully obvious. Recently Kevin Judd, an applied mathematicianat the University of Western Australia, has argued that not only theprinciple of least squares but the idea of maximum likelihoodgiven the observations is also an unreliable guide in nonlinearsystems. That does not imply that the problem is unsolvable:our 21st-century demon can estimate α very accurately, butshe will not be using least squares. She will be working withshadows. Modern statistics is rising to the challenge of nonlinearestimation, at least in cases where the mathematical structure ofour models is correct.Lies, damn lies, and dimension estimatesA young student once had the intention,to quantify fractal dimension.But data points are not free,and, needing 42-to-the-D,she settled for visual inspection.(after James Thieler)Sorry, wrong number: statistics and chaos115"},{"pageNumber":134,"pageContent":"While Mark Twain would probably have liked fractals, he wouldhave without doubt hated dimension estimates. In 1983, PeterGrassberger and Itamar Procaccia published a paper entitled‘Measuring the Strangeness of Strange Attractors’, which has nowbeen cited by thousands of other scientific papers. Most papersgather only a handful of citations. It would be interesting to usethese citations and examine how ideas from the study of chaosspread between disciplines, from physics and applied mathematicsthrough every scientific genre.The paper provides an engagingly simple procedure for estimating,from a time series, the number of components the state of a goodmodel for a chaotic system would require. The procedure camecomplete with many well-signposted pitfalls. Nevertheless, many ifnot most applications to real data probably lie in one or the other ofthose pits. The mathematical robustness of the dimension is whatmakes capturing it such a prize: you can take an object and stretchit, fold it, roll it up in a ball, even slice it into a myriad of pieces andstick the pieces back together any old way, and you will not alter itsdimension. It is this resilience that effectively requires huge datasets to have a fighting chance at meaningful results. Regrettably,the procedure tended towards false positives, and finding chaosby measuring a low dimension was fashionable. An unfortunatecombination. Interest in identifying low-dimensional dynamics andchaos was triggered by a mathematical theorem, which suggestedone might be able to predict chaos without even knowing what theequations were.Takens’ Theorem and embedologyTime series analysis was re-landscaped in the eighties as ideas fromphysicists in California led by Packard and Farmer were given amathematical foundation by the Dutch mathematician Takens;with that basis new methods to analyse and forecast from a timeseries appeared apace. Takens’ Theorem tells us that if we takeobservations of a deterministic system which evolves in a stateChaos116"},{"pageNumber":135,"pageContent":"space of dimension d, then under some very loose constraints therewill be a nearly identical dynamical model in the delay spacedefined by almost every single measurement function(observation). Suppose the state of the original system has threecomponents a, b, and c, the theorem says that one can build a modelof the entire system from a time series of observations of any one ofthese three components; this is illustrated with real observations inFigure 24; taking just one measurement, say of a, and making avector whose components are values of a in the present and in thepast, results in a delay-reconstruction state space in which a modelequivalent to the original system can be found. When this works, itis called a delay embedding. The ‘almost every’ restrictions arerequired to avoid picking a particularly bad period of time betweenthe observations. By analogy: if you observed the weather only atnoon, then you would have no inkling of what happened at night.Takens’ Theorem recasts the prediction problem from one ofextrapolation in time to one of interpolation in state space. Thetraditional statistician who is at the end of his data stream andtrying to forecast into an unknown future, while Takens’ Theoremplaces our physicist in a delay-embedding state space trying tointerpolate between previous observations. These insights impactmore than just data-based models; complicated high-dimensionalsimulation models evolving on a lower-dimensional attractormight also be modelled by much lower-dimensional, data-basedmodels. In principle, we could integrate the equations in thislower-dimensional space also, but in practice we set up ourmodels as physical simulations in high-dimensional spaces; wecan sometimes prove that lower-dimensional dynamics emerge,but we have no clue how to set up the equations in the relevantlower-dimensional spaces.Comparing Figure 24 with Figure 14 makes it clear that theobservations of the circuit ‘look like’ the Moore-Spiegel attractor,but how deep is this similarity, really? Every physical system isdifferent. Often when we have little data and less understanding,Sorry, wrong number: statistics and chaos117"},{"pageNumber":136,"pageContent":"24. An illustration suggesting Takens’ Theorem might be relevant todata from Machete’s electric circuit carefully designed to produce timeseries which resemble those of the Moore-Spiegel System. Delayreconstruction of one measurement in the lower panel bears someresemblance to the distribution in the upper panel, which plots thevalues of three different simultaneous measurements. Contrast thesewith the lower panel of Figure 14 on page 67"},{"pageNumber":137,"pageContent":"then statistical models provide a valuable starting point forforecasting. As we learn more, and gather more data, simulationmodels often show behaviour ‘similar’ to the time series ofobservations, and as our models get more complicated thissimilarity often becomes more quantitative. On the rare occasionslike this circuit when we have a vast duration of observations, itseems our data-based models – including those suggested byTakens’ Theorem – often provide the best quantitative match. It isalmost as if our simulation models are modelling some perfectcircuit, or planet, while our data-based models more closely reflectthe circuit on the table. In each case, we have only similarity;whether we use statistical models, simulation models, or delay-reconstruction models, the sense in which the physical system isdescribed by any model equations is unclear. This is repeatedly seenin physical systems for which our best models are chaotic; we wouldlike to make them empirically adequate, but are not always surehow to improve them. And with systems like the Earth’satmosphere, we cannot wait to take the required duration ofobservation. The study of chaos suggests a synthesis of these threeapproaches to modelling, but none has yet been achieved.There are several common misinterpretations of Takens’ Theorem.One is that if you have a number of simultaneous observations youshould use only one of them; Takens allows us to use them all! Asecond is to forget that Takens’ only tells us that if we have low-dimensional deterministic dynamics then many of its properties arepreserved in a delay-reconstruction. We must be careful not toreverse the if-then argument and assume that seeing certainproperties in a delay-reconstruction necessarily implies chaos, sincewe rarely if ever know the True mathematical structure of thesystem we are observing.Takens’ Theorem tells us that almost any measurement will work.This is a case where the ‘almost any’ in our mathematician’sfunction space corresponds to ‘not a single one’ in the laboratoriesof the real world. Truncation to a finite number of bits violates anSorry, wrong number: statistics and chaos119"},{"pageNumber":138,"pageContent":"assumption of the theorem. There is also the issue of observationalnoise in our measurements. To some extent these are merelytechnical complaints; a delay reconstruction model may still existand our statistician and physicist can rise to the challenge ofapproximating it given realistic constraints on the data stream.Another problem is more difficult to overcome: the duration of ourobservations needs to exceed the typical recurrence time. It maywell be that the required duration is not only longer than our currentdata set, it may be longer than the lifetime of the system itself. This isa fundamental constraint with philosophical implications. How longwould it take before we would expect to see two days with weatherobservations so similar we could not tell them apart? That is, twodays for which the difference between the corresponding states ofthe Earth’s atmosphere was within the observational uncertainty?About 1030 years. This can hardly be considered a technicalconstraint: on that time scale the Sun will have expanded into a redgiant and vaporized the Earth, and the Universe may even havecollapsed in the Big Crunch. We will leave our philosopher to ponderthe implications held by a theorem that requires that the duration ofthe observations exceed the lifetime of the system.In other systems, like a series of games of roulette, the time betweenobservations of similar states may be much less. The search fordimensions from data streams is slowly being replaced by attemptsto build models from data streams. It has been conjectured that italmost always takes less data to build a good model than it does toobtain an accurate dimension estimate. This is another indicationthat it may prove more profitable to pay attention to the dynamicsrather than estimate statistics. In any event, the excitement ofconstructing these new data-based models brought manyphysicists into what had been largely the preserve of thestatistician. A quarter of a century down the line, one majorimpact of Takens’ Theorem was to meld the statisticians’approach to modelling dynamical systems with that of thephysicists. Things are still evolving and a true synthesis of thesetwo may yet emerge.Chaos120"},{"pageNumber":139,"pageContent":"Surrogate dataThe difficulty of getting to grips with statistical estimation innonlinear systems has stimulated new statistical tests ofsignificance using ‘surrogate data’. Scientists use surrogate data in asystematic attempt to break their favourite theories and nullify theirmost cherished results. While not every test that fails to kill aconclusion makes it stronger, learning the limitations of a result isalways a good thing.Surrogate data tests aim to generate time series which look like theobserved data but come from a known dynamical system. The keyis that this system is known not to have the property one is hopingto detect: can we root out results that look promising but in fact arenot (called false positives) by applying the same analysis to theobserved data and then to many surrogate data sets. We know atthe start that the surrogate data can show only false positives, so ifthe observed data set is not easily distinguished from thesurrogates, then the analysis holds few practical implications. Whatdoes that mean in practice? Well suppose we are hoping to ‘detectchaos’ and our estimated Lyapunov exponent turns out to be 0.5: isthat value significantly greater than zero? If so then we haveevidence for one of the conditions for chaos.Of course, 0.5 is greater than zero. The question we want to answeris: are random fluctuations in an estimated exponent likely to be asbig as 0.5 in a system (i) which produced similar-looking timeseries, and (ii) whose true exponent really was not greater thanzero? We can generate a surrogate time series, and estimate theexponent from this surrogate series. In fact, we can generate 1,000different surrogate series, and get 1,000 different exponents. Wemight then take comfort in our result if almost all of 1,000estimates from the surrogate series are much less than the value of0.5, but if the analysis of surrogate data often yields exponentsgreater than 0.5, then it is hard to argue that the analysis of the realdata provided evidence for a Lyapunov exponent greater than zero.Sorry, wrong number: statistics and chaos121"},{"pageNumber":140,"pageContent":"Applied statisticsIn a pinch, of course, one can drive a screw with a hammer.Statistical tools designed for the analysis of chaotic systems canprovide a new and useful way of looking at observations fromsystems that are not chaotic. Just because the data do not comefrom a chaotic system does not mean that such a statistical analysisdoes not contain valuable information. The analysis of many timeseries, especially in the medical, ecological, and social sciences, mayfall into this category and can provide useful information,information not available from traditional statistical analysis.Statistical good practice protects against being mislead by wishfulthinking, and the insight obtained can prove of value in application,regardless of whether or not it establishes the chaotic credentials ofthe data stream.Data Assimilation is the name given to translating a collection ofnoisy observations into an ensemble of initial model-states. WithinPMS there is a True state that we can approximate, and given thenoise model there is a perfect ensemble which, though availableonly to our 21st-century demon, we can still aim to approximate.But in all real forecasting tasks, we are trying to predict realphysical systems using mathematical systems or computersimulations. The perfect model assumption is never justified andalmost always false: What is the goal of data assimilation in thiscase? In this case, it is not simply that we get the ‘wrong number’when estimating the state of our model that corresponds to reality,but that there is no ‘right number’ to identify. Model inadequacyappears to take even probability forecasts beyond our reach.Attempts to forecast chaotic systems with imperfect models areleading to new ways of exploring how to exploit the diversity ofbehaviour our imperfect models display. Progress requires we neverblur the distinction between our mathematical models, ourcomputer simulations and the real world that provides ourobservations. We turn to prediction in the next chapter.Chaos122"},{"pageNumber":141,"pageContent":"Chapter 9Predictability: does chaosconstrain our forecasts?On two occasions I have been asked [by members of Parliament],‘Pray, Mr. Babbage, if you put into the machine wrong figures, willthe right answers come out?’ I am not able rightly to apprehend thekind of confusion of ideas that could provoke such a question.Charles BabbageWe are always putting the wrong numbers into our machines; thestudy of chaos has refocused interest in determining whether or notany ‘right numbers’ exist. Prediction allows us to examine theconnection between our models and the real world in twosomewhat different ways. We may test our model’s ability to predictthe behaviour of the system in the short term, as in weatherforecasting. Alternatively, we may employ our models whendeciding how to alter the system itself, here we are attempting toalter the future itself towards some desirable, or less undesirable,behaviour, as when using climate models for deciding policy.Chaos poses no prediction problems for Laplace’s demon: givenexact initial conditions, a perfect model and the power to makeexact calculations, it can trace a chaotic system forward in time asaccurately as it can a periodic system. Our 21st-century demon hasa perfect model and can make exact calculations, but is restricted touncertain observations, even if they extend at regular intervals intothe indefinite past. As it turns out, she cannot use these historical123"},{"pageNumber":142,"pageContent":"observations to identify the current state. She does, however, haveaccess to the a complete representation of her uncertainty in thestate given the observations that were made, some would call thisan objective probability distribution for the state but we need not gothere. These facts hold a number of implications: even with aperfect model of a deterministic system, she cannot do better thanmake probability forecasts. We cannot aspire to do better, and thisimplies that we will have to adopt probabilistic evaluation of ourdeterministic models. But all of these demons exist within thePerfect Model Scenario, we must abandon the mathematicalfictions of perfect models and irrational numbers if we wish to offerhonest forecasts of the real world. To fail to make it clear that wehave done so would be to peddle snake oil.Forecasting chaosAnd be these juggling fiends no more believ’d,That palter us in a double sense;That keep the word of promise to our ear,And break it to our hope.Macbeth (Act V)Those who venture to predict have long been criticized even whentheir forecasts prove accurate, in a technical sense. Shakespeare’splay Macbeth focuses on predictions which, while accurate in sometechnical sense, do not provide effective decision support. WhenMacbeth confronts the witches asking them what it is that they do,they reply ‘a deed without a name’. A few hundred years later,Captain Fitzroy coined the term ‘forecast’. There is always thepossibility that a forecast be internally consistent from themodellers’ perspective while actively misdirecting the forecastuser’s expectations. There lies the root of Macbeth’s complaintagainst the witches: they repeatedly offer welcome tidings of whatwould seem to be a path to a prosperous future. Each forecastproves undeniably accurate, but there is little prosperity. Canmodern forecasters who interpret uncertainty within their124Chaos"},{"pageNumber":143,"pageContent":"mathematical models as though it reflected real-world probabilitiesof future events hope to avoid the charge of speaking in a double-sense? Are they guilty of Macbeth’s accusation in carefully wordingtheir probability forecasts, knowing full well we will allow theexcuse of chaos to distract us from entirely different goings on?From accuracy to accountabilityWe can hardly blame our forecasters for failing to provide a clearpicture of where we are going to end up at if we cannot give them aclear picture of where we are at. We can, however, expect ourmodels to tell us how accurately we need to know the initialcondition in order to ensure that the forecast errors stay below sometarget level. The question of whether or not we can reduce the noiseto that level is, hopefully, independent of our model’s ability toforecast given a sufficiently accurate initial state.Ideally, a model will be able to shadow: there will be some initialstate we can iterate so that the resulting time series remains close tothe time series of observations. We have to wait until after we havethe observations to see if a shadow exists, and ‘close’ must bedefined by the properties of the observational noise. But if there isno initial state that shadows, then the model is fundamentallyinadequate. Alternatively, if there is one shadowing trajectory therewill be many. The collection of current states whose pre-historieshave shadowed so far can be considered indistinguishable: if theTrue state is in there we cannot identify it. Nor can we know whichof them will continue to shadow when iterated forward to form aforecast, but we could take some comfort from knowing the typicalshadowing times of forecasts started from one of theseindistinguishable states.It is fairly easy to see that we are headed towards ensemble forecastsbased upon candidates who have shadowed the observations up tothe present. Realizing that even a perfect model couldn’t yield aperfect forecast given an imperfect initial condition, in the 1960s,125Predictability: does chaos constrain our forecasts?"},{"pageNumber":144,"pageContent":"the philosopher Karl Popper defined an accountable model as onethat could quantify a bound on how small the initial uncertaintymust be in order to guarantee a specific desired limit on the forecasterror. Determining this bound on the initial uncertainty issignificantly more difficult for nonlinear systems than it is for linearsystems, but we can generalize the notion of accountability and useit to evaluate whether or not our ensemble forecasts reasonablyreflect probability distributions. Our ensembles will always have afinite number of members, and so any probability forecast weconstruct from them will suffer from this finite resolution: if wehave 1,000 members then we might hope to see most events with a1% chance of happening, but we know we are likely to miss eventswith only a 0.001% chance of happening. We will call an ensembleprediction system accountable if it tells us how big the ensemblehas to be in order to capture events with a given probability.Accountability must be evaluated statistically over many forecasts,but this is something our statistician knows how to do quite well.Our 21st-century demon can make accountable forecasts: she willnot know the future but it will hold no surprises for her. There willbe no unforeseeable events, and unusual events will happen withtheir expected frequency.Model inadequacyWith her perfect model, our 21st-century demon can computeprobabilities that are useful as such. Why can’t we? There arestatisticians who argue we can, including perhaps a reviewer of thisbook, who form one component of a wider group of statisticianswho call themselves Bayesians. Most Bayesians quite reasonablyinsist on using the concepts of probability correctly, but there is asmall but vocal cult among them that confuse the diversity seen inour models for uncertainty in the real world. Just as it is a mistaketo use the concepts of probability incorrectly, it is an error to applythem where they do not belong. Let’s consider an example derivedfrom Galton’s Board.126Chaos"},{"pageNumber":145,"pageContent":"Look back at Figure 2 on page 9. You can buy modern incarnationsof the image on the left on the internet, just Google ‘quincunx’. Themachine corresponding to the image on the right is more difficult toobtain. Modern statisticians have even questioned whether Galtonactually built that one, although Galton describes experiments withthe version, they have been called ‘thought experiments’ since evenmodern efforts to build a device to reproduce the expectedtheoretical results have found it ‘exceedingly difficult to make onethat will accomplish the task in a satisfactory manner’. It is notuncommon for a theorist to blame the apparatus when anexperiment fails to match his theory. Perhaps this is merely anindication that our mathematical models are just different from thephysical systems they aim to reflect? To clarify the differencesbetween our models and reality, we will consider experiments onthe Not A Galton (NAG) Board shown in Figure 25.The NAG Board: an example of pandemoniumThe NAG Board is ‘Not A Galton Board’. It was originallyconstructed for a meeting to celebrate the 150th year of the RoyalMeteorological Society, of which Galton was a member. The NAGBoard has an array of nails distributed in a manner reminiscent ofthose in a Galton Board, but the nails are spaced further apart andimperfectly hammered. Note the small white pin at the top of theboard, just to the left of half way. Rather than using a bucket of leadshot, golf balls are allowed through the NAG Board one at a time,each starting in exactly the same position, or as exactly as a golf ballcan be placed under the white pin by hand. The golf balls do make apleasant sound, but they do not make binary decisions at each nail;in fact, they occasional move horizontally past several nails beforefalling to the next level. Like the Galton Board and Roulette, thedynamics of the NAG Board are not recurrent: the dynamics of eachball is transient and so these systems do not display chaos. Spiegelsuggested this behaviour be called pandemonium. Unlike theGalton Board, the distribution of golf balls at the bottom of theNAG Board does not reflect the bell-shaped distribution;127Predictability: does chaos constrain our forecasts?"},{"pageNumber":146,"pageContent":"nevertheless, we can use an ensemble of golf balls to gain auseful probabilistic estimate of where the next golf ball is likelyto fall.But reality is not a golf ball. Reality is a red rubber ball. And it isdropped only once. Laplace’s demon would allow no discussion of25. The Not A Galton Board, first displayed at a meeting held in StJohn’s College, Cambridge, to celebrate the 150th year of the RoyalMeteorological Society. Note the golf ball falling through the board doesnot make simple binary choices128Chaos"},{"pageNumber":147,"pageContent":"what else might have happened: nothing else could have happened.The analogy here is to take the red rubber ball as the Earth’satmosphere and the golf balls as our model ensemble members. Wecan invest in as many members as we choose. But what does ourdistribution of golf balls tell us about the single passage of the redrubber ball? Surely the diversity of behaviour we observe betweengolf balls tells us something useful? If nothing else, it give us a lowerbound on our uncertainty beyond which we know we cannot beconfident; but it can never provide a bound in which we can beabsolutely confident, even in probabilistic terms. By close analogy,examining the diversity of our models can be very useful, even ifthere is no probability forecast in sight.The red ball is much like a golf ball: it has a diameter slightly largerbut roughly the same as a golf ball and it has, somewhat moreroughly, a similar elasticity. But the red ball which is reality can dothings that a golf ball simply cannot do: some unexpected, somenot; some relevant to our forecast, some not; some known, somenot. In the NAG Board, the golf ball is a good model of reality, auseful model of reality; and an imperfect model of reality. How arewe to interpret this distribution of golf balls? No one knows.Welcome to frontline statistical research. And it gets better. Wecould always interpret the distribution of golf balls as a probabilityforecast conditioned on the assumption that reality is a golf ball.Would it not be a double-sense to proffer probability forecasts oneknew were conditioned on an imperfect model as if they reflectedthe likelihood of future events, regardless of what small printappeared under the forecast?Our ensembles are not restricted to using only golf balls. We mightobtain green rubber balls of a slightly smaller diameter and repeatthe experiment. If we get a distribution of green balls similar to ourdistribution of golf balls, we might take courage – or better, takehope – that the inadequacies of our model might not play such alarge role in the forecast we are interested in. Alternatively, our twomodels may share some systematic deficiency of which we are not129Predictability: does chaos constrain our forecasts?"},{"pageNumber":148,"pageContent":"aware . . . yet. But what if the distributions of golf balls and greenballs are significantly different? Then we cannot sensibly rely oneither. How might quantifying the diversity of our models withthese multi-model ensembles allow us to construct a probabilisticforecast for the one passage of reality? When we look at seasonalweather forecasts, using the best models in the world, thedistribution from each model tends to cluster together, each in adifferent way. How are we to provide decision support in this case,or a forecast? What should be our aim? Indeed, how exactly can wetake aim at any goal given only empirically inadequate models? Ifwe naı ̈vely interpret the diversity of an ensemble of models as aprobability, we will be repeatedly misled; we know at the start thatour models are imperfect, so any discussion of ‘subjectiveprobability’ is a red herring: we do not believe in (any of ) ourmodels in the first place!The bottom line is rather obvious: if our models were perfect andwe had the resources of Laplace’s demon, we would know thefuture; while if our models were perfect and we had the resources ofour 21st-century demon, then chaos would restrict us to probabilityforecasts, even if we knew the Laws of Nature were deterministic. Incase the True Laws of Nature are stochastic, we can envision astatistician’s demon, which will again offer accountable probabilityforecasts with or without exact knowledge of the current state of theuniverse. But is the belief in the existence of mathematically preciseLaws of Nature, whether deterministic or stochastic, any lesswishful thinking than the hope that we will come across any of ourvarious demons offering forecasts in the woods?In any event, it seems we do not currently know the relevantequations for simple physical systems, or for complicated ones. Thestudy of chaos suggests that difficulty lies not with uncertainty inthe number to ‘put in’ but the lack of an empirically adequate modelto put anything into: chaos we might cope with, but it is modelinadequacy, not chaos, that limits predictability. A model mayundeniably be the best in the world, but that says nothing about130Chaos"},{"pageNumber":149,"pageContent":"whether or not it is empirically relevant, much less useful inpractice, or even safe. Forecasters who couch predictions theyexpect to be fundamentally flawed with sleight-of-hand phrasessuch as ‘assume the model is perfect’ or ‘best available information’,may be technically speaking the truth, but if those models cannotshadow the past then it is not clear what ‘uncertainty in the initialstate’ might mean. Those who blame chaos for the shortcomings ofprobability forecasts they devised under the assumption theirmodels were perfect, models they knew to be inadequate, palter tous in a double-sense.131Predictability: does chaos constrain our forecasts?"},{"pageNumber":150,"pageContent":"Chapter 10Applied chaos: can we seethrough our models?All theorems are true,All models are wrong.All data are inaccurate.What are we to do?Scientists often underestimate the debt they owe real-timeforecasters who, day after day, stand up and present their vision ofthe future. Prominent among them are weather forecasters andeconomists, while professional gamblers risk more than their imagewhen they go to work. As do futures traders. The study of chaos hasinitiated a rethink of modelling and clarified the restrictions onwhat we can see through our models. The implications differ, ofcourse, for mathematical systems where we know there is a target totake aim at, and physical systems where what we aim for may wellnot exist.Modelling from the ground up: data-based modelsWe will consider four types of data-based models. The simplest arepersistence models which assume that things will stay as they arenow. A simple dynamic variation on this theme are advectionmodels, which assume the persistence of velocities: here, a stormmoving to the east would be forecast to continue moving to the eastat the same speed. Fitzroy and LeVerrier employed this approach in132"},{"pageNumber":151,"pageContent":"the 1800s, exploiting telegraph signals which could race ahead of anoncoming storm. The third are analogue models. Lorenz’s classic1963 paper ends with the sentence: ‘In the case of the realatmosphere, if all other methods fail, we can wait for an analogue.’An analogue model requires a library of past observations fromwhich a previous state similar to the current state is identified; theknown evolution of this historical analogue provides the forecast.The quality of this method depends on how well we observe thestate and whether or not our library contains sufficiently goodanalogues. When forecasting a recurrent system, obtaining a goodanalogue is just a question of whether or not the library’s collectionis large enough given our aims and the noise level. In practice,building the library may require more than just patience: howmight we proceed if the expected time required to observerecurrence is longer than the lifetime of the system itself ?Traditional statistics has long exploited these three approacheswithin the context of forecasting from historical statistics. Takens’Theorem suggests that for chaotic systems we can do better thanany of them. Suppose we wish to forecast what the state of theatmosphere will be tomorrow from a library. The situation is shownschematically in Figure 26. The analogue approach is to take thestate in the library which is nearest to today’s atmospheric state,and report whatever it did the next day as our forecast fortomorrow. Takens’ Theorem suggests taking a collection of nearbyanalogues and interpolating between their outcomes to form ourforecasts. These data-based delay reconstruction models can proveuseful without being perfect: they need only outperform – or merelycomplement – the other options available to us. Analogueapproaches remain popular in seasonal weather forecasting, whileroulette suggests a data-based modelling success story.It is easy to put money on a winner in roulette: all you have to do isbet one dollar on each number and you’ll have a winner every time.You’ll lose money, of course, since your winner will pay $36, whileyou’ll have to bet on more than 36 numbers. ‘Play them all’133Applied chaos: can we see through our models?"},{"pageNumber":152,"pageContent":"strategies lose money on each and every game; casinos worked thisout some time ago. Making a profit requires more than placing awinning bet every time: it requires a probabilistic forecast that isbetter than the house’s odds. Luckily, that can be achieved short ofthe harsh requirements of empirical adequacy or mathematicalaccountability.The fact that bets can be placed after the ball is in play makesroulette particularly interesting to physicists and the oddstatistician. Suppose you record whenever the ball passes, say, thezero with the big toe on your left foot, and whenever zero passes afixed point on the table with the big toe on your right foot; howoften could a computer in the heel of your cowboy boot correctlypredict which quarter of the roulette wheel the ball would land on?Predicting the correct quarter of the wheel half of the time wouldturn the odds in your favour: when you were right you’d win aboutfour times the amount you lost, leaving a profit of three times yourgamble, and you’d lose it all about half the time; so on average,you’d make about one and a half times the stake you put at risk.While the world will never know how many times people have triedthis, we can put a lower bound of once: the story is nicely told byThomas Bass in ‘The Newtonian Casino’.26. A schematic illustration of interpreting between analogues to makea forecast in a data-based state space. Knowing where the image of eachnearby point falls, we can interpolate to form a forecast for the pointmarked ‘*’134Chaos"},{"pageNumber":153,"pageContent":"Simulation modelsWhat if the most similar analogues did not provide a sufficientlydetailed forecast? One alternative is to learn enough physics tobuild a model of the system from ‘first principles’. Such modelshave proven seductively useful across the sciences, yet we mustremember to come back from model-land and evaluate ourforecasts against real observations. We may well have access to thebest model in the world, but whether or not that model is of anyvalue in making decisions is an independent question.Figure 27 is a schematic reflecting the state space of a UK Met.Office Climate model. The state space of a numerical weatherprediction (NWP) model falls along similar lines, but weathermodels are not run for as long as climate models, and so one oftensimplifies them by assuming things that change slowly, such as theoceans, sea ice or land use, are effectively constant. While theschematic makes models look more elaborate than the simple mapsof previous chapters, once transfered onto a digital computer, theiteration of a weather model is not any more complex really, justmore complicated. The atmosphere, along with the ocean, and thefirst few metres of the Earth’s crust in some models, is effectivelydivided up into boxes; model variables – temperature, pressure,humidity, wind speed, and so on – are defined by one number ineach box. In as much as it contains an entry for every variable inevery grid-box, the model state can be rather large, some have over10,000,000 components. Updating the state of the model is astraightforward if tedious process: one just applies the rule for eachand every component, and iterates over and over again. This is whatRichardson did by hand, taking years to forecast one day ahead. Thefact that the calculations focus on components from ‘nearby’ cellsgave Richardson the idea that a room full of computers arranged asshown in Figure 28 could in fact compute the weather faster than ithappened. Writing in the 1920s, Richardson’s computers werehuman beings. Today’s multiprocessor digital supercomputers usemore or less the same scheme. NWP models are among the most135Applied chaos: can we see through our models?"},{"pageNumber":154,"pageContent":"complicated computer codes ever written and often produceremarkably realistic-looking simulations. Like all models, however,they are imperfect representations of the real-world system theytarget, and the observations we use to initialize them are noisy. Howare we to use such valuable simulations in managing our affairs?Can we at least get an idea of how much we should rely on today’sforecast for next weekend?27. A schematic reflecting the way weather and climate models divideboth the atmosphere and the ocean into ‘‘grid points’’. Here each gridpoint in the atmosphere represents approximately a 250 km by 250 kmsquare, which means that about six points account for the whole ofBritain as shown above136Chaos"},{"pageNumber":155,"pageContent":"28. A realization of Richardson’s dream,in which human computers work inmassively parallel style to calculate theweather before it happens. Note thedirector in the central platform is shininga light on northern Florida, presumablyindicating that those computers areslowing down the project (or perhaps theweather there is just particularly tricky tocompute?)"},{"pageNumber":156,"pageContent":"Ensemble weather prediction systemsLatest EPS giving northern France an edge over Cornwall. Do youhave a travel agent who can advise on ferry bookings?Timemail dated 5 August 1999In 1992 operational weather forecasting centres on both sides of theAtlantic took a great step forward: they stopped trying to say exactlywhat the weather would be next weekend. For decades, they hadrun their computer simulations once a day. As computers grewfaster, the models had grown more and more complicated, limitedonly by the need to get the forecast out well before the weatherarrived. This ‘best guess’ mode of operation ended in 1992: insteadof running the most complicated computer simulation once andthen watching as reality did something different, a slightly lesscomplex model was run a few dozen times. Each member of thisensemble was initialized at a slightly different state. The forecastersthen watched the ensemble of simulations spread out from eachother as they evolved in time towards next weekend, and used thisinformation to quantify the reliability of the forecast for each day.This is an Ensemble Prediction System (EPS).By making an ensemble forecast we can examine alternativesconsistent with our current knowledge of the atmosphere and ourmodels. This provides significant advantages for informed decisionsupport. In 1928, Sir Arthur Eddington predicted a solar eclipse‘visible over Cornwall’ for 11 August 1999. I wanted to see thiseclipse. So did Tim Palmer, Head of the Probability ForecastDivision at the European Centre for Medium-range WeatherForecasts (ECMWF) in Reading, England. As the eclipseapproached, it seemed Cornwall might be overcast. The email fromTim quoted at the beginning of this section was sent six daysbefore the eclipse: we examined the ensemble for the 11th, notingthat the number of ensemble members suggested clear sky overFrance exceeded the corresponding number for Cornwall; the samething happened on the 9th and we left England for France by ferry.138Chaos"},{"pageNumber":157,"pageContent":"There we saw the eclipse, thanks to playing the odds suggested bythe EPS, and to a last minute dash for better visibility madepossible by Tim’s driving skills on tiny French farm roads in aright-hand-drive car; not to mention his solar eclipse black-outglasses. The study of chaos in our model suggests that ouruncertainty in the current state of the atmosphere makes itimpossible to say for certain, even only a week in advance, wherethe eclipse will be visible and where it will be obscured by clouds.By running an ensemble forecast with the aim of tracking thisuncertainty, the EPS provided effective decision supportnevertheless: we saw the eclipse. We did not have to assumeanything about the perfection of the model and there were noprobability distributions in sight.Since the EPS first became operational in 1992, no ensembleforecast was generated for the Burns’ Day storm of January 1990.ECMWF has kindly generated a retrospective ensemble forecastusing the data available two days before the Burns’ Day stormstruck. Figure 4 (on page 14) shows the storm as seen within amodern weather model – called the analysis – along with atwo-day-ahead forecast using only data from before the time ofthe critical ship observations discussed in Chapter 1. Note thatthere is no storm in the forecast. Twelve other ensemble membersalso from two days before the storm are shown in Figure 29;some have storms, some not. The second ensemble member inthe top row looks remarkably like the analysis; the member tworows below it has what looks like a super-storm while othermembers suggest a normal British winter’s day. As the criticalship observations were made after this EPS forecast, thisensemble would have already provided an indication that astorm was likely, and significantly reduced the pressure on theintervention forecaster. At longer lead times, the ensemble fromthree days before Burns’ Day has members with storms overScotland, and there is even one member from the four-day-aheadensemble forecast with a major storm in the vicinity. The ensembleprovides early warning.139Applied chaos: can we see through our models?"},{"pageNumber":158,"pageContent":"29. An ensemble of forecasts from the ECMWF weather model, twodays in advance of the Burns’ Day storm: some show storms, some donot. Unlike the single ‘best guess’ forecast shown in Figure 4 on page 14,here we have some forewarning of the storm"},{"pageNumber":160,"pageContent":"At all lead times, we must cope with the Burns effect: our collectionof ECMWF weather ‘golf balls’ shows the diversity of our model’sbehaviour to aid us when we ‘guess and fear’, without actuallyquantifying the uncertainty in our real-world future. In fact, wecould widen this diversity, if we have enough computer power andquestioned the reliability of certain observations, we might runsome ensemble members with those observations while omittingthem in others. We will never see another situation quite like theBurns’ Day storm of 1990. We might decide where to take futureobservations designed to maximize the chance of distinguishingwhich of our ensemble members were most realistic: those with astorm in the future or those without?Rather than wasting too much energy trying to determine the ‘best’model, we might learn that ensembles members from differentmodels were of more value than one simulation of an extremelyexpensive super-model. But we should not forget the lessons of theNAG Board: our ensembles reveal the diversity of our models notthe probability of future events. We can examine ensembles overinitial conditions, parameter values, even mathematical modelstructures, but it seems only our 21st-century demon can makeprobability forecasts which are useful as such. Luckily, an EPS caninform and add value without providing probabilities that we woulduse as such for decision making.Just after Christmas in 1999, another major storm swept acrossEurope. Called T1 in France and Lothar in Germany, this stormdestroyed 3,000 trees in Versailles alone and set new record highinsurance claims in Europe. Forty-two hours before the storm,ECMWF ran its usual 51-member EPS forecast. Fourteen membersof the 51-member ensemble had storms. It is tempting to forgetthese are but as golf balls on a NAG Board, and interpret this assaying that there was about a 28% probability of a major storm.Even though that temptation should be resisted, we have hereanother EPS forecast with great utility. Running a more realistic,more complicated model once might have shown a storm, or might142Chaos"},{"pageNumber":161,"pageContent":"have shown no storm: why take the chance of not seeing the stormwhen an EPS might quantify that chance? Ensemble forecasting isclearly a sensible idea, but how exactly should we distribute limitedresources between using a more expensive model and making alarger ensemble? This active research question remains open. In themeantime, the ECMWF EPS regularly provides a glimpse ofalternative future scenarios seen through our models withsignificant added value.How to communicate this information in the ensemble withoutshowing the public dozens of weather maps also remains an openquestion. In New Zealand, where severe weather is rather common,the Meteorological Service regularly makes useful probabilisticstatements on their website – statements like ‘two chances in five’.This adds significant value to the description of a likely event. Ofcourse, meteorologists often display a severe weather fetish, whileenergy companies are happy to exploit the significant economicvalue in extracting useful information from more mundaneweather, every day. And those in other sectors with operationalweather risk are beginning to follow suit.Chaos and climate changeClimate is what you expect. Weather is what you get.Robert Heinlein, Time Enough for Love (1974)Climate modelling differs fundamentally from weatherforecasting. Think of the weather in the first week in January ayear from now. It will be mid-summer in Australia and mid-winter in the northern hemisphere. That alone gives us a goodidea of the range of temperatures to expect: this collection ofexpectations is climate – ideally reflecting the relative probabilityof every conceivable weather pattern. If we believe in physicaldeterminism, then the weather next January is alreadypreordained; even so, our concept of the climate collection isrelevant, as our current models are not able to distinguish that143Applied chaos: can we see through our models?"},{"pageNumber":162,"pageContent":"preordained future. The ideal ensemble weather forecast wouldtrace the growth of any initial uncertainty in the state of theatmosphere until it became indistinguishable from thecorresponding climate distribution. Given imperfect models, ofcourse, this doesn’t ever quite happen, as our ensemble of modelsimulations evolves towards the attractor of the model not that ofthe real world, if such a thing exists. Even with a perfect model,and ignoring the impacts of human free will noted by Eddington,accurate probability forecasts based on the current conditions ofthe Earth would be prevented by influences just now leaving theSun, or those due to arrive from beyond the solar system, ofwhich we cannot know today, even in principle.Climate modelling also differs from weather forecasting in that itoften contains a ‘what if’ component. Altering the amount of carbondioxide (CO2) and other greenhouse gases in the atmosphere isanalogous to changing the parameter α in the Logistic Map; as wechange parameter values, the attractor itself changes. In otherwords, while weather forecasters try to interpret the implications adistribution of golf balls holds for the single drop of a red rubberball in the NAG Board of Figure 25 (page 128), climate modellersadd the complication of asking what would happen if the nails weremoved about.Looking at just one run of a climate model carries the same dangersas looking at just one forecast for Burns’ Day in 1990, although therepercussions of such naı ̈ve over-confidence would be much greaterin the climate case. No computing centre in the world has the powerto run large ensembles of climate models. Nevertheless, suchexperiments are made possible by harnessing the backgroundprocessing power of PCs in homes spread about the globe (seewww.climateprediction.net). Thousands of simulations haverevealed that a surprisingly large range of diversity exists within onestate-of-the-art climate model, suggesting that our uncertainty inthe future of real-world climate is at least very large. These resultscontribute to improving current models. They fail to provide144Chaos"},{"pageNumber":163,"pageContent":"evidence that the current generation of climate models canrealistically focus the questions of regional detail, which, whenavailable, will be of great value in decision support. A frankappraisal of the limitations of today’s climate models casts littledoubt upon the wide consensus that significant warming has beenseen in the data of the recent past.How wide is the current diversity among our models? This depends,of course, on what model variables you examine. In terms of planet-wide average temperature, there is a consistent picture of warming;a goodly number of ensemble members show a great deal morewarming than was previously considered. In terms of regionaldetails, there are vast variations between ensemble members. It ishard to judge the utility of estimated precipitation for decisionsupport, even for monthly rainfall over the whole of Europe. Howmight one distinguish what are merely the best currently availableforecasts from forecasts that actually contain useful information fordecision makers in the climate context?In reality, carbon dioxide levels and other factors are constantlychanging, weather and climate merge into a single realization of aone-off transient experiment. Weather forecasters often seethemselves as trying to extract useful information from theensemble before it spreads out across the ‘weather attractor’;climate modellers must address difficult questions about how thestructure of that attractor would change if, say, the amountof carbon dioxide in the atmosphere was doubled and then heldconstant. Lorenz was already doing active research here in the1960s, warning that issues of structural stability and long transientscomplicate climate forecasts, and illustrating the effects in systemsnot much more complicated than the maps we defined in Chapter 3.Given that our weather models are imperfect, their ensembles donot actually evolve towards realistic climate distributions. Andgiven that the properties of the Earth’s climate system areconstantly changing, it makes little sense to talk about some145Applied chaos: can we see through our models?"},{"pageNumber":164,"pageContent":"constantly changing, unobservable ‘realistic climate distribution’ inthe first place. Could any such thing exist outside of model-land?That said, coming to understand chaos and nonlinear dynamics hasimproved both the experimental design in and the practice ofclimate studies, allowing more insightful decision support forpolicy makers. Perhaps most importantly, it has clarified thatdifficult decisions will have to be made under uncertainty. Neitherthe fact that this uncertainty is not tightly constrained nor the factthat it can only be quantified with imperfect models, provides anexcuse for inaction. All difficult policy decisions are made in thecontext of the Burns effect.Chaos in commerce: new opportunities in PhynanceWhen a large number of people are playing a game with clear rulesbut unknown dynamics, it is hard to distinguish those who win withskill from those who win by chance. This is a fundamental problemin judging hedge-fund managers and improving weather models,since traditional scores can actually penalize skilful probabilisticplay. The Prediction Company, or PredCo, was founded on thepremise that there must be a better way to predict the economicmarkets than the linear statistical methods that dominatedquantitative finance two decades ago. PredCo set out upon adifferent path blazed by Doyne Farmer and Norm Packard, alongwith some of the brightest young nonlinear dynamicists of the day,who gave up post-docs for stock options. If there was chaos in themarkets, perhaps others were being be fooled without randomness?Sadly, confidentiality agreements still cloud even PredCo’s earlydays, but the continued profitability of the company indicates thatwhatever it is doing, it is doing it well.PredCo is one example of a general move towards Phynance,bringing well-trained mathematical physicists in to look at forecastproblems in finance, traditionally the statistician’s preserve. Is thestock market chaotic? Current evidence suggests our best models ofthe markets are fundamentally stochastic, so the answer is ‘no’. But146Chaos"},{"pageNumber":165,"pageContent":"neither are they linear. To take one example, the study of chaos hascontributed to fascinating developments at the interface of weatherand economics: many markets are profoundly affected by weather,some are even affected by weather forecasts. Many analysts so fearthat they might be fooled by randomness that they are religiouslycommitted to fairly simple, purely stochastic models, and ignore theobvious fact that some ensemble weather forecasts contain usefulinformation. For energy companies, information on the uncertaintyof weather information is being used daily to avoid ‘chasing theforecast’: buying high, then selling low, then buying high the samecubic metre of natural gas yet again as the weather forecast for nextFriday’s temperature jumps down, then up, then down again, takingthe expected electricity demand for next Friday along with it at eachjump. That fact has put speculators in hot pursuit of methods toforecast the next forecast.The study of chaos leads to efficiency beyond short-term profit;Phynance is making significant contributions to the improveddistribution of perishable goods with weather-related demand,ship, train and truck transport, and demand forecasting in general.Better probabilistic forecasts of chaotic fluctuations in wind andrain significantly increase our ability to use renewable energy,reducing the need to keep fossil fuel generators running on‘standby’, except on days of truly low predictability.Retreating towards a simpler realityPhysical systems inspired the study of chaotic dynamical systems,and we now understand how our 21st-century incarnation ofLaplace’s demon could generate accountable probability forecastsof chaotic systems with her perfect model. Whether purely data-based or derived from today’s ‘Laws of Nature’, the models we haveto hand are imperfect. We must contend both with observationaluncertainty and with model inadequacy. Interpreting an ensembleforecast of the real world as if it were a perfect model probabilityforecast of a mathematical system is to make the most naı ̈ve of147Applied chaos: can we see through our models?"},{"pageNumber":166,"pageContent":"forecasting blunders. Can we find a single real-world system inwhich chaos places the ultimate limit on our forecasts?The Earth’s atmosphere/ocean system is a tough forecasting nut tocrack; physicists avoid a complete retreat to mathematical modelsby examining simpler physical systems on which to break theirforecasting procedures and theories of predictability. We willtrack the course of this retreat from the Earth’s atmosphere toexamine the last ditch, and then examine what lies there in somedetail. Lorenz noted the laboratory ‘dish pan’ experiments ofRaymond Hide to support chaotic interpretations of his computersimulations in the early 1960s. Offspring of those experiments arestill rotating in the Physics Department of Oxford University, wherePeter Read provides the raw material for their data-basedreconstructions. Thus far, probabilistic forecasts of these fluidsystems remain very imperfect. Experimentalists around theglobe have taken valuable data both from fluid systems and frommechanical systems motivated by the chaotic nature of thecorresponding physical models. Real pendulums tend to heat up,changing the ‘fixed’ parameters of simulation models while leavingthe regions of state space on which data-based models were trained.Even dice wear down, a bit, on each throw. Such is the nature of thereal world.Physical systems providing large volumes of data, low observationalnoise levels, and physically stationary conditions might prove moreamenable to the tools of modern nonlinear data analysis.Ecosystems are right out. Fast, clean, and accurately instrumentedlasers have proven rich sources, but we do not have accountableforecast models here or when studying the dynamics of more exoticfluids like helium. At the last ditch we find electronic circuits:arguably simple analogue computers. A manuscript reportingsuccessful ensemble forecasts of these systems is likely to berejected by professional referees for having taken too simple asystem. So much greater the insight when we fail to generateaccountable forecasts for these simplest of real-world systems.148Chaos"},{"pageNumber":167,"pageContent":"Figure 30 shows ensemble forecasts of observed voltages in a circuitconstructed to mimic the Moore-Spiegel system. Forecasts fromtwo different models are shown. In each panel, the dark solid lineshows the target observations generated by the circuit, while eachlight line is an ensemble member; the forecasts start at time equalszero; the ensemble was formed using only observations takenbefore that time. The top two panels show results from Model One,while the bottom two show results from Model Two. Look at the twopanels on the left, which show simultaneous forecasts from eachmodel. Every member of the Model One ensemble runs away fromreality without warning just before time 100, as shown in the upperpanel; the Model Two ensemble in the lower panel manages tospread out at about the correct time (or is it a bit early?), and thediversity of this ensemble looks useful all the way to the end of theforecast. In this case, we may not know which model was going toprove correct, but we can see where they began to strongly divergefrom each other. On the panels to the right, both models fail atabout the same time, in about the same way.In each case, it appears that the forecasts provide insight into thelikely future observations, but that the point in the future when thisinsight fails is not well reflected by either ensemble system. Howcan we best interpret this diversity in terms of a forecast?Analysis of many forecasts from different initial conditions showsthat, interpreted as probability forecasts, these ensembles are notaccountable. This seems to be a general result when using arguablychaotic mathematical models to forecast real-world systems. I knowof no exceptions. Luckily, utility does not require extracting usefulprobability estimates.Odds: do we really have to take our modelsso seriously?In academic mathematics, odds and probabilities are more or lessidentical. In the real world this is not the case. If we add up the149Applied chaos: can we see through our models?"},{"pageNumber":168,"pageContent":"30. Ensemble forecasts of the Machete’s Moore-Spiegel Circuit. Thedark line shows the observations; the light lines are the ensemblemembers; the forecast starts at time zero. The two panels on the leftshow ensemble forecasts for the same data but made by two differentmodels; note that the ensemble in the lower panel manages to catch thecircuit even when the model in the upper panel loses it near time 100.Forecasts from a second initial condition by these same two models isshown in the two panels on the right where the ensembles under bothmodels fail at about the same time"},{"pageNumber":170,"pageContent":"probability of every possible event, then the sum of the probabilitiesshould be one. For any particular set of odds-on, we can then definethe implied probability of an event from the odds on that event. Ifthe sum of the implied probabilities is equal to one, then this set ofodds are probabilistic odds. Outside mathematics lectures,probabilistic odds are rather hard to find in the real world. Therelated notion of ‘fair odds’, where the odds are fixed and one isgiven the option to take either side of a bet, suggests a similar sort ofivory tower ‘wishful thinking’; implied probabilities from odds-against do not complement those from odds-on. The confusion atthe heart of both conceptions comes largely from blurring thedistinction between mathematical systems and the real-worldsystems they model. At the racetrack or in a casino, the impliedprobabilities sum to more than one. A European roulette wheelyields 37/36, while an American wheel yields 38/36. In a casino thisexcess ensures profit; scientifically, we might exploit this sameexcess to communicate information about model inadequacy.Model inadequacy can steer us away from probability forecasts in amanner not dissimilar to the way in which uncertainty in the initialcondition steers us away from the principle of least squares innonlinear models. Theory for incorporating probability forecastsystems into a decision support by maximizing expected utility – orsome other reflection of the user’s goal – is well developed. A‘probability forecast’ which would not be used as such in this settingshould perhaps not be called a probability forecast at all. A theoryfor incorporating forecast systems which provides odds rather thanprobabilities for decision support could, no doubt, be constructed.Judd has already provided several worked examples.It appears that accepting the inadequacy of our own models, whilebeing ignorant of the inadequacy of the models to which thecompetition has access, requires we aim for something short of fairodds. If an odds prediction system can cover its losses – breakingeven when evaluated over all comers while covering its runningcosts – then we can say it generates sustainable odds. Sustainable152Chaos"},{"pageNumber":171,"pageContent":"odds then provide decision support which does not result (has notyet resulted) in catastrophe nor instilled the desire to invest more inimproving those odds in order either to gain greater market shareor to cover running expenses.Ensembles over all the alternatives one can think of to samplemight lead to sustainable odds, allowing the diversity withinmulti-model ensembles to estimate the impact of modelinadequacy. The extent to which the sum of our impliedprobabilities exceeds one provides a manner to quantify modelinadequacy. One wonders if, as we understand some real-worldsystem better and better, we can expect the implied probabilities ofour odds forecasts to ever sum to one for any physical system?Moving to forecast systems which provide odds rather thanprobabilities releases our real-world decision support fromunnatural constraints due to probabilities, which may be well-defined only in our mathematical systems. It is an awkward butinescapable fact that sustainable odds will depend both on thequality of your model and on that of the opposition. Decisionmaking would be easy if accountable probability forecasts were onoffer, but when model diversity cannot be translated into (a decisionrelevant) probability, we have no access to probability forecasts.Pursuing risk management as if we did for the sake of simplicity isfoolhardy. And while odds might prove useful in hourly or dailydecision making, what are we to do in the climate change scenario,where it appears we have only one high-impact event and no trulysimilar test cases to learn from?We have reached the coal face of real-world scientific forecasting.The old seam of probability is growing thin and it is unclear exactlywhich direction we should dig in next. If chaotic dynamical systemshave not provided us with a new shovel, they have at least given us acanary.153Applied chaos: can we see through our models?"},{"pageNumber":172,"pageContent":"Chapter 11Philosophy in chaosYou don’t have to believe everything you compute.Is there really anything new in chaos? There is an old joke aboutthree baseball umpires discussing the facts of life within the game.The first umpire says ‘I calls’em as I see’em.’ The second umpire says‘I calls’em as they are.’ Finally, the third says ‘They ain’t, until Icalls’em.’ The study of chaos tends to force us towards thephilosophical position of the third referee.Complications of chaosDo the quantities we forecast exist only within the forecast modelswe construct? If so, then how might we contrast them with ourobservations? A forecast lies in the state space of our model and,while the corresponding observation is not in that state space,are these two ‘subtractable’? This is a mathematical version ofthe ‘apples and oranges’ problem: are the model state andthe observation similar enough that we can meaningfullysubtract one from the other to define a distance, to then call aforecast error? Or are they not? And if not, then how might weproceed?Evaluation of chaotic models has exposed a second fundamentalcomplication that arises even in perfect nonlinear models with154"},{"pageNumber":173,"pageContent":"unknown parameter values: how do we determine the bestvalues? If the model is linear, then we have several centuriesof experience and theory which convincingly establish that thebest values in practice are those that yield the closest agreementon the target data, where closest is defined in a least squaressense (smallest distance between the model and the targetobservations); likelihood is a useful thing to maximize. If ourmodel is not linear, then our centuries of intuition often prove adistraction, if not an impediment to progress. Taking least squaresis no longer optimal, and the very idea of ‘accuracy’ has to berethought. This simple fact is as important as it is neglected.This problem is easily illustrated in the Logistic Map: given thecorrect mathematical formula and all the details of the noisemodel – random numbers with a bell-shaped distribution –using least squares to estimate α leads to systematic errors.This is not a question of too few data or insufficient computerpower, it is the method that fails. We can compute the optimalleast squares solution: its value for α is too small at all noiselevels. This principled approach just does not apply to nonlinearmodels because the theorems behind the principle of leastsquares repeatedly assume bell-shaped distributions. The shapeof these distributions is preserved by linear models, butnonlinear models distort the bell-shape, making least squaresinappropriate. In practice, this ‘wishful linear thinking’systematically underestimates the true parameter value atevery noise level. Recent (mis)interpretations of climatemodels have floundered due to similarly wishful linear thinking.Our 21st-century demon will be able to estimate α very accurately,but she will not be using least squares to do so! (She will be lookingfor shadows.)Philosophers have also wondered whether fractal intricacy mightestablish the existence of real numbers in nature, proving thatirrational numbers exist even if we can only see a few of theleading bits. Strange attractors offer nothing to support sucharguments that cannot be obtained from linear dynamical155Philosophy in chaos"},{"pageNumber":174,"pageContent":"systems. On the other hand, chaos offers a new way to use bothmodels and our observations to define variables in remarkabledetail – if our models are good enough – via states along the shadowfrom an empirically adequate nonlinear model. If our modelshadows the observations for an extended time, then all theshadowing states will fall into a very narrow range of values,providing a way to define values for observables like temperature toa precision beyond that at which our usual concept of temperaturebreaks down. We will never get to an irrational number, but anempirically adequate model could supply a definition of arbitraryaccuracy, using the observations while placing the model into a rolenot unlike that of the third umpire. That said, the traditionalconnection between temperature and our measurements of it via anoise model, remains safe until useful shadowing trajectories areshown to exist.Another philosophical quandary arises in terms of how to define the‘best’ forecast in practice. Probabilistic forecasts provide adistribution as each forecast, while the target observation we verifyagainst will always be a single event: when the forecast distributiondiffers from one forecast to the next, we have yet another ‘applesand oranges’ problem and can never evaluate even one of ourforecast distributions as a distribution.The success of our models tends to lull us towards the happythought that mathematical laws govern the real-world systems ofinterest to us. Linear models formed a happy family. The wronglinear model can be close to the right linear model, and seen to beso, in a sense that does not apply to nonlinear models. It is not easyto see that an imperfect nonlinear model is ‘close to’ the right modelgiven only observations: we can see that it allows long shadows, butif the two models have different attractors – and we know that theattractors of very similar mathematical models can be very different– then we do not know how to make ensembles that produceaccountable probability forecasts. We must reconsider how ournonlinear models might approach Truth, in the case that Truth can156Chaos"},{"pageNumber":175,"pageContent":"be encapsulated in some ‘right’ model. We have no scientific reasonto believe that such a perfect model exists. Our philosopher mightturn from muddy issues raised on the quest for Truth andcontemplate the implications of there being nothing more thancollections of imperfect models. What advice might she offer ourphysicist? If new computer power allows the generation ofensembles over everything we can think of (initial conditions,parameter values, models, compilers, computer architecture, and soon), how do we interpret the distributions that come outscientifically? Or expose the folly of hiding from these issues behinda single simulation from a particularly complicated ultra-high-resolution model?Lastly, note that when working with the wrong model, we may askthe wrong question. Who is who in la Tour’s card game? Thequestion assumes a model in which each player can be only amathematician or a physicist or a statistician or a philosopher, andthat there must be a representative of each discipline at the table.Perhaps this assumption is false. As real-world scientists, can eachof our players take on every role?The burden of proof: what is chaotic, really?If we stay with mathematical standards of proof, then very fewsystems can be proven to be chaotic. The definition of mathematicalchaos can only be applied to mathematical systems, so we cannotbegin to prove a physical system is chaotic, or periodic for thatmatter. Nevertheless, it is useful to describe physical systems asperiodic or chaotic as long as we do not confuse the mathematicalmodels with the systems we use them to describe. When we havethe model in hand, we can see whether it is deterministic orstochastic, but even after knowing it to be deterministic, provingit to be chaotic is non-trivial. Calculating Lyapunov exponentsis a difficult task, and there are very few systems for which we cando this analytically. It took almost 40 years to establish amathematical proof that the dynamics of the 1963 Lorenz System157Philosophy in chaos"},{"pageNumber":176,"pageContent":"were chaotic, so the question regarding more complicatedequations like those used for the weather is likely to remain open forquite some time.We cannot hope to defend a claim that a physical system is chaoticunless we discard the mathematicians’ burden of proof, and with itthe most common meaning of chaos. Nevertheless, if our bestmodels of a physical system appear to be chaotic, if they aredeterministic, appear to be recurrent, and suggest sensitivedependence by exhibiting the rapid growth of small uncertainties,then these facts provide a working definition of what it means for aphysical system to be chaotic. We may one day find a betterdescription of that physical system which does not have theseproperties, but that is the way of all science. In this sense, theweather is chaotic while the economy is not. Does this imply that ifwe were to add a so-called random number generator to ourweather model we no longer believe real weather is chaotic? Not atall, as long as we only wish to employ a random number generatorfor engineering reasons, like accounting for defects in the finitecomputerized model. In a similar vein, the fact we cannot employ atrue random number generator in our computer models does notimply we must consider the stock market deterministic. The studyof chaos has laid bare the importance of distinguishing betweenour best models and the best way to construct computersimulations of those models. If our model structure is imperfect,our best models of a deterministic system might well turn out to bestochastic!Perhaps the most interesting question of all to come out of chaoticforecasting is the open question of a fourth modelling paradigm: wesee our best model fail to shadow, we suspect that there is no way tofix this model, either within the deterministic modelling scheme ofour physicist, or within the standard stochastic schemes of ourstatistician. Can further study of mathematical chaos suggest asynthesis that will give us access to models that can at least shadowphysical systems?158Chaos"},{"pageNumber":177,"pageContent":"Shadows, chaos, and the futureOur eyes once opened, we may pass on to a yet newer outlook of theworld, but we can never go back to the old outlook.A. Eddington (1927)Mathematics is the ultimate science fiction. While mathematicianscan happily limit their activities to domains where all theirassumptions hold (‘almost always’), physicists and statisticiansmust deal with the external world through the data to hand and thetheories to mind. We must keep this difference in mind if we aregoing to use words like ‘chaos’ when speaking with mathematiciansand scientists; a chaotic mathematical system is simply a differentbeast than a physical system we call chaotic. Mathematics proves;science struggles merely to describe. Failure to recognize thisdistinction has injected needless acrimony into the discussion.Neither side is ‘winning’ this argument, and as the previousgeneration slowly leaves the field, it is interesting to observe somemembers of the next generation adopt an ensemble approach:neither selecting nor merging but literally adopting multiplemodels as a model and using them in unison. Rather than playingas adversaries in a contest, can our physicist, mathematician,statistician, and philosopher work as a team?The study of chaos helps us to see more clearly which questionsmake sense and which are truly nonsensical: the study of chaoticdynamics has forced us to accept that some of our goals areunreachable given the awkward properties of nonlinear systems.And given that our best models of the world are nonlinear – modelsfor the weather, the economy, epidemics, the brain, the Moore-Spiegel circuit, even the Earth’s climate system – this insight hasimplications beyond science, extending to decision support andpolicy making. Ideally, the insights of chaos and nonlineardynamics will come to the aid of the climate modeller, who, whenasked to answer a question she knows to be meaningless, isempowered to explain the current limits to our knowledge and159Philosophy in chaos"},{"pageNumber":178,"pageContent":"communicate the available information. Even if modelimperfections imply that there is no policy-relevant probabilityforecast, a better understanding of the underlying physical processhas aided decision makers for ages.All difficult decisions are made under uncertainty; understandingchaos has helped us to provide better decision support. Significanteconomic progress has already been made in the energy sector,where the profitability of using information-rich weather ensembleshas led to daily use of uncertainty information from trading floors ofthe markets to the control rooms of national electricity grids.Prophecy is difficult; it is never clear which context science willadopt next, but the fact that chaos has changed the goal posts maywell be its most enduring impact on science. This message needs tobe introduced earlier in education; the role of uncertainty and therich variety of behaviour that mathematically simple systems revealis still largely unappreciated. Observational uncertainty isinextricably melded with model error, forcing us to re-evaluate whatcounts as a good model. Our old goal to minimize least squares hasbeen proven to mislead, but should we replace them with a searchfor shadows, for a model with good-looking behaviour, or the abilityto make more accountable probability forecasts? From our newvantage point, we can see more clearly which questions make sense,calling forth challenges to the foundational assumptions ofmathematical physics and to applications of probability theory. Areour modelling failures due to our inability to select the correctanswer from among the available options, or is there no suitableoption on offer? How do we interpret simulations from modelswhich are not empirically adequate? Regardless of our personalbeliefs on the existence of Truth, chaos has forced us to rethink whatit means to approximate Nature.The study of chaos has provided new tools: delay reconstructionsthat may yield consistent models even when we do not know the‘underlying equations’, new statistics with which to describe160Chaos"},{"pageNumber":179,"pageContent":"dynamical systems quantitatively, new methods of forecastinguncertainty, and shadows that bridge the gaps between our models,our observations, and our noise. It has moved the focus fromcorrelation to information, from accuracy to accountability, fromartificially minimizing arguably irrelevant error to increasing utility.It rekindles debate on the status of objective probability: can weever construct an operationally useful probability forecast, or are weforced to develop novel ad hoc methods for using probabilisticinformation without probability forecasts? Are we quantifying ouruncertainty in the future of the real world or exploring the diversityin our models? Science seeks its own inadequacy; coping withconstant uncertainty in science is not a weakness but a strength.Chaos has provided much new cloth for our study of the world,without providing any perfect models or ultimate solutions. Scienceis a patchwork, and some of the seams admit draughts.Early in the film The Matrix, Morpheus echoes the words ofEddington that open this last section:This is your last chance. After this, there is no going back. You takethe blue pill and the story ends. You wake up in your bed and youbelieve whatever you want to believe. You take the red pill and youstay in Wonderland and I show you how deep the rabbit hole goes.Remember that all I am offering is the truth. Nothing more.Chaos is the red pill.161Philosophy in chaos"},{"pageNumber":180,"pageContent":"This page intentionally left blank"},{"pageNumber":181,"pageContent":"GlossaryMathematicians are like a certain type of Frenchman; when you talkto them they translate it into their own language, and then it soonturns into something completely different.Goethe, Maxims and Reflections (1779)These entries are not meant to provide precise definitions, butare intended to convey the main idea for quick reference. Someterms hold different shades of meaning when used bymathematicians (M), physicists (P), computer scientists (C), orstatisticians (S). Definitions and discussion can be found in theCATS’ Forum at www.lsecats.org and in books listed in the furtherreading.almost every (M): A mathematical catch phrase to warn that eventhough something is 100% true, there are instances when it is false.almost every (P): Almost every.attractor: A point or collection of points in state space which someother collection of states approach nearer and nearer as they areiterated forward.basin of attraction: For a particular attractor, the collection of allstates that will eventually approach it.Burns effect: An expression that encapsulates the difficulty thatincomplete foresight and imperfect models bring to attempts atrational decision making.163"},{"pageNumber":182,"pageContent":"butterfly effect: An expression that encapsulates the idea that smalldifferences in the present can result in large differences in the future.chaos (C): A computer program that aspires to represent a chaoticmathematical system. In practice, all digital computerized dynamicalsystems are on or evolving towards a periodic loop.chaos (M): A mathematical dynamical system which (a) isdeterministic, (b) is recurrent, and (c) has sensitive dependence oninitial state.chaos (P): A physical system that we currently believe would be bestmodelled by a chaotic mathematical system.chaotic attractor: An attractor on which the dynamics are chaotic. Achaotic attractor may have a fractal geometry or it may not; so thereare strange chaotic attractors and chaotic attractors that are notstrange.conservative dynamical systems: A dynamical system in which avolume of state space does not shrink as it is iterated forward. Thesesystems cannot have attractors.delay reconstruction: A model state space constructed by takingtime-delayed values of the same variable in place of observations ofadditional state variables.deterministic dynamics: A dynamical system that can be iteratedwithout recourse to a random number generator, whose initial statedefines all future states under iteration.dissipative dynamical system: A dynamical system for which, onaverage, a volume of state space shrinks when iterated forward underthe system. While the volume will tend to zero, it need not shrink to apoint and may approach a quite complicated attractor.doubling time: The time it takes an initial uncertainty to increase by afactor of two. The average doubling time is a measure ofpredictability.effectively exponential growth: Growth in time which, when averagedinto the infinite future, will appear to be exponential-on-average, butwhich may grow rather slowly, or even shrink, for long periods oftime.ensemble forecast: A forecast based on the iterates of a number ofdifferent initial states forward (perhaps with different parameter164Chaos"},{"pageNumber":183,"pageContent":"values, or even different models) and in so doing reveals the diversityof our model(s) and so provides a lower bound on the likely impacts ofuncertainty in model-based forecasts.exponential growth: Growth where the rate of increase in X isproportional to the value of X, so that as X gets larger, it grows evenfaster.fixed point: A state of a dynamical system which stays put; astationary point whose future value under the system is its currentvalue.flow: A dynamical system in which time is continuous.fractal: A self-similar collection of points or an object that is self-similarin an interesting way (more interesting than, say, a smooth line orplane). Usually, one requires a fractal set to have zero volume in thespace that it lives, as a line in two dimensions has no area, or a surfacein three dimensions has no volume.geometric average: The result of multiplying N numbers together andthen taking the Nth root of the product.indistinguishable state: One member of the collection of points which,given an observational noise model, you would not expect to be able torule out as having generated the observations actually generated bysome target trajectory X. This collection is called the set ofindistinguishable states of X and has nothing to do with anyparticular set of observations.infinitesimal: A quantity smaller than any number you can name, butstrictly greater than zero.iterate: To apply the rule defining a dynamical map once, moving thestate forward one step.linear dynamical system: A dynamical system in which sums ofsolutions are also solutions, more generally one that allowssuperposition of solutions. (For technical reasons, we do not wish tosay ‘involves only linear rules’.)Lyapunov exponent: A measure of the average speed with whichinfinitesimally close states separate. It is called an exponent, since itis the logarithm of the average rate, which makes it easy to distinguishexponential-on-average growth (greater than zero) from exponential-on-average shrinking (negative). Note that slower-than-exponential165Glossary"},{"pageNumber":184,"pageContent":"growth, slower-than-exponential shrinking, and no-growth-at-all areall combined into one value (zero).Lyapunov time: One divided by the Lyapunov exponent, this numberhas little to do with the predictability of anything except in the mostsimplistic chaotic systems.map: A rule that determines a new state from the current state; in thiskind of mathematical dynamical system, time takes on only discrete(integer) values, so the series of values of X are labelled as Xi where i isoften called ‘time’.model: A mathematical dynamical system of interest either due to itsown dynamics or the fact that its dynamics are reminiscent of those ofa physical system.noise (measurement): Observational uncertainty, the idea that there isa ‘True’ value we are trying to measure, and repeated attempts providenumbers that are close to it but not exact. Noise is what we blame forthe inaccuracy of our measurements.noise (dynamic): Anything that interferes with the system, changingits future behaviour from that of the deterministic part of themodel.noise model: A mathematical model of noise used in the attempt toaccount for whatever is cast as real noise.non-constructive proof: A mathematical proof that establishes thatsomething exists without telling us how to find it.nonlinear: Everything that is not linear.observational uncertainty: Measurement error, uncertainties due tothe inexactness of any observation of the state of the system.pandemonium: Transient dynamics that display characteristicssuggestive of chaos, but only over a finite duration of time (and so notrecurrent).parameters: Quantities in our models that represent and define certaincharacteristics of the system modelled; parameters are generally heldfixed as the model state evolves.Perfect Model Scenario (PMS): A useful mathematical sleight-of-hand in which we use the model in hand to generate the data, andthen pretend to forget that we have done so and analyse the ‘data’using our model and tools. More generally, perhaps, any situation in166Chaos"},{"pageNumber":185,"pageContent":"which we have a perfect model of the mathematical structure of thesystem we are studying.periodic loop: A series of states in a deterministic system which closesupon itself: the first state following from the last, which will repeatover and over forever. A periodic orbit or limit cycle.Poincaré section: The cross-section of a flow, recording the valueof all variables when one variable happens to take on a particularvalue. Developed by Poincaré to allow him to turn a flow intoa map.predictability (M): Property that allows construction of a usefulforecast distribution that differs from random draws from thefinal (climatological) distribution; for systems with attractors, thisimplies a forecast better than picking points blindly from theattractor.predictability (P): Property that allows current information to yielduseful information about the future state of a system.prediction: A statement about the future state of a system.probabilistic: Everything that is not unequivocal, statements thatadmit uncertainty.random dynamics: Dynamics such that the future state is notdetermined by the current state. Also called stochastic dynamics.recurrent trajectory: A trajectory which will eventually return veryclose to its current state.sample-statistic (S): A statistic (for example: the mean, the variance,the average doubling time, or largest Lyapunov exponent) that isestimated from a sample of data. The phrase is used to avoidconfusion with the true value of the statistic.sensitive dependence (P): The rapid, exponential-on-average,separation of nearby states with time.shadowing (M): A relationship between two perfectly known modelswith slightly different dynamics, where one can prove that one of themodels will have some trajectory that stays near a given trajectory ofthe other model.shadowing (P): A dynamical system is said to ‘shadow’ a set ofobservations when it can produce a trajectory that might well havegiven rise to those observations given the expected observational167Glossary"},{"pageNumber":186,"pageContent":"noise; a shadow is a trajectory that is consistent with both the noisemodel and the observations.state: A point in state space that completely defines the currentcondition of that system.state space: The space in which each point completely specifies thestate, or condition, of a dynamical system.stochastic dynamics: See random dynamics.strange attractor: An attractor with fractal structure. A strangeattractor may be chaotic or non-chaotic.time series (M, P, S): A series of observations taken to represent theevolution of a system over time; the location of the nine planets, thenumber of sunspots, and the population of mice are examples. Also,the output of a mathematical model. Also (S): Confusingly, the modelitself.transient dynamics: Ephemeral behaviour as in one game of roulette,or one ball in either the Galton Board or the NAG Board, sinceeventually the ball stops. See pandemonium.168Chaos"},{"pageNumber":187,"pageContent":"Further readingFor childrenMichael Coleman and Gwyneth Williamson, One, Two, Three, Oops!(London: Little Tiger Press, 1999)FictionRay Bradbury, ‘A Sound Like Thunder’ (Collier’s Magazine, 28 June1952)Carol Shields, Unless (Toronto: Random House Canada, 2002)History of and historical scienceThomas Bass, The Newtonian Casino (Harmondsworth: Penguin,1991)Leon Brillouin, Scientific Uncertainty and Information (New York:Academic Press, 1964)John L. Casti, Searching for Certainty (New York: William Morrow,1991)Arthur Eddington, The Nature of the Physical World (Cambridge:Cambridge University Press, Gifford Lectures Series, 1928)E. E. Fournier d’Albe, Two New Worlds (London: Longmans Green,1907)Francis Galton, Natural Inheritance (London: Macmillan, 1889)Stephen M. Stigler (2002) Statistics on the Table: The History ofStatistical Concepts and Methods (Cambridge, Mass: HarvardUniversity Press, 2002)169"},{"pageNumber":188,"pageContent":"H. S. Thayer, Newton’s Philosophy of Nature (New York: Hafner,1953)Philosophy of scienceR. C. Bishop, Introduction to the Philosophy of Social Science (London:Continuum, in press)N. Cartwright, How the Laws of Physics Lie (Oxford: Oxford UniversityPress, 1983)John Earman, A Primer on Determinism (Dordrecht: Reidel, 1986)Jennifer Hecht, Doubt: A History (San Francisco: Harper, 2003)P. Smith, Explaining Chaos (Cambridge: Cambridge University Press,1998)ChaosL. Glass and M. Mackey, From Clocks to Chaos (Princeton: PrincetonUniversity Press, 1988)Ed Lorenz, The Essence of Chaos (London: UCL Press, 1993)J. C. Sprott, Chaos and Time-Series Analysis (Oxford: Oxford UniversityPress, 2003)I. Stewart, Does God Play Dice? (Harmondsworth: Penguin, 1997)WeatherT. Palmer and R. Hagedorn, Predictability (Cambridge: CambridgeUniversity Press, 2006)More detailed discussionsEdward Ott, Chaos in Dynamical Systems (Cambridge: CambridgeUniversity Press, 2002)G. Gouesbet, S. Meunier-Guttin-Cluzel, and O. Menard (eds), Chaosand its Reconstruction (NOVA, 2003). (See, in particular, Chapter 9by Kevin Judd for a review of ten years of work at CADO in dynamicalsystems modelling from time series.)H. Kantz and T. Schreiber, Nonlinear Time Series Analysis, 2nd edn.(Cambridge: Cambridge University Press, 2003)More on the Bakers, including the equations, can be found in H. Tong(ed.), ‘Chaos and Forecasting’, World Scientific Publications(Singapore, 1995).170Chaos"},{"pageNumber":189,"pageContent":"The full 51-member forecast, along with a number of colour illustrationsin this Very Short Introduction, can be found in L. A. Smith (2002)‘Predictability and Chaos’, in Encyclopedia of Atmospheric Sciences,ed. J. Holton, J. Pyle, and J. Curry (New York: Academic Press, 2002),pp. 1777–85.Also in this seriesTimothy Gowers, Very Short Introduction to Mathematics171Further reading"},{"pageNumber":190,"pageContent":"This page intentionally left blank"},{"pageNumber":191,"pageContent":"IndexAAC Map 42–3Accountability 125–6Accuracy 125–6Advection models 132–3Almost every 34, 163Analogue models 133, 134Area-perimeter method 81Attractors 35–9, 45–7, 163chaotic 69–71, 164Hénon 69–71Hénon-Heiles 72Lorenz 66, 67Moore-Spiegel 67, 69–71strange 84–5, 168Auto-correlation function(ACF) 88BBabbage, Charles 123Baker’s Apprentice Maps 98,99–101Baker’s Map 98–101Barometer 6Base two 88–9Basin of attraction 163Bayesians 126Bell-shaped curve 8, 9, 52,114–15, 155Ben Dahir, Sissa 22–3Bifurcation diagram 60–2Binary notation 88–9Blood cells 71Borders/boundaries 80Bradbury, Ray 1, 5–6Brillouin, Leon 104Burns’ Day storm 10–16,139–42Burns effect 15, 142, 146, 163Butterfly effect 1, 5–6, 15, 164CCantor, Georg 77Card tricks 108, 108–10Causation 88Chaotic attractors 69–71,164Cheat with the Ace ofDiamonds (de la Tour)19–21Chess 22–3Climate modelling 143–6,159–60Clouds 81Coastlines 80Commerce 146–7Computer simulations 34,43–4, 90–1, 107–10,117–20, 135–6Computers 88–91, 107–10Conservative dynamicalsystems 164Correlation 88DDarwin, Charles 4–5Data assimilation 122Data-based models 117–20,132–4De Morgan, A. 76, 80Delay-embedding state space116–20Delay equations 71173"},{"pageNumber":192,"pageContent":"Delay reconstruction models117–20, 133, 164Determinism 1, 3, 42, 88, 90,107, 158, 164Digitally periodic loops 107–10Dimensions 65dimension estimates 115–16Dissipative chaos 66–71, 83Dissipative dynamical systems45, 164Doubling time 92–3, 101, 164Duration of observations 120Dynamic noise 55Dynamical systems 33–5computer simulations 34,43–4, 90–1, 107–10,117–20, 135–6creation of information89–90mathematical 33–52,89–90physical 33–4, 53–7, 64,147–9, 150–1, 157–8EEarth’s atmosphere/oceansystem 148Eddington, Arthur 17–18, 138,159Effectively exponential growth93, 164Electronic circuits 148–9,150–1Embedology 116–20Energy sector 147, 160Ensemble forecasts 28–9, 102,125–6, 138–43, 149,150–1, 164–5Ensemble weather predictionsystems (EPS) 138–43Epidemics 71Errors 4exponential growth of 27–8forecast errors 29–31, 106–7observational uncertainty 4,8, 160, 166representation error 106European Centre for Medium-range Weather Forecasts(ECMWF) 138, 139–43,142–3Evolution 5Exponential growth 22–9, 30,165Exponential-on-averagegrowth 93, 94FFair odds 152Farmer, J.D. 116Feigenbaum number 61–4Fibonacci numbers 26–7financial markets 146–7Fitzroy, Robert 5, 6, 124,132–3Fixed points 37, 60–1, 165Flows 65–6, 165Folding 29–32Forecast errors 29–31, 106–7Forecasting 16, 123–31accuracy and accountability125–6ensemble forecasts 28–9,102, 125–6, 138–43, 149,150–1, 164–5model inadequacy 126–7174Chaos"},{"pageNumber":193,"pageContent":"pandemonium 127–31weather see Weatherforecastingsee also PredictabilityFournier D’Albe, EdmundEdward 77–9Fournier Universe 78–9, 85Fractal dimensions 80–1, 85–6Fractals 76–86, 165in physics 79–81solution to Olbers’ paradox77–9in state space 81–5Franklin, Benjamin 3–4Full Logistic Map 37–9,39–42, 88, 96–7GGalton, Francis 6–8Galton Boards 8, 9, 126–7Geometric average 95–7,165Grassberger, Peter 116Great Storm of 1987 11growthexponential 22–9, 30, 165exponential-on-average 93,94linear 23stretching, folding andgrowth of uncertainty29–32HHamiltonian chaos 72Hénon attractor 69–71, 86Hénon-Heiles attractor 72Hénon Map 69–71, 83–4Hide, Raymond 148Higher-dimensional systems65–72, 74Lyopunov exponents in97–101Hokusai, Katsushika 80IImplied probability 152Indistinguishable state 165Infinitesimal quantities 31,93–4, 102–3, 165Informationcomputers and 88–91content 91mutual 91–2without correlation 88Integers 104–5Iterated Function Systems(IFS) 43Iteration 33, 165JJudd, Kevin 115, 152KKepler, Johannes 77LLa Tour, Georges De 19–21Lacunae 85Lagrangian chaos 65–6Laplace, Pierre 3, 4Laplace’s demon 3Leading Lyapunov exponent93Least squares approach114–15, 155175Index"},{"pageNumber":194,"pageContent":"Leonardo of Pisa 25LeVerrier, Urbain Jean Joseph6, 57, 132–3Limits 113Linear dynamical systems 10,28, 51, 156, 165Linear growth 23Logistic Map 45, 59–60, 92,95, 155attractors 46, 48–9computer simulations107–10universality 60–4Long-range modelling seemodelsLorenz, Ed 6, 66, 74, 133, 145,148Lorenz attractor 66, 67Lorenz system 66–9, 101,157–8Lothar/T1 storm of 1999142–3Low-dimensional systems58–64, 74Lyapunov exponents 93–102,157, 165–6in higher dimensions 97–101positive exponents withshrinking uncertainties101–2Lyapunov time 166MMacbeth 124–5Mach, E. 53Machete’s Moore-Spiegelcircuit 117, 118, 149, 150–1Mandelbrot, Benoît 80, 86Maps 23, 35–44, 166see also under individualtypes of mapMarkets 146–7Mathematical dynamicalsystems 33–52, 89–90attractors 35–9, 45–7maps 35–44parameters and modelstructure 44–5statistical models of Sunspots 50–2tuning model parametersand structural stability47–50Mathematical fractals 76, 77Mathematical models 15,58–75delay equations 71dissipative chaos 66–71exploiting insights of chaos73–5Hamiltonian chaos 72higher-dimensional systems65–72, 74origin of mathematical term‘chaos’ 65universality 60–4Mathematics 20–1, 34, 55–6,159Maximum likelihood 115Maxwell, James Clerk 8–9May, Lord 58–60Medical research 71Mercury 57Meteorology see WeatherforecastingMiddle Thirds Cantor set 77,85–6176Chaos"},{"pageNumber":195,"pageContent":"Middle Thirds IFS Map 43,81–3Model inadequacy 57, 111,126–7, 130–1, 152–3, 160Models 16, 27, 132–53, 166climate 143–6, 159–60data-based 117–20, 132–4mathematical seeMathematical modelsodds and probabilities149–53parameters see ParametersPhynance 146–7physical systems 147–9,150–1simulation 135–7weather forecasting 12–16,135–43Moore-Spiegel attractor 67,69–71Moore-Spiegel system 117, 118,149, 150–1Moran-Ricker Map 41, 59, 60,64, 95–6Mutual information 91–2NNAG (Not A Galton) Board127–31Neptune 57New Zealand 143Newton, Isaac 73, 79Newton’s Laws 3Night sky, darkness of 77–9Noise 53–4, 166dynamic 55exponential error growth27–8observational 4, 55–7, 92,106, 111Noise model 54, 92, 105, 111,166Noise reduction 29Non-constructive proof 46,166Nonlinearity 1, 10, 60, 155,159–60, 166model parameter estimation114–15Numbers 104–5, 155–6Numerical weather prediction(NWP) models 135–7OObservational noise 4, 55–7,92, 106, 111Observational uncertainty 4, 8,160, 166Observations 105–7duration of 120and model states 154operational weatherforecasting 12–15Odds 149–53Olbers’ paradox 77–9Osceledec, V. 93PPackard, N.H. 116Pandemonium 127–31, 166Parameters 24, 166best values for 113–15, 154–5and model structure 44–5tuning 47–50Perfect Model Scenario (PMS)54, 56, 57, 114, 122, 166177Index"},{"pageNumber":196,"pageContent":"Period doubling 61–4Periodic loops 43, 50, 61–4, 65,86, 167attractors 46, 48–9digitally 107–10Persistence models 132Philosophy 20–1, 35, 53, 57,154–61burden of proof 157–8complications 154–7shadowing and the future159–61Phynance 146–7Physical dynamical systems33–4, 53–7, 64, 157–8models and 147–9, 150–1observations and noise55–7Physical fractals 76, 77,79–81Physics 20–1, 34, 56, 159Planets 57Poe, Edgar Allen 4, 8, 77Poincaré section 71, 167Popper, Karl 125–6Population dynamics 25–9,58–64, 105–6Predictability 16–18, 51–2,123–31, 167quantifying 91–7, 101see also ForecastingPrediction Company (PredCo)146–7Probabilistic odds 152Probability 129–31, 161odds and 149–53Procaccia, Itamar 116Proof 157–8non-constructive 46, 166QQuadrupling Map 36–7Quantification 87–103computers and information88–91dynamics of relevantuncertainties 102–3information withoutcorrelation 88Lyapunov exponents93–102, 157, 165–6statistics for predictingpredictability 91–7Quantum mechanics 54Quartering Map 37, 39, 40, 45,95Quincunx see Galton BoardsRRabbit Map 25–9Random dynamical systems42–4, 54–5, 89–90,167Random number generators44Read, Peter 148Real world 16–18models and 147–9,150–1science in 19–21Recurrent trajectory 32, 107,158, 167Representation error 106Rice Map 22–4Richardson, L.F. 77, 79, 80–1,135, 137Roulette 133–4, 152Ruelle, David 84178Chaos"},{"pageNumber":197,"pageContent":"SSample-statistics 113, 167Self-similarity 76–7, 78Sensitive dependence 1–2, 5–6,8–10, 15, 94, 107, 158,167Shadowing 111, 125, 156,159–61, 167Sharkovski, A.N. 65Shift Map 40, 95, 96Short-range forecasting seeForecastingSimulation models 135–7Small differences see SensitivedependenceSmith, Henry 77Solar eclipse 17–18, 73,138–9Solar system 73Spiegel, Ed 127State 36, 167State space 36, 168fractals in 81–5Statistical self-similarity 76–7Statistics 20–1, 35, 112–22applied statistics 122best values for parameters113–15dimension estimates 115–16limits of 113models of Sun spots 50–2for predicting predictability91–7surrogate data 121Takens’ Theorem 55, 116–20,133Stochastic systems 42–4, 54–5,89–90, 167Stock markets 146–7Storms 6Burns’ Day storm 10–16,139–42Great Storm of 1987 11T1/Lothar Storm of 1999142–3Strange accumulators 85Strange attractors 84–5,168Stretching 29–32Strict self-similarity 76, 78Structural stability 47–50Sun spots 50–2Superposition 51Surrogate data 121Sustainable odds 152–3TT1/Lothar Storm of 1999142–3Takens, Floris 84Takens’ Theorem 55, 116–20,133Tent Map 41, 95, 96Time series 25, 34–5, 168Transient dynamics 43–4,127–31, 168Tripling Tent Map 40, 81–3,95, 96Turbulence 84UUeda, Yoshisuke 73UK Meteorological Office 6Uncertainty 2in current state, parametersand model structure47–50179Index"},{"pageNumber":198,"pageContent":"evolution in Lorenz system66–9evolution in Yule Map 51–2exponential growth 24, 28quantifying dynamics of seeQuantificationsensitivity and 8–10stretching, folding andgrowth of 29–32Universality 60–4VVulcan 57WWeather forecasting 3–4, 6–16,17–18, 106, 135–43, 147Burns’ Day storm 10–16,139–42ensemble prediction systems138–43the first forecasts 6–10,80numerical weatherprediction models135–7operational weatherforecasting 12–15Whitehead, Alfred North 16,17YYule, Udny 50–1, 88Yule Map 51–2180Chaos"}]
